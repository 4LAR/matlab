Министерство образования и науки Российской Федерации
Федеральное государственное бюджетное образовательное 
учреждение высшего профессионального образования
«Пермский национальный исследовательский 
политехнический университет» 
А.Л. Гольдштейн 
ОПТИМИЗАЦИЯ В СРЕДЕ MATLAB 
Утверждено
Редакционно-издательским советом университета
в качестве учебного пособия
Издательство 
Пермского национального исследовательского
политехнического университета
2015 
2 
УДК 004.422.8:519.873(075.8) 
Г63 
Рецензенты: 
д-р физ.-мат. наук, директор по корпоративному обучению
и научной деятельности А.Н. Румянцев
(ООО «Парма-Телеком») 
д-р техн. наук, профессор Ю.Н. Хижняков
(Пермский национальный исследовательский
политехнический университет)
Гольдштейн, А.Л. 
Г63 Оптимизация в среде MATLAB: учеб. пособие / А.Л. Гольдштейн. – Пермь: Изд-во Перм. нац. исслед. политехн. ун-та, 2015. – 
192 с. 
ISBN 978-5-398-01361-0 
Рассмотрены возможности системы компьютерной математики
MATLAB в части решения оптимизационных задач. Достаточно подробно описаны функции пакетов расширения Toolbox Optimization и
Toolbox Global Optimization. Приведены многочисленные примеры решения задач оптимизации в режиме командной строки, иллюстрированные двумерными и трехмерными графиками, а также задания для восьми лабораторных работ. 
Предназначено для студентов (бакалавров и магистров), изучающих курс «Методы оптимизации». Также может быть полезно тем, кто
сталкивается с необходимостью решать задачи оптимизации. 
УДК 004.422.8:519.873(075.8) 
ISBN 978-5-398-01361-0 © ПНИПУ, 2015 
3 
ОГЛАВЛЕНИЕ
Введение........................................................................................................ 5 
1. Одномерная минимизация в MATLAB.................................................. 7 
2. Безусловная минимизация функций многих
переменных................................................................................................. 11 
2.1. Функция fminunc ............................................................................. 11 
2.2. Функция fminsearch......................................................................... 17 
Лабораторная работа № 1. Одномерная и безусловная
оптимизация............................................................................................ 20 
3. Условная оптимизация .......................................................................... 21 
Лабораторная работа № 2. Условная оптимизация............................. 40 
4. Глобальная оптимизация....................................................................... 41 
4.1. Метод GlobalSearch ......................................................................... 41 
4.2. Метод MultiStart............................................................................... 50 
Лабораторная работа № 3. Исследование методов GlobalSearch 
и MultiStart .............................................................................................. 69 
4.3. Метод Direct Search ......................................................................... 70 
4.4. Метод Simulated Annealing ............................................................. 87 
Лабораторная работа № 4. Исследование методов
прямого поиска и отжига....................................................................... 98 
4.5. The Genetic Algorithm.................................................................... 100 
4.6. Сравнительная характеристика решателей................................. 116 
Лабораторная работа № 5. Генетический алгоритм.......................... 117 
5. Многокритериальная оптимизация .................................................... 119 
5.1. Функция gamultiobj ....................................................................... 119 
5.2. Метод достижения цели. Функция fgoalattain ............................ 128 
5.3. Функция fminimax ......................................................................... 135 
Лабораторная работа № 6. Решение многокритериальных
задач....................................................................................................... 137 
6. Линейное программирование. Функция linprog................................ 139 
7. Целочисленное программирование. Функция bintprog ................... 148 
4 
8. Квадратичное программирование. Функция quadprog..................... 152 
Лабораторная работа № 7. Решение задач математического
программирования ............................................................................... 157 
9. Другие функции пакета Toolbox Optimization................................... 159 
9.1. Нахождение корней функции одной переменной...................... 159 
9.2. Решение системы нелинейных уравнений.................................. 160 
9.3. Нелинейная задача наименьших квадратов................................ 164 
9.4. Задача аппроксимации.................................................................. 166 
9.5. Неотрицательный линейный метод
наименьших квадратов ........................................................................ 168 
9.6. Линейная задача наименьших квадратов
с ограничениями................................................................................... 170 
Лабораторная работа № 8. Решение уравнений
и метод наименьших квадратов ......................................................... 172 
Список рекомендуемой литературы....................................................... 174 
Приложение 1. Параметры fminunc........................................................ 175 
Приложение 2. Параметры fmincon........................................................ 177 
Приложение 3. Параметры GlobalSearch и MultiStart........................... 180 
Приложение 4. Параметры Direct Search ............................................... 182 
Приложение 5. Параметры Simulated Annealing ................................... 184 
Приложение 6. Параметры Genetic Algorithm 
(ga и gamultiobj)........................................................................................ 185 
Приложение 7. Параметры fgoalattain и fminimax ................................ 187 
Приложение 8. Параметры quadprog...................................................... 189 
Приложение 9. Параметры fsolve ........................................................... 190 
5 
ВВЕДЕНИЕ
MATLAB (MATrix LABoratore) – одна из наиболее мощных систем компьютерной математики, построенная на расширенном применении матричных вычислений. Она включает пакеты расширения
Simulink, Toolbox и Blockset, ориентированные на самые разнообразные задачи, где требуются математические расчеты, глубокий анализ и
моделирование. 
MATLAB имеет развитый высокоуровневый язык программирования и прекрасную двумерную и трехмерную графику, позволяющую
наглядно представлять результаты расчетов, экспериментов и процессы моделирования. 
Пакеты расширения Toolbox (ящик инструментов) специализируются на решении задач в различных предметных областях: в физике
и астрономии, в специальных разделах математики и математическом
моделировании, в проектировании и управлении технических систем
и т.д. Основным инструментом MATLAB являются функции, которые
реализуют определенные операции и алгоритмы. Имеются встроенные
функции, в том числе все элементарные, и внешние, оформленные в
виде так называемых m-файлов. Внешние функции могут пополняться
собственными функциями пользователя. 
В расширения Toolbox входят два пакета, предназначенные для
решения задач оптимизации: Toolbox Optimization и Toolbox 
Global Optimization. Настоящее пособие посвящено описанию
этих пакетов. 
Первый пакет включает набор функций, в которых реализованы
методы и алгоритмы одномерной и многомерной безусловной и условной минимизации, линейного, булевого и квадратичного программирования, наименьших квадратов и решения уравнений, а также алгоритмы многокритериальной оптимизации. 
Функции пакета Global Optimization ориентированы на поиск
глобального минимума или многих минимумов. Здесь используются
методы прямого поиска, мультистарта, моделирования отжига, генетический алгоритм. В этот пакет также включена функция многокритериального генетического алгоритма. 
Пакеты предлагают два способа решения задач: с использованием
командной строки и с использованием графического пользовательско-
6 
го интерфейса (GUI). Второй способ проще, но уступает первому
в гибкости и функциональности. Режим командной строки предоставляет пользователю всю мощь системы MATLAB, поэтому в пособии
описывается использование именно этого режима решения задач. При
умении решать задачи в командном окне использование GUI не вызовет никаких затруднений (для обращения к нему в меню соответствующего Toolbox следует выбрать Optimtool). 
MATLAB, включая рассматриваемые пакеты, имеет мощную и
удобную систему помощи, содержащую многие тысячи страниц документации. Для быстрого доступа к интересующему объекту достаточно
набрать help и имя объекта, например оператора или функции. 
В пособии рассматриваются функции обоих пакетов, приводятся
многочисленные примеры их использования, во многих случаях они
сопровождаются наглядным графическим представлением результатов. 
Для практического освоения и использования методов оптимизации, 
реализованных в пакетах, предлагается выполнить восемь лабораторных работ, охватывающих большинство функций пакетов. 
Для тех, кто не работал с MATLAB, обратим внимание на два варианта некоторых арифметических операторов: традиционный оператор (*, ^, /), определяющий матричную операцию, и оператор с точкой
впереди (.*, .^, ./), задающий поэлементные действия с операндами. 
7 
1. ОДНОМЕРНАЯ МИНИМИЗАЦИЯ В MATLAB 
Toolbox Optimization содержит специальные функции, каждая
из которых ориентирована на определенный тип задачи оптимизации. 
Для одномерной минимизации непрерывных функций предназначена
функция пакета fminbnd. Решаемая задача имеет вид
min f(x), a < x < b. 
Алгоритм минимизации базируется на методах золотого сечения и
квадратичной аппроксимации (параболической интерполяции). 
Варианты обращения к функции fminbnd:
x = fminbnd(fun,x1,x2) 
x = fminbnd(fun,x1,x2,options) 
x = fminbnd(problem) 
[x,fval] = fminbnd(...) 
[x,fval,exitflag] = fminbnd(...) 
[x,fval,exitflag,output] = fminbnd(...)
Слева от знака равенства записываются выходные величины, и если их больше одной, то они перечисляются через запятую в квадратных скобках. Справа от имени функции в круглых скобках указываются входные величины (аргументы функции). В приведенных записях
приняты следующие обозначения: 
x – значение x, соответствующее локальному минимуму функции f(x); 
fval – значение f(x) в точке найденного локального минимума; 
exitflag – признак, идентифицирующий причину завершения алгоритма, его возможные значения: 
1 – сходимость алгоритма к минимуму; 
0 – число итераций превысило максимально установленное; 
–1 – причина в функции вывода (решение не достигнуто); 
–2 – границы несовместны. 
Output – структура, содержащая информацию о процессе, имеет поля: 
Iterations – число итераций; 
funcCount – число вычислений целевой функции; 
algorithm – используемый алгоритм; 
message – конечное сообщение. 
8 
Входные аргументы: 
fun – целевая функция, может быть определена как m-файл (m-функция), например: 
function f = myfun(x) 
f = sin(x^2); 
(файл сохраняется под именем myfun.m), и тогда на месте fun записывается @myfun, где myfun – имя функции и соответствующего ей
m-файла; также fun можно представить непосредственно формулой
(без использования имени) как конструкцию @(x)sin(x^2) или как
строковое выражение ‘sin(x^2)’; 
x1,x2 – значения левой и правой границ переменной x; 
options – опции алгоритма, исходно все установлены по умолчанию; 
применяетcя, если необходимо изменить какие-либо параметры оптимизации; при этом перед обращением к функции fminbnd вносятся
изменения в настройки опций options с помощью функции optimset, аргументами которой являются пары «имя параметра, устанавливаемое значение параметра», например установка
options=optimset(‘Display’, ‘off’) 
исключит вывод на экран (в командное окно) промежуточных данных. 
При значении 'iter' будут выводиться результаты каждой итерации. 
Другие значения параметра – 'final' и 'notify' (вывод итогов и
вывод только при отсутствии сходимости). Указание параметра 'Outputfcn', в качестве значения которого записывается имя функции, 
приводит к вызову этой функции на каждой итерации алгоритма. Значение параметра 'PlotFcn' определяет функцию вывода графики. 
В пакете это функции @optimplotx (рисует текущую точку),
@optimplotfunccount (выводит количество вычислений функции),
@optimplotfval (выводит текущее значение целевой функции). 
Функции вывода и графики могут быть написаны пользователем. При
включении параметра FunValCheck ('on') выводится сообщение при
возврате целевой функцией комплексного значения или Inf и NaN. 
Problem – сохраненное из GUI Optimization Tool описание задачи, а именно: 
f – целевая функция, 
x1 – левая граница, 
x2 – правая граница, 
9 
solver – 'fminbnd', 
options – структура параметров, создается optimset. 
Результатом выполнения функции fminbnd является локальное
решение (локальный минимум). 
Пример 1. 
Найти минимум функции y = x + 25/x в интервале 2 < x < 9. 
Для решения задачи в командное окно записываем программу: 
>> x=2:0.1:9;y=x+25./x; plot(x,y);xlabel('x'); ylabel('y');... 
title('Minimization by fminbnd');hold on; ... 
options=optimset('Outputfcn', @outmy);... 
[x,fval,exitflag,output]=fminbnd('x+25./x',2,9,options) 
Примечание. Многоточие позволяет перейти на следующую строку, иначе при нажатии Enter выполнится введенная перед ним часть
программы. Также многоточие позволяет разрывать выражение для
переноса на следующую строку. 
Пояснения к программе: в 1-й строке выводится график функции и
обозначения осей, во 2-й выводится заголовок и дается указание на
удержание графического окна, в 3-й функция outmy во время работы
алгоритма выводит точки, соответствующие итерациям, в то же графическое окно. Эта функция записана в виде m-файла
function stop = outmy(x,optimValues,state) 
stop = false; 
 switch state 
 case 'init' 
 hold on 
 case 'iter' 
 y=x+25./x; 
 plot(x,y,'red.'); 
 % Label points with iteration number. 
 text(x,y+.15,num2str(optimValues.iteration+1)); 
 case 'done' 
 hold off 
 end 
end 
Результаты выполнения программы, выводимые в командное и
графическое окна, представлены ниже и на рис. 1. 
10 
Рис. 1. Поиск минимума одномерной функции
x = 
 5.0000 
fval = 
 10.0000 
exitflag = 
 1 
output = 
iterations: 9 
funcCount: 10 
algorithm: 'golden section search, parabolic interpolation' 
message: [1x112 char] 
11 
2. БЕЗУСЛОВНАЯ МИНИМИЗАЦИЯ ФУНКЦИЙ
МНОГИХ ПЕРЕМЕННЫХ
Для поиска минимума нелинейной функции многих переменных
при отсутствии ограничений можно использовать функции fminunc
или fminsearch из пакета Toolbox Optimization. Рассмотрим каждую из них в отдельности. 
Предварительно заметим, что в MATLAB принято разделять алгоритмы оптимизации на алгоритмы для задач большой (Large Scale) 
и средней размерности (Medium Scale), причем это сделано довольно
условно. Основное отличие в том, что Large Scale учитывает разреженность матрицы и для ее хранения и операций с ней использует алгебру разреженных матриц. Алгоритмы Medium Scale имеют дело с
полными матрицами и оперируют соответствующей алгеброй. При
большой размерности задачи это требует много памяти и времени. Рекомендуется сначала выбирать Medium Scale, так как эти алгоритмы
имеют более широкие функциональные возможности. 
2.1. Функция fminunc
По умолчанию функция fminunc настроена на алгоритм Large 
Scale. Он базируется на методе доверительных областей (Trustregion method), т.е. последовательной аппроксимации целевой
функции в окрестности текущей точки более простой функцией, по которой находят следующее приближение к минимуму исходной функции. Алгоритм Large Scale требует задания градиента целевой
функции, иначе fminunc будет использовать Medium Scale. Чтобы
явно указать Medium Scale, следует в качестве аргумента функции
optimset записать 'largescale','off'. 
В алгоритме Medium Scale можно выбрать один из трех методов: 
квази-ньютоновкий метод BFGS (Бройдена – Флетчера – Голдфарба – 
Шэнно) или DFP (Дэвидона – Флетчера – Пауэлла) и метод наискорейшего спуска (steepest descent method). По умолчанию используется
метод BFGS, а для указания другого метода в опции нужно добавить
параметр 'HessUpdate' со значением 'dfp' или 'steepdesc'. 
Большинство параметров являются общими для Large Scale и
Medium Scale, но часть присуща только одному из них. Все параметры с краткими пояснениями и значениями по умолчанию приведены в
прил. 1. 
12 
Варианты обращения к функции fminunc: 
x = fminunc(fun,x0) 
x = fminunc(fun,x0,options) 
x = fminunc(problem) 
[x,fval] = fminunc(...) 
[x,fval,exitflag] = fminunc(...) 
[x,fval,exitflag,output] = fminunc(...) 
[x,fval,exitflag,output,grad] = fminunc(...) 
[x,fval,exitflag,output,grad,hessian] =fminunc(...) 
Смысл обозначений выходных аргументов: 
x и fval – вектор значений искомых переменных и значение целевой функции; 
exitflag – указывает причину завершения алгоритма, может
принимать следующие значения: 
1 – величина градиента меньше заданной точности TolFun, 
2 – изменения X меньше заданной точности TolX, 
3 – изменения f меньше заданной точности TolFun, 
5 – предсказанное уменьшение f меньше чем TolFun, 
0 – превышено максимальное число итераций или число вычислений f, 
–1 – алгоритм завершен функцией вывода (решение не получено); 
Grad – градиент целевой функции; 
Hessian – гессиан целевой функции; 
Output – структура, содержащая информацию о процессе в следующих полях: 
Iterations – число итераций, 
funcCount – значение целевой функции, 
firstorderopt – условие оптимальности 1-го порядка,
algorithm – использованный алгоритм, 
cgiterations – общее число итераций (для алгоритма большой
размерности), 
stepsize – заключительное смещение по X (для алгоритмов
средней размерности),
message – сообщение о завершении.
13 
Входные аргументы: 
fun – либо только целевая функция, либо функция, возвращающая значения целевой функции и ее градиента, либо функция, возвращающая значения целевой функции, ее градиента и гессиана; в первом
случае она может задаваться, как показано в гл. 1, а во втором случае – 
m-файлом с двумя выходными аргументами f и g, причем градиент g – 
векторный аргумент (элементы разделяются точкой с запятой). 
Пример: 
function [f,g] = myfun1(x) 
f = 2*x(1)^2+x(2)*x(1)+x(2)^3; 
g =[4*x(1)+x(2);x(1)+3*x(2)^2]; 
в третьем случае – также m-файлом с тремя выходными аргументами: 
function [f,g,H] = myfun2(x) 
f = ...; 
g = ...; 
H = ...;, 
где H – матрица вторых производных целевой функции. 
Чтобы аналитические выражения градиента и гессиана использовались в алгоритме, их необходимо включить в options:
options=optimset('GradObj','on') 
или options=optimset('GradObj','on',’Hessian’,’on’). 
В противном случае они будут вычисляться приближенно через конечные разности; 
x0 – начальная точка, задается пользователем; 
options – используется для внесения изменений в настройки параметров процесса; 
problem – задает задачу указанием
objective – целевая функция, 
x0 – начальная точка, 
solver –'fminunc' 
options – настройки параметров.
Следует иметь в виду, что в MATLAB выходные аргументы, как и
входные, могут указываться только в том порядке, который предписан
синтаксисом обращения к функции минимизации. Так, например, при
обращении к fminunc недопустима запись
[x,fval,output] = fminunc(...) 
из-за пропуска аргумента exitflag. 
14 
Пример 2. 
Найти минимум функции Розенброка
f(X)=100( 2 x – 2
1 x )
2 + ( 1 x –1)2
. 
Эта функция часто используется в качестве тестовой при сравнении эффективности разных алгоритмов, так как имеет сильно выраженную овражную структуру. Она достигает минимума в точке (1; 1). 
Программу запишем в виде функции runfminunc с вложенной
функцией outfun, обеспечивающей вывод x и fval на каждой итерации: 
function history = runfminunc(x0) 
% Set up shared variables with OUTFUN 
history.x = []; 
history.fval = []; 
% call optimization 
options = optimset('largescale','off',... 
'outputfcn',@outfun,'display','on'); 
[x,fval,exitflag,output]=fminunc(@rozen,x0,options); 
disp('Xopt=');disp(x);disp('fopt=');disp(fval); 
disp(output); 
[X,Y]=meshgrid(-4:0.05:4);Z=rozen_g(X,Y);[c,h]=contour... 
(X,Y,Z,[5 12 70 120 200 300 450 600 800],'blue'); 
clabel(c,h,[70 300 600],'FontSize',7); 
 y=history.x(:,1);z=history.x(:,2); 
 hold on;plot(y,z,'black.',y,z,'red-'); 
 xlabel('x1');ylabel('x2'); 
 text(x0(1)-0.1,x0(2)+0.2,'x0'); 
 title('Minimization by fminunc for Rozenbrok'); 
 function stop = outfun(x,optimValues,state) 
 stop = false; 
 switch state 
 case 'init' 
 hold off 
 case 'iter' 
 % Concatenate current point and objective 
 % function value with history. x must be a row 
 % vector. history.fval=[history.fval; 
% optimValues.fval]; 
 history.x = [history.x; x]; 
 end 
 end 
end 
15 
В этой программе функция Розенброка представлена в двух вариантах: как входной аргумент fminunc и для вырисовки ее контуров
(линий уровня). Им соответствуют m-файлы rozen и rozen_g,
приводимые ниже.
function f = rozen(x) 
f=100*(x(2)-x(1)^2)^2+(x(1)-1)^2; 
end 
function f = rozen_g(X,Y) 
f=100*(Y-X.^2).^2+(X-1).^2; 
end 
Примечание. Во втором варианте записи функции возведению в
степень предшествует точка, что означает поэлементное действие, 
иначе MATLAB будет выполнять матричную операцию и выдаст
ошибку. 
Теперь для выполнения программы достаточно ввести в командное окно начальную точку и обращение к программе: 
>> x0=[1 -3]; history = runfminunc(x0) 
и нажать ввод. Конечные результаты выводятся в командное окно, а
линии уровня и траектория поиска – в графическое окно (рис. 2). 
Численные результаты выполнения программы: 
Xopt= 
 0.9999 0.9998 
fopt= 
 8.3148e-009 
output= 
 iterations: 28 /число итераций
 funcCount: 105 /число вычислений функции
 stepsize: 1 /размер шага
 firstorderopt: 2.4548e-004 /оптимальность первого порядка
 algorithm: 'medium-scale: Quasi-Newton line search' 
 message: [1x438 char] 
history = 
 x: [29x2 double] 
 fval: [29x1 double] 
16 
Рис. 2. Траектория поиска минимума методом BFGS 
Как следует из отчета, функция fminunc по умолчанию использовала квазиньютоновский линейный алгоритм поиска минимума. 
Рис. 3. Пример «застревания» поиска
методом наискорейшего спуска
17 
Если в аргументы optimset добавить параметр 'HessUpdate'
со значением 'steepdesc', т.е. в качестве метода минимизации указать наискорейший спуск, то поиск из начальной точки (–2 2) застрянет
вдали от минимума (рис. 3). Он также не достигнет минимума и из
точки (1 –3). Причиной такого поведения метода является сильная овражность данной целевой функции. 
2.2. Функция fminsearch
В функции fminsearch для нахождения минимума используется
симплексный метод прямого поиска Нелдера – Мида. Изменение параметров производится посредством функции optimset. Параметры
fminsearch Display, FunValCheck, MaxFunEvals, MaxIter, 
OutputFcn, PlotFcns, TolFun и TolX идентичны одноименным
параметрам для функции fminunc. Отличие только в меньшем числе
функций графики: из перечисленных для fminunc в PlotFcns
(см. прил. 1) используются первые три. 
Обращение к функции возможно в следующих вариантах: 
x = fminsearch(fun,x0) 
x = fminsearch(fun,x0,options) 
x = fminsearch(problem) 
[x,fval] = fminsearch(...) 
[x,fval,exitflag] = fminsearch(...) 
[x,fval,exitflag,output] = fminsearch(...) 
Смысл входных и выходных аргументов такой же, как в функции
fminunc. Отличие в следующем. Fun может содержать только целевую функцию, и, соответственно, в выходных аргументах нет grad и
Hessian, а exitflag может принимать только следующие значения: 
1 – получено решение в результате сходимости процесса, 
0 – число итераций превысило допустимое значение, 
–1 – процесс остановлен функцией вывода (the output function). 
Пример 3. 
Найти минимум функции Розенброка
f(X) = 100( 2 x – 2
1 x )
2 + ( 1 x –1)2
с помощью fminsearch. 
18 
Запишем программу, как и в п. 2.1, в виде функции
function history = runfminsearch(x0), 
описание которой совпадает с приведенным для функции runfminunc, в нем заменяется только fminunc на fminsearch. 
В командную строку заносим
>>x0=[1 –3];history = runfminsearch(x0), 
нажимаем Enter и получаем результаты в численном и графическом
виде (рис. 4). 
Рис. 4. Траектория поиска минимума методом Нелдера – Мида
Xopt= 
 1.0000 1.0000 
fopt= 
 3.1666e-010 
Output= 
 iterations: 56 
 funcCount: 105 
 algorithm: 'Nelder-Mead simplex direct search' 
 message: [1x196 char] 
19 
Сравнивая результаты поиска fminunc и fminsearch из одной
начальной точки (1 –3), видим, что во втором случае потребовалось в
два раза больше итераций, но число вычислений функции оказалось
одинаковым. Если начать поиск с точки (–2 2) 
>> x0=[-2 2];history = runfminsearch(x0), 
то получим следующие результаты: 
Xopt= 
 1.0000 1.0000 
fopt= 
 3.9243e-010 
Output= 
 iterations: 112 
 funcCount: 208 
 algorithm: 'Nelder-Mead simplex direct search' 
 message: [1x196 char] 
Рис. 5. Поиск методом Нелдера – Мида из точки (–2 2) 
Как видно из отчета и рис. 5, симплексный метод в отличие от метода наискорейшего спуска сходится к минимуму с высокой точностью. 
20 
Лабораторная работа № 1 
Одномерная и безусловная оптимизация
Задания: 
1. Ознакомиться с возможностями функций Toolbox Optimization для решения задач одномерной и безусловной многомерной минимизации и с методами, заложенными в них. 
2. Воспроизвести пример 1, повторить с заменой числа 25 на 38; 
найти минимум этой же целевой функции без использования графики. 
3. Найти минимум функции y = exp(sin(x)) + exp(–x) на интервале
(–0,5pi, 3pi) без графики и с графикой. 
4. Воспроизвести пример 2. Повторить для разных начальных точек, одна из которых (–2 2). 
5. На функции Розенброка исследовать поведение метода наискорейшего спуска при разных начальных точках. 
6. Для функции Розенброка применить метод DFP, используя несколько начальных точек. 
7. Воспроизвести пример 3 и исследовать поведение метода Нелдера – Мида при разных начальных точках. 
8. Найти максимум функции 22 2
21 1
10 . 30( ) 5(1,5 ) 1 y
xx x    
9. Сделать выводы по применимости исследованных алгоритмов
оптимизации. 
21 
3. УСЛОВНАЯ ОПТИМИЗАЦИЯ
Для поиска минимума функции многих переменных при наличии
ограничений предназначена функция fmincon из пакета Toolbox. 
Фактически с помощью этой функции можно решать задачи нелинейного математического программирования (НМП) в самой общей постановке. В обозначениях MATLAB задача НМП ставится так: 
min f(X) 
при условиях
C(X)  0, ceq(X) = 0, 
AX  b, AeqX = beq, 
lb  X  ub, 
где X – вектор переменных: C(X) и ceq(X) – вектор-функции левых частей нелинейных неравенств и равенств; A и Aeq – матрицы условий линейных неравенств и равенств; b и beq – векторы свободных членов
(правых частей) линейных неравенств и равенств; lb и ub – векторы
нижних и верхних границ на переменные. Очевидно, что в частных постановках задач НМП некоторые из представленных условий могут
отсутствовать. 
В связи с многообразием задач НМП функция fmincon реализует
не один, а четыре метода условной минимизации. Рассмотрим кратко
эти методы. 
Метод доверительных областей (Trust Region). Доверительной областью названа окрестность N текущей точки поиска, размеры
которой могут изменяться в зависимости от поведения целевой функции. В этой области целевая функция f(x) аппроксимируется более
простой функцией q(s), затем решается подзадача, заключающаяся в
поиске минимума функции q(s) на N, в результате находится пробный
шаг s. Если окажется, что f(x + s) < f(x), текущая точка изменяется и
становится равной x + s, в ином случае текущая точка не изменяется, 
доверительная область уменьшается и заново решается подзадача (находится новый пробный шаг). 
В стандартном методе доверительных областей используется квадратичная аппроксимация, определяемая членами только первого и второго порядка ряда Тейлора для f(x), а в качестве N – сфера или эллипсо-
22 
ид. Для нахождения минимума квадратичной функции (решения подзадачи) существуют хорошие алгоритмы (ньютоновские и др.), однако при
большой размерности они требуют слишком много времени. Поэтому
подход, примененный в Toolbox Optimization, состоит в ограничении подзадачи двумерным подпространством S. Очевидно, что в таком
случае решение подзадачи становится тривиальным. Решатель определяет S как линейное пространство, натянутое на векторы s1 и s2, где s1 – 
направление градиента G аппроксимируемой функции, а s2 – направление, определяемое или как приближенное направление Ньютона из решения линейной системы
2 Hs G   ,
в которой H – матрица Гессе, или как направление отрицательной кривизны поверхности целевой функции из неравенства
2 2 0. T
s Hs 
В первом случае решение системы равенств находится предобусловленным методом сопряженных градиентов PCG (Preconditioned 
Conjugate Gradient Method). 
Таким образом, при решении задачи без ограничений основными
шагами алгоритма будут: 
1) формулировка двумерной подзадачи доверительной области; 
2) решение подзадачи и определение s; 
3) если f(x + s) < f(x), тогда x = x + s; 
4) корректировка доверительной области. 
Шаги повторяются до установления сходимости. Задача усложняется при наличии ограничений. Если ограничения описываются линейной системой равенств, метод на каждой итерации генерирует допустимое решение. Для получения допустимой начальной точки применяется шаг метода наименьших квадратов, на последующих шагах
линейные системы решаются упрощенным методом сопряженных градиентов (PCG заменен на Reduce PCG). При двухсторонних ограничениях на переменные также генерируются только строго допустимые
решения, для чего используются соответствующие необходимые условия Куна – Таккера. 
Метод доверительных областей эффективен для решения больших
разреженных задач или средних плотных задач с двухсторонними ограничениями на переменные или только с линейными ограничениями. 
Алгоритм требует задания градиента целевой функции и указания на
его включение в optimset. 
23 
Метод активного набора (Active Set). Сегодня методы, основанные на решении уравнений Каруша – Куна – Таккера (ККТ), считают более эффективными, чем методы типа штрафных функций. Для
задач выпуклого НМП условия ККТ являются одновременно необходимыми и достаточными для точки глобального решения. 
Для общей задачи НМП, представляемой как
min f(X) 
Gi(x) = 0, i = 1, ..., me, 
Gi(x) ≤ 0, i = me + 1, ..., m, 
условия Куна – Таккера записываются в следующем виде: 
* *
*
( ) ( ) 0,
( ) 0, 1, ,
0, 1, .
m
i i
i
i i
i e
fx Gx
Gx i m
im m
   
 
  

Первое уравнение описывает взаимосвязь градиента целевой функции
с градиентами активных ограничений: первый уравновешивается градиентами ограничений с весами i – множителями Лагранжа. Множители неактивных ограничений равны нулю, что выражается вторым
уравнением; положительными могут быть только множители активных
ограничений. 
Решение уравнений ККТ составляет основу многих алгоритмов нелинейного программирования. Используемые для их решения квазиньютоновские методы с процедурой обновления обеспечивают сверхлинейную скорость сходимости. Основная идея метода активного набора состоит в квадратичной аппроксимации функции Лагранжа. В таком
варианте метод часто упоминается как последовательное квадратичное
программирование (SQP). На каждой итерации методом квадратичного
программирования решается квадратичная подзадача, определяющая направление спуска, а шаг в этом направлении находится методом линейного поиска минимума штрафной функции. Для обновления матрицы, аппроксимирующей гессиан функции Лагранжа, и обеспечения ее положительной определенности применяется метод BFGS. 
24 
Алгоритм активного набора не предназначен для больших задач. Он
эффективен для некоторых задач средней размерности с негладкими ограничениями. Для повышения скорости он может делать большие шаги. 
Алгоритм последовательного квадратичного программирования. 
Он подобен методу активного набора, однако имеет важные отличия. 
Во-первых, SQP соблюдает строгую допустимость относительно заданных границ. На каждой итерации делается шаг в области, определяемой
границами. И завершающие изменения шагов также соблюдают границы. При нестрогих границах может быть сделан шаг точно на границу. 
Такая строгая допустимость выгодна, когда целевая функция или функции нелинейных ограничений неопределенны или сложны вне границ. 
Во-вторых, алгоритм обеспечивает робастность движения: при неудачном шаге, когда функция или функции задачи оказываются неопределенными (они возвращают значения Inf, NaN), алгоритм пытается
уменьшить шаг. В-третьих, SQP отличается от алгоритма Active Set
использованием более эффективных программ линейной алгебры, которые вызываются при решении квадратичной подзадачи. Наконец, в SQP
реализованы два новых подхода к решению подзадачи квадратичного
программирования в случае невыполнения ограничений. Алгоритм использует функцию качества, которая образуется комбинацией целевой
функции и ограничений. Минимизация функции качества приводит к
допустимому решению, однако из-за увеличения числа переменных может замедлиться решение подзадачи. Второй подход к устранению нарушения ограничений связан с квадратичной аппроксимацией функций
ограничений. Он также позволяет достичь допустимого решения, но
требует большего числа вычислений функций ограничений, что приводит к замедлению процесса решения подзадачи квадратичного программирования. 
Алгоритм SQP применяется для решения задач средней размерности. 
Метод внутренней точки (Interior-point). Суть метода заключается в решении последовательности аппроксимирующих задач. 
Для общей задачи НМП 
min ( ) x f x
при условиях
hx gx ( ) 0, ( ) 0  
25 
аппроксимирующая задача для каждого  > 0 имеет вид
, min ( , )
x s f x s   , min( ( ) ln( )) i x s i
f x s  
при условиях
hx gx s ( ) 0, ( ) 0.   
Каждому ограничению-неравенству исходной задачи соответствует положительная переменная si в аппроксимирующей задаче. При
стремлении  к нулю минимум f должен приближаться к минимуму f. 
Добавленный к целевой функции член называется барьерной функцией. 
Как видно, аппроксимирующая задача представляет собой последовательность задач с ограничениями-равенствами, и ее решение найти
легче, чем исходной задачи с неравенствами. 
На каждой итерации используется один из двух основных типов
шагов: 
1) прямой шаг в пространстве (x, s) для решения ККТ уравнений
аппроксимирующей задачи путем их линейной аппроксимации; такой
шаг называется шагом Ньютона; 
2) CG-шаг (conjugate gradient – сопряженный градиент) с использованием доверительной области. 
По умолчанию сначала делается попытка выполнить прямой шаг. 
Если он невозможен, алгоритм пытается сделать CG-шаг. Неудача прямого шага может быть обусловлена локальной невыпуклостью решаемой задачи вблизи текущей точки. На каждой итерации алгоритм
уменьшает функцию качества, например такую, как
f(x,s) + ν||(h(x), g(x)+s)||. 
Параметр ν может увеличиваться по ходу итераций для продвижения
решения к допустимой области. Если предпринятый шаг не уменьшает
функцию качества, алгоритм отклоняет его и пытается сделать новый
шаг. Если в точке xj функции возвращают комплексное значение, NaN, 
Inf или ошибку, xj отвергается (как в случае недостаточного уменьшения функции качества) и делается другой, более короткий шаг. В начальной точке подобное недопустимо. 
Метод внутренней точки применяется для решения задач как
большой, так и средней размерности. Если в опциях не указан конкретный алгоритм и применение алгоритма по умолчанию, т.е. Trust 
26 
Region, к решаемой задаче невозможно, программа обращается к алгоритму внутренней точки. 
Процесс оптимизации определяется не только выбранным алгоритмом, но и значениями параметров. Изменение параметров осуществляется с помощью функции optimset. Часть параметров относится
ко всем алгоритмам, и каждый алгоритм имеет еще свои индивидуальные параметры. Все параметры fmincon и их описание приведены в
прил. 2. 
Одним из существенных параметров является 'Hessian', устанавливающий способ вычисления гессиана. Все алгоритмы, исключая
SQP, используют гессиан функции Лагранжа
22 2 2 ( , ) ( ) ( ) ( ). L ii i i        x f x C x ceq x  
Алгоритмы вычисляют гессиан по-разному. Алгоритм activeset не использует пользовательский гессиан, а вычисляет его методом квазиньютоновской аппроксимации. Алгоритм trust-regionreflective может принимать гессиан, заданный пользователем. Поскольку этот алгоритм не предназначен для нелинейных ограничений, 
гессиан функции Лагранжа совпадает с гессианом целевой функции и
описывается вместе с ней. Алгоритм interior-point воспринимает
гессиан, заданный пользователем в виде отдельной функции, описание
которой имеет вид
hessian = hessianfcn(x, lambda) 
hessianfcn=гессиан Лагранжа, 
где hessian квадратная матрица n×n, lambda – множители Лагранжа, соответствующие нелинейным ограничениям. Пользовательская
функция указывается в optimset: 
options = optimset('Hessian','user-supplied',... 
'HessFcn',@hessianfcn). 
В алгоритме interior-point можно выбрать способ вычисления гессиана из пяти вариантов, задаваемых как значение параметра
'Hessian': 'bfgs' – посредством квазиньютоновской аппроксимации; {'lbfgs',positive integer})– то же, но с ограниченной памятью на сохранение числа прошедших итераций (целое число); 
'lbfgs'– то же, но память на 10 итераций; 'fin-diff-grads'– конечными разностями градиентов, при этом все градиенты задаются
аналитически; 'user-supplied'– способ задает пользователь. 
27 
Теперь рассмотрим способы использования функции fmincon, ее
входные аргументы и возвращаемые величины (выходные аргументы). 
Обращение к функции fmincon записывается в одном из следующих возможных вариантов: 
x = fmincon(fun,x0,A,b) 
x = fmincon(fun,x0,A,b,Aeq,beq) 
x = fmincon(fun,x0,A,b,Aeq,beq,lb,ub) 
x = fmincon(fun,x0,A,b,Aeq,beq,lb,ub,nonlcon) 
x = fmincon(fun,x0,A,b,Aeq,beq,lb,ub,nonlcon,options) 
x = fmincon(problem) 
[x,fval] = fmincon(...) 
[x,fval,exitflag] = fmincon(...) 
[x,fval,exitflag,output] = fmincon(...) 
[x,fval,exitflag,output,lambda] = fmincon(...) 
[x,fval,exitflag,output,lambda,grad] = fmincon(...) 
[x,fval,exitflag,output,lambda,grad,hessian] = ... 
fmincon(...)
Смысл большинства входных аргументов ясен из описания задачи
НМП и функции fminunc. В частности, fun задается функцией, которая может возвращать значение как целевой функции, так и градиента
и гессиана, если это необходимо. Отличие только в присутствии нового аргумента nonlcon,который представляет нелинейные условия задачи в виде m-файла, например
function [c,ceq] = mycon(x) 
c = ...; 
ceq = ...; 
В этом случае в качестве nonlcon следует записать @mycon. Если равенств и неравенств больше одного, то c и ceq записываются как векторы. При отсутствии равенств или неравенств в правой части соответствующего выражения записывается []. В MATLAB при записи матрицы (вектора) элементы строки разделяются пробелом или запятой, а
строки отделяются точкой с запятой или записываются в разных строках матрицы (вектора). Так, неравенства
3
1 2
2
1 2
2 5,
12
x x
x x
 
 
в m-файле будут представлены в виде
c =[2*x(1)^3-x(2)-5;x(1)+x(2)^2-12];. 
28 
Если нужно указать конкретный алгоритм, то в опции (в optimset) записывается параметр 'Algorithm' со значением 'interiorpoint' либо 'sqp', либо 'active-set'. По умолчанию применяется
алгоритм 'trust-region-reflective' и, если он не подходит (не
задан градиент целевой функции или не соответствует тип ограничений), программа заменяет его на interior-point. 
Выходные аргументы fmincon отличаются от аргументов fminunc значениями exitflag, структурой output и новым аргументом
lambda. Значение exitflag указывает на причину завершения алгоритма: 
а) для всех алгоритмов
1 – мера оптимальности первого порядка стала меньше установленной в options.TolFun и максимальное нарушение ограничений
меньше options.TolCon (получено решение с заданной точностью),
0 – превышено максимальное число итераций (options.MaxIter) или вычислений функции (options.FunEvals), 
–1 – алгоритм завершен функцией output, 
–2 – не найдено допустимой точки; 
б) для алгоритмов доверительных областей и внутренней точки
2 – изменение в X меньше установленного в options.TolX и
максимальное нарушение ограничений меньше options.TolCon
(получено решение с заданной точностью); 
в) только для алгоритма доверительных областей
3 – изменение целевой функции меньше options.TolFun и максимальное нарушение ограничений меньше options.TolCon (получено решение с заданной точностью); 
г) только для алгоритма активного набора
4 – величина направления поиска меньше 2*options.TolX и
максимальное нарушение ограничений меньше options.TolCon
(получено решение с заданной точностью), 
5 – величина производной по направлению прямого поиска меньше 2*options.TolFun и максимальное нарушение ограничений
меньше options.TolCon (получено решение с заданной точностью); 
д) только для алгоритма внутренней точки
29 
–3 – текущая точка X ниже величины options.ObjectiveLimit
и максимальное нарушение ограничений меньше options.TolCon
(получено решение с заданной точностью). 
Структура Output содержит поля iterations, funcCount, 
lssteplength (в алгоритме активного набора), constrviolation, 
stepsize (оба в алгоритмах активного набора и внутренней точки), 
algorithm, cgiterations (в алгоритмах доверительных областей и
внутренней точки), firstorderopt, message. Пояснения требуют
только новые поля: lssteplength – размер шага линейного поиска
относительно направления поиска, constrviolation – максимальное
значение функций ограничений (величина нарушения ограничений). 
Lambda – структура, содержащая множители Лагранжа, отражающие влияние ограничений в оптимальном решении; состоит из полей, соответствующих определенным ограничениям: 
Lower – нижняя граница (lb), 
Upper – верхняя граница (ub), 
Ineqlin – линейные неравенства, 
Eqlin – линейные равенства, 
Ineqnonlin – нелинейные неравенства, 
Eqnonlin – нелинейные равенства. 
Рассмотрим несколько примеров применения функции fmincon. 
Пример 4. 
Найти минимум функции
f(X) = 4 2
1 12 (2 ) (2 )  x x x
при условиях
3x1 + x2  8, 
–x1 + x2  3. 
Сначала создадим m-файлы с именами primfun и primfun_g для
вычисления целевой функции в процессе минимизации и построения
контуров: 
function f = primfun(x) 
f=(2-x(1))^4+(2*x(1)-x(2))^2; 
end 
30 
function f = primfun_g(x,y) 
f=(2-x).^4+(2*x-y).^2; 
end 
Выпишем входные аргументы линейных ограничений: 
31 8 , . 11 3
A b           
Затем составим программу нахождения минимума и прорисовки
линий уровня, границ допустимой области и траектории поиска в виде
функции runfmincon0. В качестве алгоритма укажем 'interiorpoint', а для получения точек траектории напишем функцию outfun
(укажем ее как значение параметра 'outputfcn'). 
function history = runfmincon0(x0) 
 % Set up shared variables with OUTFUN 
 history.x = []; 
 history.fval = []; 
 % call optimization 
A=[3 1;-1 1];b=[8;3]; 
[X,Y]=meshgrid(0:0.02:3.5,0:0.02:6);Z=primfun_g(X,Y); 
[c,h]=contour(X,Y,Z,[0.007 0.025 0.1 0.5 2 5 10 15 ... 
20 27 35 45],'blue'); 
clabel(c,h,[0.5 5 15 27],'FontSize',7); 
hold on;plot([8/3 1.25],[0 4.25],'g-','linewidth',2.3); 
plot([0 1.25],[3 4.25],'g-','linewidth',2); 
text(1,1.8,'The feasible region'); 
xlabel('x1'); ylabel('x2'); text(x0(1),x0(2)+0.2,'x0'); 
title('Minimization by fmincon'); 
options = optimset('outputfcn',@outfun,'display',... 
'off','Algorithm','interior-point'); 
[x,fval,exitflag,output]=fmincon(@primfun,x0,A,b,... 
[],[],[],[],[],options) 
 y=history.x(:,1);z=history.x(:,2); 
 hold on;plot(y,z,'b.',y,z,'r-'); 
31 
function stop = outfun(x,optimValues,state) 
 stop = false; 
 switch state 
 case 'init' 
 hold on 
 case 'iter' 
 % Concatenate current point and objective 
 % function 
 history.fval = [history.fval;... 
optimValues.fval]; 
 history.x = [history.x; x]; 
 end 
 end 
end 
Вводим в командную строку
>> x0=[3 2];history=runfmincon0(x0) 
и получаем результаты в численном и графическом виде (рис. 6): 
x = 
 1.6049 3.1852 
fval = 
 0.0250 
exitflag = 
 1 
output = 
 iterations: 13 
 funcCount: 43 
 constrviolation: 0 
 stepsize: 5.6982e-007 
 algorithm: 'interior-point' 
 firstorderopt: 4.0000e-007 
 cgiterations: 0 
 message: [1x782 char] 
32 
Рис. 6. Поиск минимума алгоритмом внутренней точки
Эти данные и рис. 6 показывают, что с заданной точностью достигнут локальный минимум на границе допустимой области в точке
x1 = 1,6049, x2 = 3,1852 и с оптимальным значением целевой функции
0,025. 
Заменив в optimset значение параметра Algorithm c interiorpoint на sqp, повторим поиск из той же начальной точки. Данные, 
представленные ниже, и рис. 7 показывают, что алгоритмом SQP минимум находится значительно быстрее. 
>> x0=[3 2];history=runfmincon0(x0) 
x = 
 1.6049 3.1852 
fval = 
 0.0250 
exitflag = 
 1 
output = 
 iterations: 5 
 funcCount: 21 
 algorithm: 'sequential quadratic programming' 
33 
 message: [1x782 char] 
 constrviolation: 0 
 stepsize: 1 
 firstorderopt: 5.6766e-007 
Рис. 7. Поиск минимума методом последовательного
квадратичного программирования
Для точного вычисления градиента, используемого при минимизации, он задается аналитически в аргументе fun. Так, в рассмотренном выше примере функция primfun должна быть дополнена выражением градиента g: 
function [f,g] = primfun(x) 
f=(2-x(1))^4+(2*x(1)-x(2))^2; 
g=[-4*(2-x(1))^3+4*(2*x(1)-x(2));-2*(2*x(1)-x(2))]; 
end 
и в опции добавлен параметр ‘Gradobj’ со значением ‘on’. 
В следующем примере рассмотрим задачу с нелинейными ограничениями. 
34 
Пример 5. 
Найти минимум функции
f(X) = 4 2
1 12 (2 ) (2 )  x x x
при условиях
1,25(x1 –3,5)2
+ x2  5, 
1 12 0,75 / 1,5 2 0. x xx   
Нелинейные ограничения представим в m-файле с именем primcon: 
function [c,ceq] = primcon(x) 
%Primer for fmincon 
c=[1.25*(x(1)-3.5)^2+x(2)-5;0.75/x(1)+x(2)-... 
1.5*sqrt(2*x(1))]; 
ceq=[]; 
end 
Снова составим программу минимизации и прорисовки линий
уровня, границ допустимой области и траектории поиска в виде функции runfmincon00. 
function history = runfmincon00(x0) 
history.x = []; 
history.fval = []; 
[X,Y]=meshgrid(0:0.02:3.5,0:0.02:6);Z=primfun_g(X,Y); 
contour(X,Y,Z,[ 0.007 0.025 0.1 0.5 2 5 10 15 20 27 ... 
35 45],'blue'); 
x=1.5:0.01:2.17; y=-1.25*(x-3.5).^2+5; hold on; 
plot(x,y,'g-','linewidth',2.3); x=2.17:0.01:3.5; 
y=1.5*sqrt(2*x)-0.75./x;hold on;plot(x,y,... 
'g-','linewidth',2); 
text(2.5,2,'The feasible region'); 
xlabel('x1'); ylabel('x2'); 
title('Minimization by fmincon'); 
options = optimset('outputfcn',@outfun,'display',... 
'off', 'Algorithm', 'sqp'); 
[x,fval,exitflag,output]=fmincon(@primfun,x0,[],[],... 
[],[],[],[],@primcon,options) 
35 
 y=history.x(:,1);z=history.x(:,2); 
 hold on;plot(y,z,'b.',y,z,'r-'); 
function stop = outfun(x,optimValues,state) 
 stop = false; 
 switch state 
 case 'init' 
 hold on 
 case 'iter' 
 history.fval = [history.fval;... 
optimValues.fval]; 
 history.x = [history.x; x]; 
 end 
 end 
end 
Здесь следует обратить внимание на входные аргументы функции
fmincon. 
После ввода и выполнения команды
>> x0=[0.5 4];history = runfmincon00(x0) 
имеем нижеприведенные результаты и график траектории (рис. 8): 
x = 
 2.1661 2.7758 
fval = 
 2.4229 
exitflag = 
 1 
output = 
 iterations: 5 
 funcCount: 24 
 algorithm: 'sequential quadratic programming' 
 message: [1x782 char] 
 constrviolation: 1.9114e-012 
 stepsize: 1 
 firstorderopt: 6.5533e-008 
36 
Рис. 8. Поиск условного минимума алгоритмом SQP
при нелинейных ограничениях
Как видно из рис. 8, оптимальное решение достигается снова на
границе допустимой области. 
В случае нелинейных ограничений помимо градиента целевой
функции могут быть заданы градиенты ограничений в m-файле ограничений, и тогда для их использования необходимо добавить в опции
параметр ‘Gradconstr’ со значением ‘on’. 
В приведенных примерах с fmincon решались задачи с одноэкстремальными целевыми функциями. Теперь рассмотрим пример поиска минимума многоэкстремальной функцией при двухсторонних ограничениях на переменные. 
Пример 6. 
Найти минимум функции
f = 3(1– x1)
2
exp (– 2
1 x – (x2 + 1)2
) –10(x1/5 – 3
1 x – 5
2 x )exp (– 2
1 x – 2
1 x ) – 
–1/3exp (– (x1 + 1)2 – 2
2 x ) 
на параллелепипеде
–3  xj  3, j = 1, 2. 
37 
Для решения этой задачи сначала запишем в m-файл целевую
функцию
function f=myfun(x) 
f=3*(1-x(1))^2*exp(-x(1)^2-(x(2)+1)^2)-10*(x(1)/5.... 
-x(1)^3-x(2)^5)*exp(-x(1)^2-x(2)^2)-1/3*exp(-(x(1)... 
+1)^2-x(2)^2); 
end 
Затем составляем программу поиска минимума и отображения целевой функции, ее линий уровня и траектории поиска в виде функции
от начальной точки: 
function history = runfmincon5_1(x0) 
history.x = []; 
history.fval = []; 
% call optimization 
options = optimset... 
('outputfcn',@outfun,'display','off','Algorithm',... 'interior-point'); 
[x,fval,exitflag,output]= fmincon(@myfun,x0,[],[],[],... 
[],[-3 -3],[3 3],[],options) 
 [X,Y]=meshgrid(-3:0.02:3);Z=3*(1-X).^2.*exp(-X.^2- ... 
(Y+1).^2)-10*(X/5 ... 
-X.^3-Y.^5).*exp(-X.^2-Y.^2)-1/3*exp(-(X+1).^2-Y.^2); 
meshc(X,Y,Z); 
 y=history.x(:,1);z=history.x(:,2);v=history.fval; 
 hold on;plot3(y,z,v,'black.',y,z,v,'red-'); 
 v=-10*ones(size(z));hold on;plot3(y,z,v,'red-'); 
 xlabel('x1'); ylabel('x2');zlabel('f'); 
 title('Sequence of Points Computed by fmincon'); 
 function stop = outfun(x,optimValues,state) 
 stop = false; 
 switch state 
 case 'init' 
 hold off 
 case 'iter' 
 % Concatenate current point and objective function 
 history.fval = [history.fval; optimValues.fval]; 
 history.x = [history.x; x]; 
 end 
 end 
end 
После ввода и выполнения команды
>> x0=[1 1]; history = runfmincon5_1(x0) 
38 
получаем
x = 
 0.2283 -1.6255 
fval = 
 -6.5511 
exitflag = 
 1 
output = 
 iterations: 16 
 funcCount: 56 
 constrviolation: 0 
 stepsize: 4.8893e-008 
 algorithm: 'interior-point' 
 firstorderopt: 1.2023e-007 
 cgiterations: 0 
 message: [1x782 char] 
На рис. 9 показан процесс поиска минимума. Как видно из представленных результатов, он оказался успешным. 
Рис. 9. Вид целевой функции и траектория движения к минимуму
Однако этот результат следует считать случайным, так как случайно выбрана данная начальная точка. 
39 
Повторив поиск из другой начальной точки, получаем
>> x0=[-0.5 3]; history = runfmincon5_1(x0) 
x = 
 -2.9984 2.9976 
fval = 
 3.2869e-005 
exitflag = 
 1 
output = 
 iterations: 27 
 funcCount: 84 
 constrviolation: 0 
 stepsize: 7.2753e-004 
 algorithm: 'interior-point' 
 firstorderopt: 3.2032e-007 
 cgiterations: 0 
 message: [1x782 char] 
Из показателей поиска (признака exitflag, критериев точности) 
как будто следует, что получено решение задачи. На самом деле поиск
завершился даже не в точке одного из локальных минимумов, что хорошо видно на рис. 10. 
Рис. 10. Поиск минимума из точки (–0,5 3) 
40 
Примечание. В Toolbox Optimization имеется функция
rtrlink, по функциональности аналогичная fmincon. Она применима
для решения задач без ограничений и с линейными и нелинейными ограничениями. В ней также используются алгоритмы active-set и
interior-point. Однако она требует установки самостоятельной
библиотеки KNITRO, к которой происходит обращение при вызове
rtrlink. 
Повышение надежности отыскания минимума многоэкстремальной функции требует применения методов глобального поиска. Некоторые из них, включенные в MATLAB, рассматриваются в следующем
разделе. 
Лабораторная работа № 2 
Условная оптимизация
Задания
1. Ознакомиться с вариантами обращения к функции fmincon, ее
входными и выходными аргументами. 
2. Воспроизвести пример 4, исследовать работу трех алгоритмов
из разных начальных точек, принадлежащих и не принадлежащих допустимой области. 
3. То же в условиях примера 5. Кроме того, повторить нахождение
минимума для одной начальной точки без использования графики. 
4. Найти минимум функции из примера 5 при условиях, включающих ограничения из примеров 4 и 5. 
5. Воспроизвести пример 6 и исследовать работу всех алгоритмов
fmincon из нескольких начальных точек. Найти максимум этой же целевой функции, используя разные алгоритмы. 
6. Провести анализ результатов работы алгоритмов. 
41 
4. ГЛОБАЛЬНАЯ ОПТИМИЗАЦИЯ
В последних версиях MATLAB появился специализированный пакет Global Optimization Toolbox, предназначенный для решения
задач глобальной оптимизации. Он включает методы GlobalSearch
(глобальный поиск), Multistart (мультистарт), Genetic Algorithm
(генетический алгоритм), Direct Search (прямой поиск) и Simulated Annealing (моделирование отжига). Этот пакет применим, когда функции цели или ограничения непрерывны или имеют разрывы, 
возможно стохастические, могут не иметь производных или включают
функции моделирования или черного ящика с некоторыми неопределенными параметрами настройки. Но ни один из методов пакета не содержит критериев, позволяющих сертифицировать найденное решение
как глобальное. 
В отличие от методов локальной оптимизации не все перечисленные методы поиска глобального минимума представлены соответствующими функциями. К некоторым из них обращение идет путем создания задачи (problem) с последующим исполнением специальной
командой. Ниже рассматриваются команды и функции, позволяющие
использовать вышеназванные методы. Но сначала дается краткое описание соответствующего метода или алгоритма. 
4.1. Метод GlobalSearch
Предполагается, что целевая функция и функции ограничений являются гладкими. Алгоритм, реализующий метод GlobalSearch, 
включает ряд последовательных шагов. На первом шаге запускается
локальный решатель fmincon с заданной начальной точкой x0. Если
получена сходимость, то запоминаются начальная и конечная точки и
достигнутое значение целевой функции, используемое в функции счета
(the score function). Функция счета определяется как сумма значения целевой функции и произведения множителя на сумму нарушений ограничений в данной точке. Если точка допустимая, то значение
функции счета равно значению целевой функции. Начальное значение
множителя равно 1000, но в процессе поиска оно обновляется. На втором шаге генерируется множество пробных точек NumTrialPoints – 
потенциально стартовых точек. Для этого используется алгоритм Гловера, подобный алгоритму случайного поиска (точки должны быть
рассеяны, их компоненты лежат в диапазоне –e4+1, e4+1)). Далее вы-
42 
полняется стадия 1 (Stage 1): во всех пробных точках стадии 1 (их
число задается параметром NumStageOnePoints как часть
NumTrialPoints) вычисляется функция счета и выбирается лучшая
точка, из которой запускается fmincon, а все остальные точки удаляются из общего списка пробных точек. Затем инициализируются области притяжения (бассейны), счетчики и порог. Значение порога локального решателя (localSolverThreshold) первоначально равно
минимуму их двух значений целевой функции в точках решений, полученных из начальной точки x0 и из лучшей пробной точки. В качестве начальных бассейнов принимаются две сферические области с
центрами в точках двух полученных fmincon решений с радиусами, 
равными расстояниям от начальной точки до точки решения. В алгоритме используются два типа счетчиков, считающих число последовательно исследованных пробных точек: 1) оказавшихся в бассейне (для
каждого бассейна один такой счетчик); 2) у которых функция счета
больше порога. Все счетчики первоначально равны 0. 
Далее выполняется основной цикл алгоритма, в котором исследуются оставшиеся от первой стадии пробные точки, определяются стартовые и из них проводится локальный поиск. На стадии 2 (Stage 2) 
берется очередная пробная точка p. Если она не лежит в существующих бассейнах, ее функция счета лучше порога и, возможно, она удовлетворяет установленным границам и/или неравенствам, то из нее запускается fmincon (запускать ли из всех точек или только удовлетворяющих ограничениям, определяет параметр StartPointsToRun). 
При этом счетчики бассейнов и порога обнуляются, а множество решений обновляется. Если установлена сходимость поиска из точки p, 
полученное решение xp сравнивается со всеми уже имеющимися решениями по расстоянию между точками и/или по разности значений целевых функций. Если они больше заданных величин, которые можно
изменять параметрами TolX и/или TolFun, то в множество решений
GlobalOptimSolution добавляется новый элемент, иначе точка p 
считается эквивалентом ближайшей точки и может ее заменить при
лучшем показателе сходимости (exitflag). При сходимости поиска
из точки p порог устанавливается в значение функции счета этой точки, а радиус бассейна с центром xp принимается равным максимуму из
существующего радиуса и расстояния между p и xp. При невыполнении
в точке p приведенных выше условий локальный решатель не запускается и выполняются следующие действия. Увеличивается значение
43 
счетчиков бассейнов, содержащих точку p, и сбрасываются в ноль
счетчики остальных бассейнов. Для каждого бассейна, счетчик которого равен принятому значению MaxWaitCycle, уменьшается его радиус
умножением на (1 – BasinRadiusFactor). Если счетчик порога равен
MaxWaitCycle, порог увеличивается по следующей формуле: новый
порог:=порог + PenaltyThresholdFactor*(1 +abs(threshold)), 
а счетчик сбрасывается в 0. Все используемые здесь параметры приведены в прил. 3. По каждым 200 пробным точкам выдается одна строка
отчета глобальных итераций. 
Алгоритм завершает работу по истечении установленного значения времени или исчерпании пробных точек. Результатом является
множество решений GlobalOptimSolution, упорядоченное по значениям целевой функции. Очевидно, что реализованный в алгоритме
подход является эвристическим. 
Теперь остановимся на применении GlobalSearch. Сначала
создается структура Задача (problem) с помощью функции
createOptimProblem, для чего задаются целевая функция в виде
m-файла или анонимно, границы и функции нелинейных ограничений
(при их наличии), стартовая точка xstart, например, для трехмерной задачи так:
xstart = randn(3,1). 
Кроме того, если требуется задать параметры options, отличающиеся
от установленных по умолчанию значений, то используется optimset
(например, чтобы задать конкретный алгоритм fmincon). В качестве
аргументов функции createOptimProblem сначала записывается
имя решателя, затем параметры в виде пар «имя, значение». Для указания ограничений используются имена, приведенные ниже. 
Ограничение Имя
Нижняя граница 'lb'
Верхняя граница 'ub'
Матрица линейных неравенств 'Aineq'
Вектор ограничения линейных неравенств 'bineq'
Матрица линейных равенств 'Aeq'
Вектор ограничения линейных равенств 'beq'
Функция нелинейных ограничений 'nonlcon'
44 
Примечание. Поскольку в GlobalSearch используется только
fmincon, то при отсутствии ограничений следует добавить искусственное: 
problem.lb = -Inf; 
Приведем вариант создания задачи. Например, зададим конкретный алгоритм fmincon
opts = optimset('Algorithm','interior-point'); 
определим целевую функцию с именем glmin и линейные неравенства
с матрицей A и вектором b. Тогда для создания Задачи следует ввести
problem =createOptimProblem('fmincon','x0',xstart,... 
'objective',@glmin,'Aineq',A,'bineq',b,'options',opts); 
Теперь можно удостовериться в правильности созданной задачи
запуском решателя fmincon: 
[x fval eflag output] = fmincon(problem); 
Для применения GlobalSearch принято создавать объект решателя (solver object), используемый в команде запуска run. Если
параметры глобального поиска, установленные по умолчанию, приемлемы, то объект решателя с именем gs создается командой
gs = GlobalSearch; 
Если же требуется изменить некоторые параметры, тогда они указываются как аргументы GlobalSearch в виде пар «имя, значение», 
например
gs = GlobalSearch('TolX',0.01,'MaxTime',2000);,
где заданы значения для выявления идентичных решений (когда различия между ними в пределах 0,01) и максимально допустимое время
решения задачи. Все параметры, присущие GlobalSearch, приведены в прил. 3. Параметры локального решателя можно изменять, как и
раньше, через optimset. 
Запускается решение задачи командой run с аргументами gs и
problem: 
[x,fval,exitflag,output,manyminsg] = run(gs,problem) 
Как и в обращениях к функциям, возвращаемых глобальных аргументов здесь может быть задано меньше, например [x,fval]. Выход
exitflag дает признак причины завершения глобального решателя: 
2 – найден по крайней мере один локальный минимум и некоторые запуски локального решателя привели к сходимости, 
45 
1 – найден по крайней мере один локальный минимум и все запуски локального решателя привели к сходимости, 
0 – локальный минимум не найден, но локальный решатель вызывался не менее одного раза и превысил максимальное число итераций
или оценок функции, 
-1 – запущенный локальный решатель остановлен функцией output или plot, 
-2 – не найден допустимый локальный минимум, 
-5 – исчерпан лимит времени MaxTime, 
-8 – решение не найдено, все запуски локального решателя завершились с exitflag  -2, 
-10 – ошибки в функциях, определенных пользователем. 
Глобальная структура output содержит количество вычислений
целевой функции, общее число запусков локального решателя (fmincon), из них успешных и неуспешных. Четвертый выходной аргумент
Manyminsg представляет собой структуру глобального решения, которая включает массив X точек найденных минимумов, вектор Fval
значений целевой функции в этих точках, вектор значений Exitflag
локального решателя, структуру output и массив X0 стартовых точек. 
Очевидно, что эту структуру следует указывать в выходных аргументах в тех случаях, когда требуется получить данные обо всех найденных минимумах. 
Пример 7. 
Найти глобальный минимум функции
f = 3(1– x1)
2
exp(– 2
1 x – (x2 + 1)2
) –10( x1/5 – 3
1 x – 5
2 x )exp (– 2
1 x – 2
1 x ) – 
– 1/3exp (– (x1 + 1)2 – 2
2 x ) 
на параллелепипеде
–3  xj  3, j = 1, 2. 
Напомним, что данная функция представлена в m-файле с именем
myfun. 
Попытаемся найти глобальное решение методом GlobalSearch.
Для этого создадим объект gs с параметром 'Display' в значении
'iter', что обеспечит вывод итераций главного цикла (Stage 2) гло-
46 
бального поиска. Затем выберем алгоритм локального поиска 'interior-point', создадим Задачу (problem) с целевой функцией myfun
и обратимся к функции run. В итоге имеем следующую программу: 
gs = GlobalSearch('Display','iter'); 
opts = optimset('Algorithm','interior-point'); 
problem = createOptimProblem('fmincon','x0',x0,... 
'objective',@myfun,'lb',[-3,-3],'ub',[3,3],... 
'options',opts); 
[xminm,fminm,flagm,outptm,manyminsg] = ... 
run(gs,problem); 
Ее достаточно для поиска решения, но, чтобы придать наглядность
решению, дополним ее трехмерным графиком функции, на котором в
горизонтальной плоскости переменных отобразим линии уровня (контуры) функции, стартовые точки и центры бассейнов (найденные минимумы). При этом графические построения будем производить по
функции myfun1, записанной в одноименном m-файле: 
function f=myfun1(x,y) 
f=3*(1-x).^2.*exp(-x.^2-(y+1).^2)-10*(x/5.... 
 -x.^3-y.^5).*exp(-x.^2-y.^2)-1/3*exp(-(x... 
 +1).^2-y.^2); 
end 
Для удобства многократных запусков оформим расширенную программу в виде функции от начальной точки с именем runglobal: 
function runglobal(x0) 
[X,Y]=meshgrid(-4:0.1:4); Z=myfun1(X,Y);meshc(X,Y,Z); 
xlabel('x1');ylabel('x2');zlabel('f');hold on; 
gs = GlobalSearch('Display','iter'); 
opts = optimset('Algorithm','interior-point'); 
problem = createOptimProblem('fmincon','x0',x0,... 
'objective',@myfun,'lb',[-3,-3],'ub',[3,3],... 
'options',opts); 
[xminm,fminm,flagm,outptm,manyminsg] = run(gs,problem) 
% Plot points 
possColors = 'kbgcrm'; 
hold on 
for i = 1:size(manyminsg,2) 
% Color of this line 
cIdx = rem(i-1, length(possColors)) + 1; 
color = possColors(cIdx); 
47 
% Plot start points 
u = manyminsg(i).X0; 
x0ThisMin = reshape([u{:}], 2, length(u)); 
z=-10*ones(size(x0ThisMin)); 
plot3(x0ThisMin(1, :), x0ThisMin(2, :),z,'.', ... 
'Color',color,'MarkerSize',12); 
% Plot the basin with color i 
z=-10*ones(size(manyminsg(i).X)); 
plot3(manyminsg(i).X(1), manyminsg(i).X(2),z,'*', ... 
'Color', color, 'MarkerSize',10); 
end 
% basin center marked with a *, start points 
% with dots 
end 
Чтобы сравнить с результатами применения локального метода в
примере 6, запустим программу runglobal с начальной точки, которая тогда оказалась неудачной: 
>> x0=[-0.5 3]; runglobal(x0) 
После завершения вычислений выводится информация о больших
итерациях в виде следующей таблицы: 
 Num Pts Best Current Threshold Local Local 
Analyzed F-count f(x) Penalty Penalty f(x) exitflag Procedure 
 0 84 3.287e-005 3.287e-005 1 Initial Point 
 200 1321 -3.05 -3.05 1 Stage 1 Local 
 217 1383 -6.551 -3.461 -3.05 -6.551 1 Stage 2 Local 
 227 1429 -6.551 -4.196 -3.461 -6.551 1 Stage 2 Local 
 300 1502 -6.551 -0.06148 -3.327 Stage 2 Search 
 400 1602 -6.551 -1.315e-005 -0.4178 Stage 2 Search 
 422 1658 -6.551 -0.2512 -0.1343 -6.551 1 Stage 2 Local 
 491 1761 -6.551 -1.827 -0.6872 -3.05 1 Stage 2 Local 
 500 1770 -6.551 0.04837 -2.211 Stage 2 Search 
 529 1834 -6.551 -2.118 -2.104 -3.05 1 Stage 2 Local 
 600 1905 -6.551 -0.9791 -1.729 Stage 2 Search 
 700 2005 -6.551 -1.429 -6.25 Stage 2 Search 
 800 2105 -6.551 0.009279 -2.641 Stage 2 Search 
 879 2216 -6.551 -1.405 -1.305 -3.05 1 Stage 2 Local 
 880 2249 -6.551 -1.48 -1.405 -3.05 1 Stage 2 Local 
 900 2269 -6.551 -2.18 -2.956 Stage 2 Search 
 1000 2369 -6.551 -6.318 -6.525 Stage 2 Search 
Здесь по каждой итерации представлены число проверенных пробных точек, количество вычислений целевой функции и лучшее из ее
48 
достигнутых значение, текущий и пороговые штрафы, минимум f(x) локального решателя и признак его завершения и стадия алгоритма. 
Далее выводится сообщение: 
GlobalSearch stopped because it analyzed all the trial points. 
All 9 local solver runs converged with a positive local solver exit flag. 
Оно информирует, что алгоритм остановился, так как проанализированы все пробные точки, все девять запусков локального решателя
завершились с положительным признаком (в таблице значение
Exitflag=1 соответствует всем девяти локальным поискам). 
Следующая порция вывода содержит основные итоговые результаты: 
– координаты лучшей точки
xminm = 
 0.2283 -1.6255 
– значение целевой функции в этой точке
fminm = 
 -6.5511 
– признак завершения лучшего поиска
flagm = 
 1 
– структуру вывода, в которой дается общее количество обращений к целевой функции, общее число запусков локального решателя и
из них удачных и неудачных
outptm = 
 funcCount: 2369 
 localSolverTotal: 9 
 localSolverSuccess: 9 
 localSolverIncomplete: 0 
 localSolverNoSolution: 0 
 message: [1x137 char] 
Завершается вывод в командное окно представлением глобальной
структуры 
manyminsg = 
 1x3 GlobalOptimSolution 
 Properties: 
 X 
 Fval 
 Exitflag 
 Output 
 X0 
49 
Наконец, в графическом окне мы видим целевую функцию и точки, приводящие к минимумам (рис. 11). 
Рис. 11. Поиск глобального минимума методом GlobalSearch
На этом рисунке ромбиками показаны стартовые точки, приведшие к минимуму, а снежинками – центры бассейнов притяжения (локальные минимумы). Одному минимуму соответствует один цвет ромбиков и снежинок. Интересно, что один из обнаруженных минимумов
(зеленая снежинка) соответствует тому, в котором «застрял» локальный решатель в примере 6. Если нас интересуют все минимумы, то получить их координаты и соответствующие значения целевой функции
можно из структуры manyminsg (см. программу runglobal). 
Как следует из полученных численных и графических данных, в
процессе поиска по методу GlobalSearch исследовано 1000 пробных точек, из них восемь точек использованы как стартовые для локального решателя, при этом из пяти точек достигнут локальный минимум со значением целевой функции –3,05 (эти точки имеют синий
цвет), из трех точек – локальный минимум со значением –6,551 (черный цвет), а начальная точка x0 привела в минимум со значением
3.287e-005 (зеленый цвет). В целом поиск оказался успешным: в точке
(0,2283 –1,6255) найден глобальный минимум со значением целевой
функции –6,5511. 
50 
4.2. Метод MultiStart
К целевой функции и функциям ограничений решаемой задачи
предъявляются такие же требования, как в GlobalSearch. Методы
GlobalSearch и MultiStart базируются на общей идее: поиск минимумов осуществляется запуском локального решателя из множества
стартовых точек, а отличаются они способами формирования и выбора
этих точек. Кроме того, в MultiStart можно использовать не только
fmincon, но и другие локальные решатели, а также распараллеливать
процесс. 
Объект MultiStart создается выражением
ms = MultiStart, 
где ms – имя объекта, его глобальные свойства (параметры) приведены в прил. 3. Задача (problem) создается так же, как в GlobalSearch. 
Выполнение алгоритма осуществляется функцией run. 
Основными шагами алгоритма MultiStart являются генерация
стартовых точек, фильтрация сгенерированных точек и запуск локального решателя. Подробнее остановимся на первом шаге. 
Имеется четыре способа задания набора стартовых точек. 
1. Использовать объект RandomStartPointSet, генерирующий
псевдослучайные числа. Он создается предложением
stpoints = RandomStartPointSet; 
По умолчанию такой объект генерирует 10 стартовых точек. Если требуется другое число точек, оно указывается как значение параметра
NumStartPoints, например
stpoints = RandomStartPointSet('NumStartPoints',70)
задает 70 точек. На множество генерируемых точек можно накладывать искусственные границы через параметр ArtificialBound 
stpoints=RandomStartPointSet('NumStartPoints',70, ... 
'ArtificialBound',50). 
Если задача не содержит границ, то нижней границей будет –AB, а верхней AB, где AB – значение ArtificialBound. При наличии только нижней границы lb верхняя граница будет равна lb+2*AB. А когда
есть только верхняя граница ub, нижней границей будет ub-2*AB.
51 
2. Задать число стартовых точек S как входной параметр функции
run. В этом случае будет генерироваться S-1 псевдослучайных точек, 
к которым добавляется начальная точка x0. 
3. Создать пользовательский объект CustomStartPointSet. Для
этого сначала формируют матрицу, в которой каждая строка – это координаты стартовой точки. Например, матрицу pts из 50 точек четырехмерного пространства, равных 20 плюс экспоненциально распределенное случайное число со средним значением 10, можно получить так: 
pts = -10*log(rand(50,4)) + 20; 
Затем на этой матрице создается объект: 
tpoints = CustomStartPointSet(pts). 
Чтобы увидеть матрицу pts, можно воспользоваться функцией list: 
pts = list(tpoints). 
4. Использовать несколько наборов точек. Например, для образования множества стартовых точек с использованием приведенных выше объектов CustomStartPointSet и RandomStartPointSet следует ввести
pts = -10*log(rand(50,4)) + 20; 
tpoints = CustomStartPointSet(pts); 
rpts = RandomStartPointSet('NumStartPoints',40); 
allpts = {tpoints,rpts}. 
Включение allpts в качестве параметра функции run обеспечит
генерирование 90 стартовых точек. 
Теперь рассмотрим второй шаг алгоритма. Фильтрация сгенерированных точек имеет место, когда параметр StartPointsToRun равен
'bounds' или 'bounds-ineqs': в качестве стартовых будут использованы только точки, удовлетворяющие указанным ограничениям. 
По умолчанию используются все точки (параметр = 'all'). 
На третьем шаге MultiStart запускает локальный решатель, указанный в задаче (problem). В качестве него может быть выбран один из
следующих решателей: fmincon, fminunc, lsqcurvefit, 
lsqnonlin. Последние два решателя предназначены для задач подбора кривой и неотрицательного линейного метода наименьших квадратов
соответственно (см. гл. 9). Если установлен параллельный режим, то
стартовые точки распределяются по работающим процессорам, которые
запускают локальный решатель. Если решатель остановился из-за исчерпания лимита времени, то решение не фиксируется, иначе запоминаются результаты и выполняется следующий шаг. Алгоритм заверша-
52 
ется, когда использованы все стартовые точки или время решения превысило допустимое (MaxTime). При этом, как и в GlobalSearch, формируется множество решений GlobalOptimSolution, упорядоченное по значениям целевой функции. Из каждого множества идентичных
решений, которые выявляются с использование параметров TolFun и
TolX, в него попадает только одно. 
Далее рассмотрим на примерах применение метода MultiStart. 
Пример 8. 
Найти минимумы функции
2 46 2 4
1 1 1 12 2 2 f     4 2,1 3 4 4 x x x xx x x
при условиях
–3  xj  3, j = 1, 2. 
Целевую функцию представим в виде m-файла с именем sixmin: 
function f = sixmin(x) 
f=4*x(1)^2 - 2.1*x(1)^4 + x(1)^6/3 ... 
 + x(1)*x(2) - 4*x(2)^2 + 4*x(2)^4; 
end 
Создаем объект со свойством вывода информации по итерациям: 
ms = MultiStart('Display','iter'); 
в качестве локального решателя выбираем fmincon с алгоритмом
внутренней точки и создаем проблему: 
opts = optimset('Algorithm','interior-point'); 
problem = createOptimProblem('fmincon','x0',x0,... 
'objective',@sixmin,'lb',[-3,-3],'ub',[3,3],... 
'options',opts); 
и, наконец, задаем 40 стартовых точек в команде запуска run:
[x,fval] = run(ms,problem,40). 
Такой программы достаточно для решения нашей задачи. Но чтобы наглядно продемонстрировать работу метода, расширим программу, добавив команды вывода 3D-графика функции, ее линий уровня и
отображения стартовых и конечных точек локальных поисков. Для
отображения графики создадим второй m-файл целевой функции: 
function fg = sixmin_g(x,y) 
 fg=4*x.^2 - 2.1*x.^4 + x.^6/3 ... 
 + x.*y - 4*y.^2 + 4*y.^4; 
end 
53 
Кроме того, расширим вывод функции run, и в итоге получаем
следующую программу, оформленную как функция runglobal1: 
 function runglobal1(x0) 
[x,y]=meshgrid(-3:0.03:3);Z=sixmin_g(x,y); 
meshc(x,y,Z); 
xlabel('x1');ylabel('x2');zlabel('f'); 
figure; c=contour(x,y,Z,[-0.8 -0.2 0.07 1 3 7 ... 
15 28 45 65],'blue'); 
xlabel('x1');ylabel('x2'); 
ms = MultiStart('Display','iter'); 
opts = optimset('Algorithm','interior-point'); 
problem = createOptimProblem('fmincon','x0',x0,... 
'objective',@sixmin,'lb',[-3,-3],'ub',[3,3],... 
'options',opts); 
[x,fval,flag,outpt,manyminms] = run(ms,problem,40) 
% Plot points 
possColors = 'kbgcrm'; 
hold on 
for i = 1:size(manyminms,2) 
% Color of this line 
cIdx = rem(i-1, length(possColors)) + 1; 
color = possColors(cIdx); 
% Plot start points 
u = manyminms(i).X0; 
x0ThisMin = reshape([u{:}], 2, length(u)); 
plot(x0ThisMin(1, :), x0ThisMin(2, :),'.', ... 
'Color',color,'MarkerSize',12); 
% Plot the basin with color i 
plot(manyminms(i).X(1), manyminms(i).X(2),'*', ... 
'Color', color, 'MarkerSize',10); 
end % basin center marked with a *, start points 
% with dots 
 end 
С произвольно взятой начальной точки запускаем программу
>> x0=[0 1]; runglobal1(x0) 
Сначала выводится график функции с контурами на горизонтальной плоскости (рис. 12), на котором визуально обнаруживается несколько минимумов. Затем следует отчет по итерациям, строки которого соответствуют всем стартовым точкам, включая начальную: 
54 
Run Local Local Local Local First-order 
Index exitflag f(x) # iter F-count optimality 
1 1 -1.032 9 35 8.744e-007 
2 1 -1.032 17 55 8.745e-007 
3 1 -1.032 8 31 8.745e-007 
4 1 -1.032 8 31 8.741e-007 
5 1 -1.032 14 47 1.749e-007 
6 1 -1.032 8 30 8.744e-007 
7 1 -1.032 10 35 8.745e-007 
8 1 -0.2155 11 58 3.742e-008 
9 1 -1.032 10 37 8.744e-007 
10 1 -1.032 11 40 8.745e-007 
11 1 -1.032 15 51 2.645e-008 
12 1 -1.032 10 35 8.743e-007 
13 1 -1.032 11 40 8.745e-007 
14 1 -1.032 10 37 1.154e-008 
15 1 -1.032 8 32 8.745e-007 
16 1 -1.032 13 44 1.749e-007 
17 1 -0.2155 12 44 4.616e-008 
18 1 -1.032 11 41 8.838e-007 
19 1 -1.032 13 48 8.744e-007 
20 1 -0.2155 11 44 2.381e-008 
21 1 -1.032 11 40 8.743e-007 
22 1 -0.2155 9 34 9.864e-008 
23 1 -1.032 12 43 9.457e-007 
24 1 -1.032 11 38 4.135e-008 
25 1 -1.032 13 48 8.744e-007 
26 1 -1.032 9 33 8.743e-007 
27 1 -0.2155 13 47 2.381e-008 
28 1 -0.2155 15 53 9.864e-008 
29 1 -1.032 8 32 8.743e-007 
30 1 -0.2155 12 43 1.074e-007 
31 1 -0.2155 11 41 4.09e-008 
32 1 2.104 13 45 2.872e-007 
33 1 -1.032 15 60 8.745e-007 
34 1 -0.2155 13 45 1.025e-007 
35 1 -1.032 10 36 8.744e-007 
36 1 -1.032 9 33 8.745e-007 
37 1 -1.032 15 53 8.745e-007 
38 1 -0.2155 9 39 3.037e-007 
55 
39 1 -1.032 9 32 8.745e-007 
40 1 -1.032 9 32 8.743e-007 
MultiStart completed the runs from all start points. 
All 40 local solver runs converged with a positive local solver exit flag. 
Рис. 12. Функция sixmin
Из этого отчета следует, что поиск из всех 40 точек завершился
успешно (exitflag везде равен 1), при этом получены три минимальных значения целевой функции. 
Затем выводятся данные по лучшему минимуму и структуры
outpt и manyminms:
x = 
 -0.0898 0.7127 
fval = -1.0316 
flag = 1 
outpt = 
 funcCount: 1645 
 localSolverTotal: 40 
 localSolverSuccess: 40 
 localSolverIncomplete: 0 
 localSolverNoSolution: 0 
56 
 message: [1x128 char] 
manyminms = 
 1x5 GlobalOptimSolution 
 Properties: 
 X 
 Fval 
 Exitflag 
 Output 
 X0 
Из последней части отчета имеем: самое минимальное значение функции цели –1,0316 достигнуто в точке (–0,0898 0,7127), при этом функция
вычислялась 1645 раз и обнаружено пять локальных минимумов. 
Завершает вывод карта линий уровня (контуров) целевой функции
с нанесенными на нее стартовыми точками (цветные точки) и точками
найденных минимумов (обозначены символом *). Она представлена на
рис. 13. 
Рис. 13. Линии уровня функции sixmin и точки начала
и окончания локальных поисков
Рис. 13 подтверждает обнаружение пяти минимумов, из них две
пары минимумов оказались симметричными относительно начала координат, и поэтому минимальных значений функции только три. 
57 
Запустим программу повторно из той же начальной точки, убрав
предварительно вывод отчета по итерациям. В результате получаем
x = 
 0.0898 -0.7127 
fval = -1.0316 
flag = 1 
outpt = 
 funcCount: 1589 
 localSolverTotal: 40 
 localSolverSuccess: 40 
 localSolverIncomplete: 0 
 localSolverNoSolution: 0 
 message: [1x128 char] 
manyminms = 
 1x6 GlobalOptimSolution 
 Properties: 
 X 
 Fval 
 Exitflag 
 Output 
 X0 
Расположение стартовых точек и найденных минимумов показано
на рис. 14. 
Мы видим, что теперь при несколько меньшем числе вычислений
целевой функции обнаружено шесть минимумов, из них три пары симметрично расположенных относительно начала координат. При многократных повторах выполнения программы обнаруживается от четырех
до шести минимумов, и всегда в их число попадают два симметричных
минимума с x1 =  0,0898, x2 = 0,7127 и f = –1,0316, которые и являются глобальными. 
58 
Рис. 14. Результаты повторного поиска минимумов
функции sixmin
Пример 9. 
Методом MultiStart найти минимумы уже исследованной ранее
функции 
f = 3(1– x1)
2
exp (– 2
1 x – (x2 + 1)2
) –10(x1/5 – 3
1 x – 5
2 x )exp(– 2
1 x – 2
1 x ) – 
–1/3exp (–(x1 + 1)2 – 2
2 x ) 
при условиях
–3  xj  3, j = 1, 2. 
Для решения этой задачи составим программу, подобную runglobal1, но отличающуюся тем, что она позволит на одном графике
отображать и функцию, и контуры, и все точки, фигурирующие в процессе поиска: 
function runglobal1_2(x0) 
[X,Y]=meshgrid(-4:0.1:4); 
Z=myfun1(X,Y);meshc(X,Y,Z); 
xlabel('x1');ylabel('x2');zlabel('f'); 
ms = MultiStart('Display','iter'); 
59 
opts = optimset('Algorithm','interior-point'); 
problem = createOptimProblem('fmincon','x0',x0,... 
'objective',@myfun,'lb',[-3,-3],'ub',[3,3],... 
'options',opts); 
[xm,fm,flagm,outptm,manyminms] = run(ms,problem,40) 
possColors = 'kbgcrm'; 
hold on 
for i = 1:size(manyminms,2) 
% Color of this line 
cIdx = rem(i-1, length(possColors)) + 1; 
color = possColors(cIdx); 
% Plot start points 
u = manyminms(i).X0; 
x0ThisMin = reshape([u{:}], 2, length(u)); 
z=-10*ones(size(x0ThisMin)); 
plot3(x0ThisMin(1, :), x0ThisMin(2, :),z, '.', ... 
'Color',color,'MarkerSize',12); 
% Plot the basin with color i 
z=-10*ones(size(manyminms(i).X)); 
plot3(manyminms(i).X(1),manyminms(i).X(2),z,'*', ... 
'Color', color, 'MarkerSize',10); 
end % basin center marked with a *, start points 
 % with dots 
end 
Задаем начальную точку и запускаем нашу программу: 
>> x0=[3 -0.5];runglobal1_2(x0) 
Через несколько секунд появляется отчет по итерациям: 
Run Local Local Local Local First-order 
Index exitflag f(x) # iter F-count optimality 
1 1 -6.551 17 63 6.311e-008 
2 1 -6.551 10 39 2.394e-007 
3 1 -6.551 10 38 2.394e-007 
4 1 6.687e-005 20 63 5.184e-007 
5 1 -3.05 10 37 1.21e-008 
6 1 -6.551 14 55 2.374e-007 
7 1 -3.05 29 99 1.406e-007 
8 1 -6.551 15 54 2.99e-007 
60 
9 1 6.686e-005 22 69 7.893e-007 
10 1 -6.551 22 110 1.182e-007 
11 1 4.106e-005 26 81 5.769e-008 
12 1 -6.551 10 38 1.202e-007 
13 1 4.125e-005 24 75 8.355e-007 
14 1 -3.05 11 43 5.885e-008 
15 1 -6.551 10 43 2.394e-007 
16 1 -6.551 9 37 6.063e-008 
17 1 -6.551 12 48 5.858e-008 
18 1 -6.551 10 41 9.978e-008 
19 1 -3.05 11 39 1.462e-008 
20 1 -3.05 11 44 1.481e-007 
21 1 -3.05 12 43 3.072e-008 
22 1 6.687e-005 20 63 5.012e-007 
23 1 -6.551 9 42 1.569e-007 
24 1 -3.05 16 53 9.032e-008 
25 1 3.227e-005 26 81 6.415e-008 
26 1 -3.05 8 33 5.869e-008 
27 1 -6.551 12 45 1.798e-007 
28 1 4.125e-005 27 84 6.959e-007 
29 1 -3.05 15 52 5.174e-008 
30 1 -6.551 21 71 1.182e-007 
31 1 -6.551 16 54 9.978e-008 
32 1 -6.551 12 50 2.394e-007 
33 1 -3.05 12 43 8.849e-008 
34 1 -6.551 13 58 8.356e-008 
35 1 -3.05 9 34 1.21e-008 
36 1 -3.05 11 42 3.072e-008 
37 1 -3.05 12 42 9.032e-008 
38 1 -6.551 10 39 2.394e-007 
39 1 -3.05 13 45 1.183e-007 
40 1 -6.551 21 72 6.311e-008 
MultiStart completed the runs from all start points. 
All 40 local solver runs converged with a positive local solver exit flag. 
После таблицы выдано сообщение, в котором констатируется, что
метод завершил работу по причине использования для поиска всех
стартовых точек, и все старты локального решателя привели к сходи-
61 
мости. Последующая часть текстового вывода содержит итоги работы
MultiStart: 
– точку предполагаемого глобального минимума и его значение
xm = 
0.2283 -1.6255 
fm = 
-6.5511 
– признак завершения глобального поиска и его структуры
flagm = 1 
outptm = 
funcCount: 2165 
localSolverTotal: 40 
localSolverSuccess: 40 
localSolverIncomplete: 0 
localSolverNoSolution: 0 
message: [1x128 char] 
manyminms = 
 1x8 GlobalOptimSolution 
Properties: 
X 
Fval 
Exitflag 
Output 
X0 
Таким образом, поиски из 40 стартовых точек позволили выявить
восемь точек, в которых возможен глобальный минимум. Как легли
эти точки на заданную область поиска, показано на рис. 15. Там же
символом * отмечены пять локальных минимумов, включая глобальный минимум в точке (0,2283 –1,6255) со значением целевой функции
–6,5511. Это же решение было получено методом GlobalSearch
(пример 7), которому потребовалось вычислять целевую функцию
2369 раз против 2165 методом MultiStart. 
62 
Рис. 15. Поиск минимумов функции myfun методом MultiStart 
Пример 10. 
Найти максимумы функции из примера 9 при тех же условиях. 
Чтобы воспользоваться тем же методом, изменим знак функции и
запишем ее в m-файл с именем myfun2, заменим ею функцию myfun в
runglobal1_2 и новую версию программы запишем под именем runglobal1_3. 
Результаты, полученные при выполнении этой программы, приведены ниже. 
>> x0=[3 -0.5]; runglobal1_3(x0) 
Run Local Local Local Local First-order 
Index exitflag f(x) # iter F-count optimality 
1 1 -3.592 11 39 5.336e-008 
2 1 -3.592 10 36 6.254e-008 
3 1 -8.106 9 36 6.565e-008 
4 1 -3.777 7 37 8.437e-007 
5 1 -3.592 19 69 3.018e-008 
6 1 -3.592 21 77 2.333e-007 
7 1 -8.106 11 40 1.193e-007 
8 1 -8.106 22 76 2.82e-007 
63 
9 1 -8.106 13 49 1.193e-007 
10 1 -8.106 24 112 1.41e-007 
11 1 -3.592 10 36 5.336e-008 
12 1 -8.106 10 38 1.193e-007 
13 1 -3.777 9 35 8.437e-007 
14 1 -3.592 23 84 5.958e-008 
15 1 -8.106 10 37 1.605e-007 
16 1 -8.106 30 104 1.194e-007 
17 1 -8.106 20 68 1.193e-007 
18 1 -8.106 15 76 2.385e-007 
19 1 -8.106 31 101 5.952e-007 
20 1 -8.106 31 104 8.512e-008 
21 1 -3.777 10 38 8.437e-007 
22 1 -8.106 21 81 2.82e-007 
23 1 -3.777 14 50 8.731e-008 
24 1 -8.106 11 42 5.96e-007 
25 1 -8.106 18 61 1.192e-007 
26 1 -8.106 17 61 2.82e-007 
27 1 -8.106 9 37 3.577e-007 
28 1 -3.777 9 36 5.668e-008 
29 1 -8.106 10 38 2.385e-007 
30 1 -8.106 10 37 2.385e-007 
31 1 -3.592 12 40 1.192e-007 
32 1 -3.777 9 34 8.435e-007 
33 1 -8.106 18 63 8.512e-008 
34 1 -8.106 11 42 3.576e-007 
35 1 -8.106 15 52 8.512e-008 
36 1 -8.106 12 44 1.41e-007 
37 1 -3.777 15 54 8.437e-007 
38 1 -3.777 8 34 8.436e-007 
39 1 -8.106 8 34 1.193e-007 
40 1 -3.592 10 36 8.572e-008 
MultiStart completed the runs from all start points. 
All 40 local solver runs converged with a positive local solver exit flag. 
xm = 
 -0.0093 1.5814 
fm = 
 -8.1062 
flagm = 
64 
 1 
outptm = 
 funcCount: 2171 
 localSolverTotal: 40 
 localSolverSuccess: 40 
 localSolverIncomplete: 0 
 localSolverNoSolution: 0 
 message: [1x128 char] 
manyminms = 
 1x3 GlobalOptimSolution 
 Properties: 
 X 
 Fval 
 Exitflag 
 Output 
 X0 
Рис. 16. Поиск максимумов функции myfun методом MultiStart
Как следует из текстового отчета и рис. 16, найдено три максимума, наибольший из которых равен 8,1062 и находится в точке (–0,0093 
1,5814). Более точное представление о расположении стартовых точек
65 
и минимумов может дать контурная карта. Чтобы ее получить, изменим программу runglobal1_3, уменьшив объем текстового отчета и
убрав 3D-представление функции. Измененную программу runglobal1_4 запускаем с той же начальной точки и получаем краткий
отчет и контурную карту со всеми стартовыми точками и точками минимумов (рис. 17): 
>> x0=[3 -0.5]; runglobal1_4(x0) 
MultiStart completed the runs from all start points. 
All 40 local solver runs converged with a positive local solver exit flag. 
x = 
 -0.0093 1.5814 
fval = 
 -8.1062 
flag = 
 1 
outpt = 
 funcCount: 2162 
 localSolverTotal: 40 
 localSolverSuccess: 40 
 localSolverIncomplete: 0 
 localSolverNoSolution: 0 
 message: [1x128 char] 
manyminms = 
 1x3 GlobalOptimSolution 
 Properties: 
X 
Fval 
Exitflag 
Output 
X0 
Чтобы получить значения всех найденных максимумов и их координат, обратимся к структуре manyminms: 
>> [manyminms.Fval] 
ans = 
 -8.1062 -3.7766 -3.5925 /значения функции с обратным знаком в трех
 /максимумах
66 
>> [manyminms.X] 
ans = 
 Columns 1 through 5 
 -0.0093 1.5814 -0.4600 -0.6292 1.2857 /координаты трех
 Column 6 
 -0.0048 /максимумов
Таким образом, задача решена успешно. 
Рис. 17. Стартовые точки и максимумы (*) на контурной карте
функции myfun
Пример 11. 
Решим задачу из примера 10 при дополнительном ограничении
–4x1 + 5x2  7. 
В программу runglobal1_4 внесем изменения: при создании
проблемы (problem) помимо границ зададим линейное ограничение, 
добавим функцию рисования этого ограничения, в команде run определим 50 стартовых точек и параметром StartPointsToRun в объекте ms потребуем использовать только те точки, которые удовлетворяют всем условиям. В итоге имеем следующую программу: 
67 
function runglobal1_5(x0) 
[x,y]=meshgrid(-3:0.03:3);Z=myfun1(x,y); 
c=contour(x,y,Z,30); 
xlabel('x1');ylabel('x2');hold on; plot([-3 2], ... 
[-1 3], 'g-','linewidth',2.3); 
 
ms = MultiStart('StartPointsToRun','bounds-ineqs'); 
opts = optimset('Algorithm','interior-point'); 
problem = createOptimProblem('fmincon','x0',x0,... 
'objective',@myfun2,'Aineq',[-4 5],'bineq',7,'lb', ... 
[-3, -3],'ub',[3,3],'options',opts); 
[x,fval,flag,outpt,manyminms] = run(ms,problem,50) 
% Plot points 
possColors = 'kbgcrm'; 
hold on 
for i = 1:size(manyminms,2) 
% Color of this line 
cIdx = rem(i-1, length(possColors)) + 1; 
color = possColors(cIdx); 
% Plot start points 
u = manyminms(i).X0; 
x0ThisMin = reshape([u{:}], 2, length(u)); 
plot(x0ThisMin(1, :), x0ThisMin(2, :),'.', ... 
'Color',color,'MarkerSize',12); 
plot(manyminms(i).X(1), manyminms(i).X(2),'*', ... 
'Color', color, 'MarkerSize',10); 
end % basin center marked with a *, start points 
 % with dots 
end 
Выполним эту программу: 
>> x0=[3 -0.5]; runglobal1_5(x0) 
Выполнение завершается выдачей результатов решения задачи в
виде рис. 18 и текстового отчета: 
MultiStart completed the runs from all start points. 
All 37 local solver runs converged with a positive 
local solver exit flag. 
x = 
 0.1265 1.5012 
68 
fval = 
 -7.8502 
flag = 
 1 
outpt = 
 funcCount: 1880 
 localSolverTotal: 37 
 localSolverSuccess: 37 
 localSolverIncomplete: 0 
 localSolverNoSolution: 0 
 message: [1x128 char] 
manyminms = 
 1x3 GlobalOptimSolution 
 Properties: 
 X 
 Fval 
 Exitflag 
 Output 
 X0 
Рис. 18. Расположение стартовых точек и максимумов
при линейном ограничении
69 
Из рис. 18 видно, что все использованные стартовые точки лежат в
допустимой области – это 37 точек из 50 заданных. Естественно, что
глобальный максимум, равный 7,8502, оказался меньше, чем при отсутствии линейного неравенства, и потому лежит на границе этого неравенства. Как и в предыдущем примере, всего найдено три максимума, два из которых те же, что в варианте задачи без неравенства. Значения максимумов и их координаты получим из глобальной структуры
manyminms: 
>>manyminms.Fval 
ans = 
 -7.8502 
ans = 
-3.7766 
ans = 
 -3.5925 
>>XX=[manyminms.X] 
XX = 
 0.1265 1.5012 -0.4600 -0.6292 1.2857 -0.0048 
В массиве ХХ представлены три пары точек, соответствующих координатам трех максимумов, а значения максимумов с обратным знаком – в переменных ans. 
Лабораторная работа № 3
Исследование методов GlobalSearch и MultiStart
Задания: 
1. Ознакомиться с основами методов GlobalSearch и
MultiStart, уяснить синтаксис и параметры создания глобальных
объектов и проблемы, параметры команды run. 
2. Воспроизвести программу из примера 8 и провести пять запусков; сделать анализ результатов. 
3. Применить методы GlobalSearch и MultiStart для нахождения минимумов функции f = –exp(x1sin(x1) – 2
2 x ) + 0,4x1 при условиях
–4 xj  4, j = 1, 2. Сравнить эффективность методов. 
70 
4. Применить методы GlobalSearch и MultiStart для нахождения минимумов функции из примера 9 при дополнительном ограничении 4x1 – 5x2  5. Сопоставить решения при разном числе стартовых
точек и разных значениях параметра StartPointsToRun. 
4.3. Метод Direct Search
Методы прямого поиска отличаются тем, что в них направление
движения к оптимуму определяется только по значениям целевой функции, т.е. не используются производные функции (градиенты и гессианы). Поэтому эти методы можно применять для минимизации недифференцируемых функций и функций, не являющихся непрерывными. 
Пакет Global Optimization включает три алгоритма прямого
поиска: 
1) GPS – обобщенный поиск по шаблону или образцу (pattern); 
2) GSS – поиск по генерируемому набору; 
3) MADS – адаптивный поиск петли (mesh) или окружения. 
Все они являются алгоритмами исследования образца, порождающими последовательность точек, приближающихся к минимуму. На
каждом шаге определяется набор точек вокруг текущей точки, называемый окружением или петлей (mesh). Точки окружения образуются
добавлением к текущей точке произведения скаляра на векторы, совокупность которых и называют шаблоном или образцом (pattern). Если в окружении находится точка с меньшим значением целевой функции, чем в текущей точке, она становится текущей для следующего
шага алгоритма. 
GPS-алгоритм для создания mesh использует векторы фиксированных направлений. Применяются два набора таких векторов: 
1) 2N положительный базис (2N positive basis), содержащий 
N векторов единичной матрицы размера N×N и N векторов противоположного знака, где N – число независимых переменных в целевой
функции. Например, при N = 3 такой набор состоит из шести векторов:
v1 = [1 0 0], v2 = [0 1 0], v3 = [0 0 1], v4 = [–1 0 0], v5 = [0 –1 0], v6 = [0 0 –1]; 
2) N + 1 положительный базис, содержащий N векторов единичной
матрицы размера N×N и один N-мерный вектор, все элементы которого
равны –1. Например, при трех переменных имеем
v1 = [1 0 0], v2 = [0 1 0], v3 = [0 0 1], v4 = [–1 –1 –1]. 
71 
Аналогичный набор векторов (шаблон) использует алгоритм GSS, 
за исключением случаев, когда в задаче с линейными ограничениями
текущая точка оказывается вблизи линейного ограничения. Специальный способ построения шаблона в этой ситуации предложен Kolda, 
Lewis и Torczon и здесь не рассматривается. Поэтому алгоритм GSS
предпочтительнее GPS для задач с линейными ограничениями. 
В алгоритме MADS векторы образца выбираются случайным образом. В зависимости от метода проверки или опроса (poll) число выбираемых векторов равно 2N или N + 1. В первом случае генерируются
N векторов, а остальные N образуются изменением знака у первых векторов. Во втором случае каждый компонент вектора N + 1 есть сумма
компонент первых N векторов, взятая с обратным знаком. 
Выбор алгоритма определяется параметром PollMethod, по
умолчанию его значение равно ‘GPSPositiveBasis2N’, что соответствует алгоритму GPS с 2N положительным базисом. 
Упомянутый выше скаляр, используемый для формирования окружения, называется размером окружения и обозначается Δm. Если x
k – 
текущая точка, а y
i
 – точка ее окружения, то она находится по формуле
y
i 
= x
k + Δm·vi, i = 1, …, 2N или i = 1, …, N + 1. 
На каждом шаге алгоритм обходит (polling) точки окружения, 
вычисляя в них значение целевой функции. Когда параметр Complete 
poll включен (‘on’), обходятся все точки окружения. Если среди них
окажется точка со значением целевой функции меньше, чем у текущей
точки, она становится новой текущей, а обход считается успешным. Если параметр Complete poll установлен в 'off', что принято по
умолчанию, обход прекращается, как только найдена точка с лучшим, 
чем у текущей точки, значением целевой функции, и такая точка становится новой текущей. При неуспешном обходе текущая точка не изменяется. Параметр PollingOrder определяет порядок, в котором ищутся
точки окружения. Его значения: Random – в случайном порядке, 
Success – первое направление поиска равно направлению, на котором
найдена лучшая точка на предшествующей итерации, Consecutive – 
последовательный порядок, согласно векторам образца. 
Опции поиска (Search options) позволяют указать алгоритму, 
что он может делать перед опросом (обходом) точек окружения. Если
этот дополнительный поиск улучшает целевую функцию, то соответ-
72 
ствующая точка используется на следующей итерации, а опрос не проводится. Здесь основным параметром является SearchMethod, по
умолчанию шаг дополнительного поиска не делается (значение равно []), другие значения параметра приведены в прил. 4. 
На каждой итерации размер окружения изменяется: при успешном
обходе он умножается на коэффициент расширения MeshExpansion, 
при неуспешном – на коэффициент сужения MeshContraction (по
умолчанию они равны 2 и 0,5 соответственно). Алгоритм завершает
работу при выполнении одного или нескольких критериев окончания, 
значения которых можно изменять через функцию установки параметров поиска psoptimset. Варианты критериев даются ниже при описании exitflag. 
Для решения задач, содержащих нелинейные ограничения, применяется алгоритм поиска по образцу, использующий расширенную
функцию Лагранжа (сокращенно ALPS). При общей модели задачи
минимизации в виде 
min f(X) 
при условиях
Ci (X)  0, i = 1, …, m,
ceqi(X) = 0, i = m + 1, …, mt,
AX  b, 
AeqX = beq, 
lb  X  ub
функция Лагранжа включает только нелинейные ограничения: 
2
1 1
( , , , ) ( ) lg( ( )) ( ( ) ( )) 2
m mt
ii i i i i i
i im
x s f x s s C x ceq x ceq x  
            , 
где i – неотрицательные множители Лагранжа; 
si – неотрицательные смещения, 
 – положительный параметр штрафа. 
Начальное значение параметра штрафа по умолчанию равно 10, 
а коэффициента его увеличения – 100. Эти значения могут быть изменены параметрами InitialPenalty и PenaltyFactor соответственно. 
73 
Алгоритм прямого поиска при удовлетворении границ и линейных
ограничений минимизирует последовательность подзадач Лагранжа, 
которая аппроксимирует исходную задачу. Когда минимизация подзадачи достигает требуемой точности и удовлетворения допустимости, 
оценки лагранжиана обновляются. Иначе параметр штрафа увеличивается в PenaltyFactor раз, и измененная подзадача снова минимизируется. Эти шаги повторяются до выполнения критерия останова. 
В Toolbox Global Optimization описанный алгоритм реализован в виде функции patternsearch. Рассмотрим варианты обращения к данной функции. 
 x = patternsearch(@fun,x0) 
 x = patternsearch(@fun,x0,A,b) 
 x = patternsearch(@fun,x0,A,b,Aeq,beq) 
 x = patternsearch(@fun,x0,A,b,Aeq,beq,LB,UB) 
 x = patternsearch(@fun,x0,A,b,Aeq,beq,LB,UB,nonlcon) 
 x = patternsearch(@fun,x0,A,b,Aeq,beq,LB,UB,... 
nonlcon,options) 
 x = patternsearch(problem) 
 [x,fval] = patternsearch(@fun,x0, ...) 
 [x,fval,exitflag] = patternsearch(@fun,x0, ...) 
 [x,fval,exitflag,output] = patternsearch(@fun,x0, ...)
Смысл входных аргументов функции такой же, как и в ранее рассмотренных функциях. Остановимся только на отличающихся по значениям и составу последних двух выходных аргументах. 
Индикатор exitflag в зависимости от причин останова может
иметь одно из следующих значений: 
1 – значение размера окружения меньше допустимого и нарушение ограничений меньше TolCon,
2 – изменение x меньше допустимого и нарушение ограничений
меньше TolCon,
4 – величина шага меньше машинной точности и нарушение ограничений меньше TolCon,
0 – число вычислений целевой функции превысило допустимое
значение, 
-1 – оптимизация остановлена функцией вывода графика, 
-2 – не найдено допустимой точки. 
74 
Структура output содержит следующие поля: 
function – целевая функция, 
problemtype – тип задачи: без ограничений, с границами или линейными ограничениями, 
pollmethod – метод создания окружения (алгоритм), 
searchmethod – используемый дополнительный метод поиска, 
iterations – общее число итераций, 
funccount – общее число вычислений целевой функции, 
meshsize – размер окружения, 
maxconstraint – максимальное нарушение ограничений, 
message – сообщение о причине останова алгоритма. 
Параметры оптимизации прямым поиском, как обычно, установлены по умолчанию, но могут быть изменены функцией psoptimset
путем записи выражения
options = psoptimset('param1',value1,'param2',... 
value2,...),
где в качестве аргументов функции указываются пары «имя, значение
параметра». Если справа от равенства записать только имя функции, то
это приведет к восстановлению значений всех параметров по умолчанию. Все параметры и их значения по умолчанию приведены в прил. 4. 
На работу алгоритма влияют параметры, определяющие окружение (mesh): 
InitialMeshSize – размер начального окружения (длина самого
короткого вектора от начальной точки к окружению), по умолчанию
равен 1,0; 
MaxMeshSize – макимальный размер окружения, по умолчснию
равен для GPS и GSS Inf, а для МADS 1; 
MeshAccelerator – задает или нет ускорение сходимости вблизи
минимума; 
MeshExpansion, MeshContraction – коэффициенты изменения размера окружения (их значения по умолчанию приведены в описании алгоритма); 
MeshRotate – задает или нет умножение векторов окружения на
 –1 после неудачного опроса при размере окружения меньше чем
TolMesh/100; применяется, когда PollMethod установлен в GPS или
75 
GSS с Positive basis Np1; включение полезно для функций с разрывами, но не работает при наличии равенств; 
ScaleMesh – включает или нет масштабирование точек окружения умножением векторов образца на константу, пропорциональную
логарифму абсолютного значения компонент текущей точки (по умолчанию ‘on’); при наличии равенств блокируется. 
В случае детерминированной целевой функции, требующей большого времени вычисления, ускорить алгоритм можно включением
кеш-памяти. Она позволяет не делать вычисление функции в точке, 
которая близка к ранее опрошенной точке. Включение осуществляется
параметром Cache, а изменить размер памяти можно параметром
CacheSize. 
Наконец, параметры Vectorized and UseParallel позволяют выбрать способ вычисления функций: последовательный, паралелльный или векторизованный. 
Графики, отражающие процесс работы алгоритма, можно получить с помощью функций вывода графики. Они задаются параметром
PlotFcns, а набор соответствующих функций пакета дан в прил. 4. 
При использовании собственной функции ее первая строка должна соответствовать синтаксису
function stop = plotfun(optimvalues, flag), 
где optimvalues – структура, содержащая поля: 
x – текущая точка,
iteration – номер итерации, 
fval – значение целевой функции, 
meshsize – текущий размер окружения, 
funccount – число вычислений функции, 
method – метод, использованный в последней итерации, 
TolFun – допуск на значение целевой функции
TolX – допуск на x, 
nonlinineq – индикация нелинейных неравенств, 
nonlineq – индикация нелинейных равенств; 
flag – текущее состояние, в котором вызвана функция, его значения: 
init – начальное состояние, 
76 
iter – процесс итераций, 
interrupt – промежуточная стадия, 
done – конечное состояние. 
Аналогично может быть подключена стандартная функция или
функции вывода данных о ходе процесса параметром OutputFcns. 
Описание собственной функции вывода должно начинаться со строки
[stop,options,optchanged] = 
psoutputhistory(optimvalues,options,flag,interval), 
где interval – число итераций между вызовами функции, 
optchanged – индикатор изменения параметров, stop равен false
при продолжении работы алгоритма и true при завершении на текущей итерации. 
Пример 12. 
Найдем минимумы функции
F = 5 + 2|x1–1| + 0,5| x1–3| + 0,7| x2 + 3|+| x2 – 2| + 2sin(x1 + x2) 
при условиях
–4  xi  5, i = 1, 2. 
Как видно, целевая функция дифференцируема не всюду, что не
позволяет использовать методы, требующие градиента. Поэтому для
решения нашей задачи применим метод прямого поиска Direct 
Search. На рис. 19 представлен 3D-график целевой функции, из которого следует, что функция имеет по крайней мере два минимума. 
Как и раньше, сначала функцию запишем в два m-файла – один для
ее вычислений в алгоритме, второй для графического представления: 
function f = direct1(x) 
f=5+abs(x(1)-1)*2+abs(x(1)-... 
3)*0.5+abs(x(2)+3)*0.7+abs(x(2) -2)+... 
2*sin(x(1)+x(2)); 
function z = direct_g(x,y) 
z=5+abs(x-1)*2+abs(x-3)*0.5+abs(y+3)*0.7+abs(y-2)... 
+2*sin(x+y); 
77 
Рис. 19. Вид целевой функции из примера 12 
Составим программу, в которой все параметры поиска имеют значения по умолчанию и предусмотрено отображение линий уровня целевой функции и лучших точек каждой итерации. Программу представим как функцию начальной точки x0: 
function history=directsearch(x0) 
 history.x=x0; 
 history.fval=[]; 
 options= psoptimset('PlotFcn',@outfun); 
 [x,fval,flag,output] = patternsearch(@direct1, ... 
x0,[],[],[],[],[-4 -4],[5 5],[],options) 
 y=history.x(:,1);z=history.x(:,2); 
plot(y,z,'r.',x(1),x(2),'r*');hold on; 
[X,Y]=meshgrid(-4:0.03:5);Z=direct_g(X,Y); 
contour(X,Y,Z,25,'blue');xlabel('x1');ylabel('x2'); 
 function stop = outfun(optimvalues,flag) 
 stop = false; 
 switch flag 
 case 'init' 
 hold on 
 case 'iter' 
 % Concatenate current point and objective function 
78 
 history.fval = [history.fval; optimvalues.fval]; 
 history.x = [history.x; optimvalues.x]; 
 end 
 end 
end 
Запустим программу из точки (–4 3), результаты ее выполнения
приведены ниже. 
>> x0=[-4 3]; history=directsearch(x0) 
Optimization terminated: mesh size less than options.TolMesh. 
x = 
 1.8643 2.0000 
fval = 
 9.4736 
flag = 
 1 
output = 
 function: @direct1 
 problemtype: 'boundconstraints' 
 pollmethod: 'gpspositivebasis2n' 
 searchmethod: [] 
 iterations: 48 
 funccount: 152 
 meshsize: 9.5367e-007 
 maxconstraint: 0 
 message: 'Optimization terminated: mesh size less than options.TolMesh.' 
history = 
 x: [49x2 double] 
 fval: [48x1 double] 
Отчет показывает, что использован метод создания окружения
(pollmethod) GPS 2N и за 48 итераций найден один из минимумов, 
о чем свидетельствует значение flag. Чтобы посмотреть, как изменялись значения x, обратимся к history.x: 
79 
>> history.x 
ans = 
 -4.0000 3.0000 
 -4.0000 2.0000 
 -2.0000 2.0000 
 -2.0000 2.0000 
 -2.0000 2.0000 
 2.0000 2.0000 
 2.0000 2.0000 
 2.0000 2.0000 
 2.0000 2.0000 
 2.0000 2.0000 
 2.0000 2.0000 
 1.7500 2.0000 
 1.7500 2.0000 
 1.7500 2.0000 
 1.8750 2.0000 
 1.8750 2.0000 
 1.8750 2.0000 
 1.8750 2.0000 
 1.8750 2.0000 
 1.8594 2.0000 
 1.8594 2.0000 
 1.8594 2.0000 
 1.8672 2.0000 
 1.8672 2.0000 
 1.8672 2.0000 
 1.8633 2.0000 
 1.8633 2.0000 
 1.8633 2.0000 
 1.8652 2.0000 
 1.8652 2.0000 
 1.8652 2.0000 
 1.8643 2.0000 
80 
 1.8643 2.0000 
 1.8643 2.0000 
 1.8643 2.0000 
 1.8643 2.0000 
 1.8644 2.0000 
 1.8644 2.0000 
 1.8644 2.0000 
 1.8643 2.0000 
 1.8643 2.0000 
 1.8643 2.0000 
 1.8643 2.0000 
 1.8643 2.0000 
 1.8643 2.0000 
 1.8643 2.0000 
 1.8643 2.0000 
 1.8643 2.0000 
 1.8643 2.0000 
Из этих данных видно, что уже на шестой итерации точка оказывается вблизи минимума, затем ряд изменений размера окружения не
дает улучшения и в последующем идет уточнение первой координаты
до достижения заданной точности по размеру окружения (meshsize= 
9.5367e-007< TolMesh). На рис. 20, где эти точки представлены красными ромбиками, шестая точка самая правая, а точка минимума выделена символом *. 
Заметим, что по этим результатам мы не можем утверждать о глобальности найденного минимума, даже зная о наличии только двух
минимумов. Необходимо найти второй минимум и сравнить значения
функции в двух минимумах. 
Поэтому повторим поиск из другой точки: 
>> x0=[-3.5 2];history=directsearch(x0) 
Результаты поиска приводятся ниже. 
81 
Рис. 20. Поиск минимума функции direct1
методом Direct Search из точки (–4 3) 
Optimization terminated: mesh size less than options.TolMesh. 
x = 
 1.0000 -2.4202 
fval = 
 8.8487 
flag = 
 1 
output = 
 function: @direct1 
 problemtype: 'boundconstraints' 
 pollmethod: 'gpspositivebasis2n' 
 searchmethod: [] 
 iterations: 46 
 funccount: 159 
 meshsize: 9.5367e-007 
 maxconstraint: 0 
 message: 'Optimization terminated: mesh size less than options.TolMesh.' 
82 
Как продвигался этот поиск, можно видеть на рис. 21. На этот раз
достигнут второй минимум, и он оказался более глубоким, а следовательно, глобальным. 
Рис. 21. Поиск минимума функции direct1
методом Direct Search из точки (–3,5, 2) 
Возьмем еще одну точку справа от минимумов: 
>> x0=[4.5 3]; history=directsearch(x0) 
Optimization terminated: mesh size less than options.TolMesh. 
x = 
 1.0000 -2.4202 
fval = 
 8.8487 
flag = 
 1 
output = 
 function: @direct1 
 problemtype: 'boundconstraints' 
 pollmethod: 'gpspositivebasis2n' 
 searchmethod: [] 
 iterations: 48 
 funccount: 167 
83 
 meshsize: 9.5367e-007 
 maxconstraint: 0 
 message: 'Optimization terminated: mesh size less than options.TolMesh.' 
Полученные данные и рис. 22 свидетельствуют о том, что снова
достигнут глобальный минимум. Однако еще один поиск из начальной
точки (3,5 –4) не приводит к глобальному минимуму: 
>> x0=[-3.5 -4];history=directsearch(x0) 
Optimization terminated: mesh size less than options.TolMesh. 
x = 
 1.8643 2.0000 
fval = 
 9.4736 
flag = 
 1 
iterations: 60 
funccount: 170 
Из этого можно заключить, что результат работы алгоритма GPS
случаен и зависит от выбора начальной точки. 
Рис. 22. Поиск минимума функции direct1 
методом Direct Search из точки (4,5 3) 
84 
Теперь посмотрим, что даст алгоритм MADS. Установим его в опциях, указав как аргумент функции psoptimset параметр PollMethod
со значением 'MADSPositiveBasis2N'. Запустим программу из предыдущей точки: 
>> x0=[-3.5 -4]; history=directsearch(x0) 
Optimization terminated: mesh size less than 'sqrt(TolMesh)'. 
x = 
 1.0000 -2.4202 
fval = 
 8.8487 
flag = 
 1 
output = 
 function: @direct1 
 problemtype: 'boundconstraints' 
 pollmethod: 'madspositivebasis2n' 
 searchmethod: [] 
 iterations: 42 
 funccount: 197 
Мы видим, что в отличие от GPS алгоритм MADS, стартуя из этой
точки, находит глобальный минимум. Однако из точки (–4 3) метод
MADS, как и GPS, приводит только к локальному минимуму, и вывод о
случайности нахождения глобального минимума методом Direct 
Search остается в силе. 
Продолжим исследование этого метода и подключим один из
вспомогательных методов search нахождения шага. Для этого используем параметр SearchMethod со значением, например, 
@searchneldermead, тем самым указываем на метод Нелдера – Мида
(функция fminseach). Вот результаты: 
>> x0=[-4 3]; history=directsearch(x0) 
Optimization terminated: mesh size less than options.TolMesh. 
x = 
 1.8643 2.0000 
fval = 
 9.4736 
flag = 
 1 
85 
output = 
 function: @direct1 
 problemtype: 'boundconstraints' 
 pollmethod: 'gpspositivebasis2n' 
 searchmethod: @searchneldermead 
 iterations: 33 
 funccount: 253 
 meshsize: 9.5367e-007 
 maxconstraint: 0 
 message: 'Optimization terminated: mesh size less than options.TolMesh.' 
Очевидно, что подключение searchneldermead не дало улучшения. Тогда возьмем опцию searchlhs. По умолчанию она влияет
только на первую итерацию, на которой поиск происходит в латинском
гиперкубе (LHS). Гиперкуб представляет собой набор случайно сгенерированных точек на нескольких уровнях по каждой переменной. По
умолчанию установлен вариант, по которому пары точек симметричны
относительно центра куба. 
Итак, изменив значение аргумента SearchMethod на
@searchlhs, повторим поиск из той же точки:
>> x0=[-4 3];history=directsearch(x0) 
Optimization terminated: mesh size less than options.TolMesh. 
x = 
 1.0000 -2.4202 
fval = 
 8.8487 
flag = 
 1 
output = 
 function: @direct1 
 problemtype: 'boundconstraints' 
 pollmethod: 'gpspositivebasis2n' 
 searchmethod: @searchlhs 
 iterations: 73 
 funccount: 242 
 meshsize: 9.5367e-007 
 maxconstraint: 0 
86 
Рис. 23. Картина поиска методом GPS из точки (–4, 3) 
при подключении searchlhs
Как видно по распечатке результатов и рис. 23, из этой точки, наконец, достигнут глобальный минимум. Остается проверить надежность этого варианта поиска. Повторим поиск из этой же точки: 
x0=[-4 3]; history=directsearch(x0) 
Optimization terminated: mesh size less than options.TolMesh. 
x = 
 1.8643 2.0000 
fval = 
 9.4736 
flag = 
 1 
output = 
 function: @direct1 
 problemtype: 'boundconstraints' 
 pollmethod: 'gpspositivebasis2n' 
 searchmethod: @searchlhs 
 iterations: 67 
 funccount: 227 
 meshsize: 9.5367e-007 
 maxconstraint: 0 
 message: [1x61 char] 
87 
Рис. 24. Повторный поиск из точки (–4 3) 
при подключении searchlhs
Значение целевой функции (fval=9.4736) и рис. 24 показывают, что
результат поиска изменился: найденный минимум является только локальным. 
Подводя итог экспериментам с применением метода Direct 
Search, можно сказать, что за один поиск этот метод позволяет находить только один минимум, который может быть как локальным, так и
глобальным. 
4.4. Метод Simulated Annealing
Это стохастический метод, предназначенный для решения задач
безусловной оптимизации и задач при наличии границ на переменные. 
Метод моделирует процесс нагревания материального тела с последующим медленным снижением температуры для уменьшения дефектов. 
Итерация алгоритма Simulated Annealing начинается с генерирования новой случайной точки с использованием для этого датчика
псевдослучайных чисел. Расстояние между новой и текущей точкой
называется размером поиска. Размер определяется по распределению
вероятностей, шкала которого пропорциональна текущей температуре. 
Если целевая функция в новой точке лучше, чем в текущей, то новая
88 
точка становится текущей (принимается). В противном случае новая
точка также может стать текущей, т.е. принятой, но только с некоторой
вероятностью. Это делается для того, чтобы по возможности избегать
«застревания» в локальном минимуме. Процесс отжига определяется
начальной температурой и графиком отжига, которые задаются параметрами InitialTemperature и TemperatureFcn соответственно. 
По ходу выполнения алгоритм систематически понижает температуру
согласно графику отжига, сохраняя при этом лучшую найденную точку. Чем медленнее уменьшается температура, тем больше шансов найти оптимальное решение, но тем больше требуется времени. После определенного числа принятых точек, задаваемого параметром ReannealInterval, происходит переотжиг. Он повышает температуру в
каждом измерении в зависимости от его чувствительности, после чего
поиск продолжается с новыми значениями температур. Алгоритм останавливается, когда выполняется один из критериев останова. 
В качестве этих критериев используются следующие условия: 
– среднее изменение значения целевой функции, вычисляемое по
числу итераций, заданному параметром StallIterLimit, меньше
TolFun; 
– число итераций алгоритма превысило MaxIter; 
– число вычислений целевой функции превысило MaxFunEval; 
– время выполнения алгоритма превысило TimeLimit (с); 
– лучшее значение целевой функции не больше ObjectiveLimit; 
Все параметры алгоритма, устанавливаемые через saoptimset, 
приведены в прил. 5. Если нужно получить значения по умолчанию
всех параметров, то достаточно выполнить команду
options = saoptimset('simulannealbnd') 
Если же требуется изменить значения некоторых параметров, то
они описываются парами «имя, значение» каждого изменяемого параметра как аргументы функции saoptimset, например, 
options = saoptimset(‘Maxiter’,1000,’Display’,’iter’) 
Параметр PlotFcns позволяет использовать следующие функции
графики: 
@saplotbestf отображает лучшее значение целевой функции,
@saplotbestx выводит лучшую точку,
@saplotf представляет текущее значение целевой функции,
89 
@saplotx выводит текущую точку,
@saplotstopping показывает уровни критериев остановки,
@saplottemperature выводит температуру на каждой итерации, 
@myfun – функция, создаваемая пользователем. 
Структура пользовательской функции такая же, как для метода
directsearch, а входной аргумент optimvalues содержит поля: 
x – текущая точка, 
fval – значение целевой функции в х, 
bestx – лучшая точка к данному моменту, 
bestfval – значение целевой функции в этой точке, 
temperature – текущая температура, 
iteration – текущая итерация, 
funccount – число вычислений функции, 
t0 – время старта алгоритма, 
k – параметр отжига. 
При необходимости использовать две или более функций графики
они перечисляются в фигурных скобках, например, 
options = saoptimset('PlotFcns',{@saplottemperature,@myfun}) 
Поведение температуры задается тремя параметрами: начальной
температурой InitialTemperature, функцией изменения температуры TemperatureFcn и числом принятых точек перед переотжигом
ReannealInterval. В качестве функции TemperatureFcn могут
быть указаны следующие: 
@temperatureexp — температура равна InitialTemperature*0.95^i, где i – номер итерации (эта функция принята по умолчанию),
@temperaturefast — температура равна InitialTemperature/i,
@temperatureboltz — температура равна InitialTemperature/ln(i), 
@myfun — функция, создаваемая пользователем.
С помощью параметра AnnealingFcn можно выбрать функцию
генерации новых точек. Кроме функции, создаваемой пользователем, в
пакете имеются две функции: @annealingfast, которая использует
шаг, соответствующий температуре и случайно направленный, и
90 
@annealingboltz с шагом, соответствующим корню квадратному из
температуры и имеющим случайное направление. При создании пользовательской функции используется синтаксис
newx = myfun(optimValues,problem), 
где problem – структура с полями
objective – целевая функция, 
x0 – стартовая точка, 
nvar – число переменных задачи, 
lb – нижняя граница, 
ub – верхняя граница. 
Параметр HybridFcn позволяет вызывать в течение работы основной функции метода simulannealbnd или по окончании итераций решателя другую функцию оптимизации для улучшения конечного результата. В качестве такой функции могут быть fminsearch, 
patternsearch, fminunc или fmincon. При необходимости изменения параметров этих функций используются соответствующие им опции, например: 
hybridopts=optimset('display','iter','LargeScale','off'); 
options=saoptimset(options,'HybridFcn',{@fminunc,hybridopts}); 
Для указания интервала работы решателя, на котором вызывается
другая функция, используется параметр HybridInterval. 
Чтобы получить данные по каждой итерации решателя, пользователь должен создать соответствующую(ие) функцию(и) вывода, указав
ее(их) в качестве значения(й) параметра OutputFcns. Собственная
функция записывется аналогично пользовательской, рассмотренной в
предшествующем методе, а содержание optimvalues дано выше при
описании PlotFcns. 
Как уже отмечалось, метод моделирования отжига реализован в
виде функции simulannealbnd. Чтобы решить задачу, достаточно установить нужные или принять по умолчанию значения параметров и
вызвать функцию метода. Узнать значения по умолчанию всех параметров можно командой
options = saoptimset('simulannealbnd') 
91 
Обращение к функции возможно по одному из приводимых ниже
вариантов: 
x = simulannealbnd(fun,x0) 
x = simulannealbnd(fun,x0,lb,ub) 
x = simulannealbnd(fun,x0,lb,ub,options) 
x = simulannealbnd(problem) 
[x,fval] = simulannealbnd(...) 
[x,fval,exitflag] = simulannealbnd(...) 
[x,fval,exitflag,output] = simulannealbnd(fun,...) 
Смысл всех аргументов ясен из рассмотрения предыдущих функций оптимизации. Первый вариант применяется, если решается задача
на безусловный экстремум. При наличии границ на переменные используется второй вариант. Если устанавливаются свои значения некоторых параметров, то обязателен третий вариант. На месте отсутствующих входных аргументов (кроме последнего) записывается []. 
Содержание выходных аргументов exitflag и output специфично для данной функции. Exitflag сообщает причину завершения
алгоритма через значения: 
1 – среднее значение целевой функции по StallIterLimit итерациям меньше, чем TolFun, 
5 – достигнут предел ObjectiveLimit, 
0 – исчерпано максимальное число вычислений функции или итераций, 
-1 – процесс остановлен функцией вывода или графики, 
-2 – не найдено допустимой точки, 
-5 – исчерпан лимит времени. 
Структура output содержит информацию о задаче и выполнении
алгоритма в следующих полях: 
problemtype – тип задачи (без ограничений или с границами), 
iterations – число итераций, 
funccount – число вычислений целевой функции, 
message – сообщение о причине останова, 
temperature – температура на момент остановки, 
totaltime – общее время работы решателя, 
rngstate – состояние датчика случайных чисел перед началом
работы алгоритма. 
Рассмотрим примеры применения функции simulannealbnd. 
92 
Пример 13. 
Методом Simulated Annealing найти минимум исследованной
ранее в примерах 7 и 9 функции 
f = 3(1– x1)
2
exp (– 2
1 x – (x2 + 1)2
) –10( x1/5 – 3
1 x – 5
2 x )exp (– 2
1 x – 2
1 x ) – 
–1/3exp (–(x1 + 1)2 – 2
2 x ) 
при условиях
–3  xj  3, j = 1, 2. 
Эта функция записана в m-файлах myfun(x) и myfun1(X,Y), последний из них предназначен для графического отображения функции. 
Для получения численного ответа достаточно обратиться к функции
метода по одному из описанных выше вариантов. Однако мы составим
программу нахождения минимума с именем runsa, используя в ней не
только первый, но и второй файл целевой функции с тем, чтобы полнее
и нагляднее представить результаты работы метода. 
function history=runsa(x0) 
history.x=x0; 
history.fval=[]; 
options= saoptimset('PlotFcn',@outfun); 
history.t=[]; 
[x,fval,exitflag,output]=simulannealbnd(@myfun,x0,... 
[-3 -3], [3 3],options) 
y=history.x(:,1);z=history.x(:,2); 
plot(y,z,'r.',x(1),x(2),'r*'); 
text(x0(1),x0(2)+0.12,'x0'); 
hold on; [X,Y]=meshgrid(-3:0.03:3);Z=myfun1(X,Y); 
contour(X,Y,Z,25,'blue');xlabel('x1');;ylabel('x2'); 
 function stop = outfun(options,optimvalues,flag) 
 stop = false; 
 switch flag 
 case 'init' 
 hold on 
 case 'iter' 
 % Concatenate current point, objective 
 % function and temperature 
 history.fval = [history.fval;... 
 optimvalues.bestfval]; 
 history.x = [history.x;... 
93 
 optimvalues.bestx]; 
 history.t=[history.t;... 
 optimvalues.temperature]; 
 end 
 end 
 t1=[];for i=1:2:output.iterations; 
 t1(i)=history.t(i); 
 end 
 figure;plot(t1);xlabel('N of iteration'); 
 ylabel('t1'); 
end 
Запустим программу из двух начальных точек: 
>> x0=[2 2.5]; history=runsa(x0) 
Optimization terminated: change in best function value less than options.TolFun. 
x = 
 0.2270 -1.6230 
fval = 
 -6.5510 
exitflag = 
 1 
output = 
 Iterations: 1650 
 funccount: 1669 
 message: [1x80 char] 
 rngstate: [1x1 struct] 
 problemtype: 'boundconstraints' 
 temperature: [2x1 double] 
 totaltime: 11.8281 
history = 
 x: [1651x2 double] 
 fval: [1650x1 double] 
 t: [3300x1 double] 
Решение получено за 1650 итераций, на что потребовалось 11,83 с. 
В результате найден глобальный минимум. На рис. 25 на фоне линий
уровня целевой функции показаны лучшие точки, начиная с x0, а на
рис. 26 – изменение температуры в измерении x1. 
94 
Рис. 25. Поиск минимума функции myfun из точки (2 2,5) 
методом simulannealbnd
Рис. 26. График изменения температуры по x1
при поиске из точки (2 2,5) 
95 
Как видно, переотжиг происходил четыре раза через интервалы от
300 до 400 итераций. Узнаем температуру в финальной точке: 
по x1 >> history.t(3299) 
 ans = 
 0.2962 
по x2 >> history.t(3300) 
 ans = 
 0.2882 
Повторим поиск из новой точки: 
>> x0=[-1 1]; history=runsa(x0) 
Optimization terminated: change in best function value less than options.TolFun. 
x = 
 0.2276 -1.6258 
fval = 
 -6.5511 
exitflag = 
 1 
output = 
 iterations: 2314 
 funccount: 2341 
 message: [1x80 char] 
 rngstate: [1x1 struct] 
 problemtype: 'boundconstraints' 
 temperature: [2x1 double] 
 totaltime: 20.6406 
history = 
 x: [2315x2 double] 
 fval: [2314x1 double] 
 t: [4628x1 double] 
Мы получили тот же результат, однако на это ушло значительно
больше итераций и времени решателя. На рис. 27 представлено расположение лучших на текущую итерацию точек от начальной и до оптимальной, обозначенной символом *, и график изменения температуры
по x1. По x2 температурный график имеет аналогичный вид. В отличие от предыдущего, в процессе этого поиска переотжиг производился
семь раз. 
96 
Рассмотрим еще один пример применения метода моделирования
отжига. 
Пример 14. 
Найти максимум функции 2 2 4 4 1 12 1 2 2 44 (1 20,25( ) ) (2 (0,5 0,5) ( 1) )
1 12 1,5 (0,5 0,5) ( 1) x xx x x f xe x x e         
при условиях
0  x1  4, 0  x2  3. 
Рис. 27. Поиск минимума функции myfun из точки (–1 1) методом simulannealbnd: слева – лучшие точки, справа – график температуры по x1
Как и выше, записываем целевую функцию в m-файлы в двух вариантах: 
function f = multiextr1(x) 
f=-1.5*x(1)^2*exp(1-x(1)^2-20.25*(x(1)-x(2))^2)-... 
(0.5*x(1)-0.5)^4*(x(2)-1)^4*exp(2-(0.5*x(1)-0.5)^4-... 
(x(2)-1)^4); 
end 
function f = multiextr1_g(x,y) 
f=1.5*x.^2.*exp(1-x.^2-20.25*(x-y).^2)+... 
(0.5*x-0.5).^4.*(y-1).^4.*exp(2-(0.5*x-0.5).^4-(y1).^4)+0.5; 
end 
Вид функции multiextr1_g показан на рис. 28, из которого следует наличие у функции многих экстремумов, в частности четырех
максимумов. 
Для поиска максимума этой функции в программе runsa заменяем
имена функций и значения границ переменных на новые, затем запускаем ее с задаваемой начальной точки. Результаты выполнения программы приведены ниже. 
97 
>> x0=[3 1.4];history=runsa(x0) 
Optimization terminated: change in best function value less than options.TolFun. 
x = 
 1.0016 1.0028 
fval = 
 -1.5000 
exitflag = 
 1 
output = 
 iterations: 1601 
 funccount: 1620 
 message: [1x80 char] 
 rngstate: [1x1 struct] 
 problemtype: 'boundconstraints' 
 temperature: [2x1 double] 
 totaltime: 11.7031 
history = 
 x: [1602x2 double] 
 fval: [1601x1 double] 
 t: [3202x1 double] 
Рис. 28. Вид функции multiextr1_g 
98 
Полученные данные и рис. 29 показывают, что найден глобальный
максимум, расположенный на гребне целевой функции. Поиск занял
1601 итерацию. За время поиска переотжиг выполнялся пять раз. Температуры в конечной точке поиска берем из history: 
>> [history.t(3201),history.t(3202)] 
ans = 
 0.0077 0.0073 
Рис. 29. Контуры функции multiextr1_g 
и расположение лучших точек
Два приведенных примера свидетельствуют о высокой надежности отыскания глобального экстремума методом моделирования отжига. Однако следует помнить, что этот метод не решает задачи с функциональными ограничениями. 
Лабораторная работа № 4 
Исследование методов прямого поиска и отжига
Задания: 
1. Ознакомиться с описанием методов DirectSearch и Simulated
Annealing и вызовом соответствующих функций, изучить основные
параметры методов. 
99 
2. Воспроизвести программу из примера 12 и провести ее запуски
из одной точки, но при разных алгоритмах прямого поиска; исследовать влияние параметра Complete poll. 
3. К задаче из примера 12 добавить условие x1 + x2  –2 и сравнить
результаты поиска разными алгоритмами прямого поиска. 
4. Методом прямого поиска найти минимумы функции 
f1 = (x1 + sin x1) 2
1x
e

(1,5–x2)
2 при условиях –5  x1  5, –4  x2  5. 
5. Воспроизвести программу из примера 14 и исследовать метод
моделирования отжига при изменении параметров AnnelingFcn, HybridFcn и начальной температуры. 
6. Методом моделирования отжига найти глобальный минимум
функции multiextr
f2 = 
2 2
12 1 2 x   xx x cos(18 ) cos(18 )
при условиях –0,5  xj  1, j = 1, 2. Выяснить влияние начальной температуры отжига. 
Вид функции f2 показан на рис. 30. 
Рис. 30. Функция multiextr
7. Сравнить результаты поиска минимума функции f2 методами
DirectSearch и Simulated Annealing. 
100 
4.5. The Genetic Algorithm 
Генетический алгоритм использует терминологию, заимствованную из биологии и отличную от стандартных методов оптимизации. 
Оптимизируемая функция в генетическом алгоритме называется фитнес-функцией (fitness function). Каждой итерации алгоритма соответствует набор точек, образующих популяцию (population), а отдельные точки называются особями (individuals). Особь представляется вектором (геномом), состоящим из генов. Популяция
представляется матрицей с числом строк, равным размеру популяции, 
и числом столбцов, равным числу переменных. Значение фитнесфункции особи есть ее метка (score). Последовательности итераций
алгоритма соответствует последовательность популяций, называемых
поколениями (generations). 
Популяция характеризуется разнообразием (diversity), которое
оценивается средним расстоянием между особями популяции. Чем оно
больше, тем разнообразие выше и тем бόльшая область пространства
поиска охватывается популяцией. Для создания нового поколения алгоритм выбирает определенные особи из текущей популяции в качестве родителей (parents) и использует их для создания индивидуальностей нового поколения, называемых потомками или детьми
(children). Эти действия выполняются специальными операторами
генетического алгоритма. В целом алгоритм включает три этапа: 
1. Генерация начальной популяции с помощью датчика случайных
чисел. 
2. Создание последовательности новых популяций. Для этого на
каждом шаге алгоритм использует особи текущего поколения для образования следующей популяции, выполняя последовательно шаги: 
а) помечает каждую особь текущей популяции посредством вычисления значения фитнес-функции; 
б) масштабирует полученные метки, преобразуя их к более удобному диапазону значений; 
в) выбирает родителей, основываясь на их фитнес-функциях; 
г) несколько особей с более низкими значениями фитнеса, как
элитные, переводит в новую популяцию; 
101 
д) порождает из родителей потомков путем случайных изменений
у одного из родителей (мутация, mutation) или комбинируя гены пары родителей (скрещивание, crossover) 
е) заменяет текущую популяцию потомками, формируя следующее поколение. 
3. Завершение алгоритма при выполнении критерия останова. 
Рассмотрим более полно эти этапы и реализующие их функции. 
Начальная популяция определяется ее размером (Population size), 
который по умолчанию равен 20, и диапазоном (Initial range), по
умолчанию равным [0; 1]. Подробнее об этих и других параметрах сказано ниже. 
Обычно в качестве родителей выбираются особи, имеющие лучшие значения фитнес-функции. Однако можно задать другую функцию
отбора родителей, указав ее как значение параметра Selectionfcn
(прил. 6). 
Как следует из описания этапов, алгоритм использует три способа
получения потомков: элитизм, скрещивание пар родителей и мутацию
одного из родителей. При скрещивании по умолчанию в каждую позицию (локус) потомка переносится ген из той же позиции одного из родителей, выбранного случайно (равномерный кроссовер). Мутация по
умолчанию выполняется добавлением к вектору родителя случайного
вектора с гауссовским распределением. 
В качестве критериев остановки применяются следующие условия: 
– превышено заданное число поколений (параметр Generations), 
– исчерпан лимит времени поиска (Time limit), 
– значение фитнес в лучшей точке не больше Fitness limit, 
– средневзвешенное изменение значения фитнеса на ряде поколений
(Stall generations) меньше допустимости (Function tolerance), 
– нет улучшения функции в течение интервала времени Stall time 
limit (с). 
Заметим, что генетический алгоритм может решать задачи, содержащие границы переменных, линейные и нелинейные ограничения. 
При этом используется подход, аналогичный рассмотренному в методе
Direct search (The Augmented Lagrangian Genetic 
Algorithm (ALGA)), т.е. нелинейные ограничения вводятся в функцию Лагранжа, которая минимизируется ga при выполнении условий
102 
по границам и линейным ограничениям. Нарушение нелинейных ограничений сопоставляется с параметром Nonlinear constraint 
tolerance (по умолчанию 1е
-6). 
Генетический алгоритм реализован в функции ga, а для задания
параметров алгоритма используется функция gaoptimset. Если ввести в командную строку
options = gaoptimset(@ga), 
то будет создана структура параметров, имеющих значения по умолчанию. Для изменения параметров каждый параметр указывается в виде
пары «’имя’, значение» как аргументы функции gaoptimset. Все параметры генетического алгоритма, их смысл и значения по умолчанию
приведены в прил. 6. 
Важным параметром алгоритма является размер популяции
(PopulationSize), его значением может быть целое положительное
число или целочисленный вектор. Во втором случае будет создано
столько подпопуляций, какова размерность вектора, а размер подпопуляций будет равен значениям компонент вектора. 
Параметр PopulationType задает тип данных популяции, его
значениями могут быть: 'bitstring', 'custom' (оба при отсутствии ограничений), 'doubleVector' (по умолчанию). 
Следующим параметром популяции является CreationFcn, который определяет функцию, создающую начальную популяцию. Ga
предлагает три варианта функций: 
1) равномерная (@gacreationuniform), создающая случайную
начальную популяцию с равномерным распределением, используется
по умолчанию при отсутствии границ или ограничений; 
2) допустимая популяция (@gacreationlinearfeasible), создающая случайную начальную популяцию, удовлетворяющую всем
границам и линейным ограничениям, используется по умолчанию при
наличии таких ограничений; 
3) Custom (собственная), написанная пользователем и генерирующая данные, тип которых должен соответствовать определенному
в PopulationType. 
В последнем случае функция задается в опциях как
options = gaoptimset('CreationFcn', @mycreat)
103 
где mycreat – имя собственной функции, первая строка определения
которой имеет вид
function Population = mycreat(GenomeLength, FitnessFcn, 
options),
где GenomeLength – число независимых переменных, FitnessFcn – 
фитнес-функция. Можно задать начальную популяцию или ее часть, указав массив, ее содержащий, в параметре InitialPopulation. При этом
число строк массива не должно превышать значение параметра
PopulationSize, а число столбцов равно числу переменных. Недостающие особи будут созданы стандартной функцией. В параметре
PopInitRange можно указать диапазон значений переменных в начальной популяции в виде вектор-столбца или матрицы с двумя строками и
числом столбцов, равным числу переменных. По умолчанию этот параметр равен [0;1], т.е. для всех переменных установлен диапазон от 0 до 1. 
Перед применением оператора выбора алгоритм масштабирует
фитнес для удобства выполнения выбора. По умолчанию применяется
ранговая функция масштабирования fitscalingrank, которая лучшим
индивидуумам присваивает ранг 1, следующим 2 и т.д. Параметром
FitnessScalingFcn можно задать другой вид масштабирования: пропорциональное (fitscalingprop), основанное на лучших особях
(fitscalingtop), смещенное линейное (fitscalingshiftlinear), 
или написать собственную функцию. 
Для выбора родителей алгоритм предлагает несколько функций. 
По умолчанию выбор реализует стохастическая функция
selectionstochunif. В ней используется линия (аналог рулетки), 
разбитая на участки, длина которых пропорциональна масштабированному качеству особи. Вдоль линии выполняются шаги одинакового
размера. Выбирается родитель из участка, на котором завершен очередной шаг. Первый шаг равен равномерному случайному числу, 
меньшему заданного размера шага. 
Изменить функцию выбора можно заданием ее имени в значении параметра SelectionFcn. Дополнительно имеются следующие функции: 
– Функция остатка selectionremainder, которая число родителей от одной особи берет равным целой части масштабированной целевой функции, а недостающие родители выбираются стохастически с
вероятностью, пропорциональной дробной части. 
104 
– Функция равномерности (однородности) selectionuniform,
рекомендуется только на стадии отладки или испытаний. 
– Функция рулетки selectionroulette, использующая модель
рулетки, размер секторов которой пропорционален качеству особей. 
Выбирается родитель сектора, на который выпало случайное число. 
– Турнирная функция selectiontournament, реализующая метод турниров. Случайно выбираются несколько особей, и родителем
становится лучшая из них. По умолчанию число выбираемых особей, 
т.е. размер турнира, равно 4. Размер не должен быть меньше 2, а изменить его можно в опциях
options = gaoptimset('SelectionFcn',... 
{@selecttournament,size}), 
где size – размер турнира. 
Кроме того, пользователь может написать собственную функцию
выбора. При этом заголовок функции, например с именем myfun, 
должен иметь вид
function parents = myfun(expectation, nParents, options), 
где expectation – ожидаемое число детей для каждой особи популяции, nParents – число выбираемых родителей. Функция выбора
возвращает родителей в виде вектор-строки длиной nParents, содержащей индексы родителей. 
Создание детей для нового поколения регулируется двумя параметрами: 
EliteCount определяет число элитных особей, которые гарантированно переходят без изменений в новое поколение, по умолчанию
оно равно 2; 
CrossoverFraction устанавливает долю нового поколения, порождаемую кроссовером (по умолчанию 0,8). 
Управление мутацией, т.е. созданием детей внесением в индивидуумы малых случайных изменений, обеспечивает параметр
MutationFcn. Он задает функцию мутации, которой может быть: 
– Mutationgaussian, устанавливаемая по умолчанию. Она к
каждому гену родителя добавляет случайное число, взятое из распределения Гаусса со средним 0 и дисперсией, определяемой параметрами
Scale и Shrink (по умолчанию они равны 1). Изменить их можно, 
задав конкретные значения в опциях: 
options = gaoptimset('MutationFcn',... 
{@mutationgaussian,scale,shrink}). 
105 
– Mutationuniform производит мутацию в два шага. Сначала
выбирается часть генов особи, каждый ген которой может мутировать
с вероятностью Rate, по умолчанию равной 0,01. На втором шаге выбранный ген заменяется случайным числом с равномерным распределением из диапазона значений данного гена. Изменить вероятность
Rate можно в опциях
options = gaoptimset('MutationFcn', {@mutationuniform, 
rate}). 
– Mutationadaptfeasible генерирует случайные направления, адаптированные к прошлым результатам генерации. Длина шага
вдоль каждого направления выбирается так, чтобы соблюдались линейные ограничения и границы на переменные. 
– Собственная функция мутации, заголовок описания которой
имеет вид
function mutationChildren = myfun(parents, options, 
nvars, FitnessFcn, state, thisScore, thisPopulation), 
где parents – вектор-строка родителей, отобранных функцией выбора; 
nvars – число переменных; 
state – структура, содержащая информацию о текущем поколении; 
thisScore – вектор меток (фитнес) текущей популяции; 
thisPopulation – матрица особей текущей популяции. 
Функции мутации возвращают потомство (детей) от мутации в виде
матрицы, строки которой соответствуют детям, а столбцы переменным. 
Теперь остановимся на функциях кроссовера. По умолчанию установлена функция crossoverscattered, соответствующая рассеянному кроссоверу. Она формирует случайный бинарный вектор (шаблон) с размерностью хромосомы, и если в его позиции стоит 1, то в эту
же позицию потомка помещается соответствующий ген первого родителя, иначе берется ген второго родителя. Параметром CrossoverFcn
можно установить следующие функции:
– Crossoversinglepoint, реализующую одноточечный кроссовер. По случайному числу находится точка разбиения хромосомы, и
родители обмениваются подстроками генов. 
– Crossovertwopoint, соответствующую двухточечному кроссоверу. Выбираются два неравных целых числа, определяющих точки
разбиения, и родители обмениваются генами, расположенными между
этими точками. 
106 
– Crossoverintermediate создает потомков взятием взвешенного среднего родителей. Веса задаются параметром Ratio в виде скаляра или вектора с длиной, равной числу переменных (по умолчанию
единичная вектор-строка). Функция образует детей по формуле
child = parent1 + rand * Ratio * ( parent2 - parent1). 
Значение Ratio можно изменить при задании функции, указав его
после ее имени. 
– Crossoverheuristic возвращает потомка, образуемого по
формуле
child = parent2 + R * (parent1 - parent2), 
где parent1 – родитель с лучшей фитнес-функцией, R – параметр
ratio определяет близость потомка к родителям. Чем ближе R к 1, 
тем ближе потомок к лучшему родителю. По умолчанию R = 1,2, а изменить его можно при задании кроссовера. 
– Crossoverarithmetic создает детей, которые являются
средним арифметическим двух родителей. При этом дети всегда удовлетворяют линейным ограничениям и границам. 
– Собственная функция кроссовера (Custom). В 1-й строке ее определения с именем myfun следует записать
xoverKids = myfun(parents, options, nvars,... 
FitnessFcn, unused,thisPopulation), 
где xoverKids – возвращаемый аргумент в виде матрицы, строки которой являются потомками, unused – служебное слово, означающее, 
что фиксация позиции не используется. 
Если популяция представлена подпопуляциями, то имеет место
движение особей между ними (миграция). Лучшие особи из одной
подпопуляции замещают худшие в другой путем копирования. Процесс миграции управляется тремя параметрами: 
1) направлением (MigrationDirection), которое может иметь
значение 'forward', определяющее движение от n-й к n + 1-й подпопуляции, и 'both', когда особи n-й подпопуляции мигрируют в n – 1-ю
и в n + 1-ю подпопуляции; 
2) интервалом (MigrationInterval), которым задается число
поколений, через которое происходит миграция; 
3) долей мигрирующих особей (MigrationFraction), которая
относится к меньшей подпопуляции (при размерах подпопуляций 20 и
50 и доле 0,1 число мигрантов составит 2). 
107 
При решении задачи с нелинейными ограничениями алгоритм использует значения двух параметров: 
1) начальный штраф (InitialPenalty) устанавливает начальное
значение параметра штрафа в функции Лагранжа; 
2) коэффициент штрафа (PenaltyFactor) увеличивает параметр
штрафа для достижения заданной точности и выполнения ограничений; оба параметра должны быть не меньше 1. 
Параметры алгоритма 'Vectorized' и 'UseParallel' определяют один из способов оценивания фитнес-функции и функции ограничений: последовательный, параллельный или векторный. 
Для указания функций вывода и графики используются параметры
outputfcns и plotfcns. Соответствующие стандартные функции
приведены в прил. 6. При написании собственной функции графики
первая строка должна быть следующей: 
function state = plotfun(options, state, flag), 
где state – структура состояния, содержащая поля: 
Population – популяция текущего поколения, 
Score – метки текущей популяции, 
Generation – номер текущего поколения, 
StartTime – время старта алгоритма, 
StopFlag – описание причины останова, 
Selection – индексы особей элитных, полученных кроссовером и
мутацией, 
Expectation – ожидание выбора особей, 
Best – вектор с лучшими значениями меток в каждом поколении, 
LastImprovement – поколение, на котором произошло последнее
улучшение фитнес-функции, 
LastImprovementTime – время, на котором произошло последнее улучшение, 
NonlinIneq – нелинейные неравенства, если они есть в задаче, 
NonlinEq – нелинейные равенства, если они есть в задаче; 
flag – индикация текущего статуса алгоритма: 'init' – начальная
стадия, 'iter' алгоритм работает, 'interrupt' – промежуточная
стадия, 'done' – алгоритм завершен. 
108 
В описании функции вывода данных каждой итерации первая
строка имеет вид
[state,options,optchanged] = outputfun(options,... 
state,flag,interval), 
где optchanged – флаг индикации изменения параметров, interval – 
факультативный параметр интервала. 
Применение генетического алгоритма
В зависимости от того, какие принимаются параметры, вида ограничений задачи и желаемых выходных данных используется один из
приводимых ниже вариантов вызова функции ga генетического алгоритма. 
x = ga(fitnessfcn,nvars) 
x = ga(fitnessfcn,nvars,A,b) 
x = ga(fitnessfcn,nvars,A,b,Aeq,beq) 
x = ga(fitnessfcn,nvars,A,b,Aeq,beq,LB,UB) 
x = ga(fitnessfcn,nvars,A,b,Aeq,beq,LB,UB,nonlcon) 
x = ga(fitnessfcn,nvars,A,b,Aeq,beq,LB,UB, nonlcon,... 
options) 
x = ga(problem) 
[x,fval] = ga(...) 
[x,fval,exitflag] = ga(...). 
Здесь fitnessfcn – имя фитнес-функции, например @myobj,
nvars – число переменных, exitflag равен целому от 1 до 4, когда
останов происходит по достижении одной из заданных точностей, и от
0 до –5, когда исчерпывается один из заданных лимитов или не найдено допустимое решение; смысл остальных аргументов был приведен
при описании других функций. Еще один вариант вызова функции
[x,fval,exitflag,output] = ga(...) 
приводит к возвращению также и структуры output, содержащей поля: 
rngstate – состояние генератора случайных чисел непосредственно перед стартом алгоритма; для повторного воспроизведения результата решения его можно восстановить; 
generations – число полученных поколений; 
funccount – число вычислений фитнес-функции; 
message – содержит причину останова алгоритма; 
maxconstraint – значение максимального нарушения ограничения. 
109 
Дополнительные выходные данные о решении можно получить, 
применив форму вызова
[x,fval,exitflag,output,population,scores] = ga(...), 
при которой функция возвращает матрицу конечной популяции (population) и вектор ее оценок (scores). 
При каждом старте алгоритма создается новая начальная популяция. Иногда для улучшения результата желательно в качестве начальной популяции использовать конечную популяцию предыдущего запуска. Для этого следует сохранить конечную популяцию с именем, 
например popfin, указав его в качестве четвертого выходного аргумента вызываемой функции
[x,fval,exitflag,output,popfin]=ga(@fitnessfcn,nvars) 
и затем указать это имя в параметре начальной популяции. Очевидно, 
что аналогично можно использовать и новую конечную популяцию в
продолжение поиска лучшего решения. 
Пример 15. 
Генетическим алгоритмом найти минимум функции 
f = 3(1 – x1)
2
exp (– 2
1 x –(x2 + 1)2
) – 10( x1/5 – 3
1 x – 5
2 x )exp (– 2
1 x – 2
1 x ) – 
–1/3exp (– (x1 + 1)2 – 2
2 x ) 
при условиях
–3  xj  3, j = 1, 2. 
Эта функция ранее была представлена в файлах myfun и myfun1. 
Для наглядного представления нескольких поколений напишем собственную функцию графики plotfun1:
function state = plotfun1(options, state, flag) 
 switch flag 
 case 'init' 
 plot(state.Population(:,1),state.Population(:,2),... 
 'ko')hold on; 
 case 'iter' 
 if state.Generation==1 
 plot(state.Population(:,1),state.Population(:,2),... 
 'g.'); 
 end 
 if state.Generation==2 
 plot(state.Population(:,1),state.Population(:,2),... 
 'b.'); 
 end 
110 
 if state.Generation==20 
 plot(state.Population(:,1),state.Population(:,2),... 
 'c.'); 
 end 
 case 'done' 
 plot(state.Population(:,1),state.Population(:,2),... 
 'r*'); 
 end 
end 
Примем размер популяции 10 и составим и исполним следующую
программу: 
>> options=gaoptimset('PlotFcns',@plotfun1,'PopulationSize',10); 
[x,fval,exit,output]=ga(@myfun,2,[],[],[],[],[-3 -3],[3 3],[],options) 
[X,Y]=meshgrid(-3:0.03:3);Z=myfun1(X,Y);contour(X,Y,Z,20); 
xlabel('X1');ylabel('X2'); 
Optimization terminated: average change in the fitness value less than 
options.TolFun. 
x = 
 -1.3448 0.2054 
fval = 
-3.0498 
exit = 
1 
output = 
problemtype: 'boundconstraints' 
rngstate: [1x1 struct] 
generations: 51 
funccount: 520 
message: [1x86 char] 
maxconstraint: 0 
Полученные результаты показывают, что за 51 итерацию, в течение которых целевая функция вычислялась 520 раз, найден минимум, 
оказавшийся локальным. На рис. 31 представлено расположение особей в четырех итерациях: черными кружками – начальная популяция, 
зелеными ромбиками – особи первого поколения, синими – второго
поколения, лазурными – 20-го поколения и красными снежинками – 
финальная популяция. Видно, что уже 20-е поколение располагается
близко к локальному минимуму, а особи конечной популяции настолько близки друг к другу, что слились в одну точку. На первых итераци-
111 
ях хорошо видно, что по крайней мере две особи смежных поколений
совпадают, что обусловлено использованием элитизма (по умолчанию
две особи элитные). 
Добавим в программу обращение к стандартной функции графики
gaplotbestf и повторим ее исполнение: 
>> options= gaoptimset('PlotFcns',{@gaplotbestf,@plotfun1},… 
'PopulationSize',10); 
[x,fval,exit,output]=ga(@myfun,2,[],[],[],[],[-3 -3],[3 3],[],options) 
[X,Y]=meshgrid(-3:0.01:3);Z=myfun1(X,Y);contour(X,Y,Z,20); 
xlabel('X1');ylabel('X2'); 
Рис. 31. Поиск минимума функции myfun генетическим алгоритмом
Результаты выполнения этой программы представлены на рис. 32 
и в следующем отчете: 
Optimization terminated: average change in the fitness value less than 
options.TolFun. 
x = 
 -1.3448 0.2054 
fval = 
-3.0498 
exit = 
1 
output = 
problemtype: 'boundconstraints' 
112 
rngstate: [1x1 struct] 
generations: 51 
funccount: 520 
message: [1x86 char] 
maxconstraint: 0 
Затраты на поиск того же локального минимума не изменились, но
изменилось расположение поколений, кроме конечного (см. рис. 32). 
На верней части рис. 32 показано изменение двух показателей поколения за весь процесс поиска: среднего в поколении значения фитнесфункции и ее лучшего значения в поколении. Хорошо видно, что минимум получен за 30 поколений, а остальные поколения потребовались
для «доводки» точности и достижения условия останова. 
Рис. 32. Поиск минимума целевой функции myfun
при двух функциях графики
Попробуем найти глобальный минимум дополнительными повторными исполнениями программы. Только на пятой попытке получен искомый результат, о чем свидетельствуют нижеприводимый отчет
програмы (рис. 33): 
>> options=gaoptimset('PlotFcns',@plotfun1,'PopulationSize',10); 
[x,fval,exit,output]=ga(@myfun,2,[],[],[],[],[-3 -3],[3 3],[],options) 
113 
[X,Y]=meshgrid(-3:0.03:3);Z=myfun1(X,Y);contour(X,Y,Z,20); 
xlabel('X1');ylabel('X2'); 
Optimization terminated: average change in the fitness value less than 
options.TolFun. 
x = 
 0.2372 -1.6268 
fval = 
 -6.5503 
exit = 
 1 
output = 
problemtype: 'boundconstraints' 
rngstate: [1x1 struct] 
generations: 57 
funccount: 580 
message: [1x86 char] 
maxconstraint: 0 
Для достижения глобального оптимума в точке (0,2372 –1,6268) со
значением функции цели –6,5503 потребовалось сгенерировать 57 поколений и 580 раз вычислить фитнес-функцию. 
Рис. 33. Расположение особей поколений при нахождении
глобального минимума
114 
Пример 16. 
Решить задачу из примера 15 при дополнительном линейном ограничении
0,9x1 – x2  1,2. 
Для этого в программу из примера 15 добавим значения входных
аргументов: матрицу A = [0,9 –1] и вектор b = [1,2]. После удачной попытки выполнения программы получили
>> options=gaoptimset('PlotFcns',@plotfun1,'PopulationSize',10); 
[x,fval,exit,output]=ga(@myfun,2,[0.9 -1],[1.2],[],[],[-3 -3],[3 3],[],options) 
[X,Y]=meshgrid(-3:0.03:3);Z=myfun1(X,Y);contour(X,Y,Z,20); 
xlabel('X1');ylabel('X2');plot([-2 3],[-3 1.5],'b-','linewidth',2.3); 
Optimization terminated: average change in the fitness value less than 
options.TolFun. 
x = 
 -0.3269 -1.4941 
fval = 
 -3.4532 
exit = 
 1 
output = 
 problemtype: 'linearconstraints' 
 rngstate: [1x1 struct] 
 generations: 62 
 funccount: 630 
 message: [1x86 char] 
 maxconstraint: 0 
Как следует из рис. 34, генетический алгоритм нашел условный
глобальный минимум, который расположен на границе допустимой
области в точке (–0,3269 –1,4941) и имеет значение –3,4532. Для этого
потребовалось 62 поколения популяций и 630 вычислений целевой
функции. 
115 
Рис. 34. Поиск минимума функции myfun
при линейном неравенстве
Пример 17. 
Генетическим алгоритмом найти глобальный максимум функции 2 2 4 4 1 12 1 2 2 44 (1 20,25( ) ) (2 (0,5 0,5) ( 1) )
1 12 1,5 (0,5 0,5) ( 1) x xx x x f xe x x e         
при условиях
0  x1  4, 0  x2  3. 
Эта функция представлена m-файлами multiextr1 и multiextr1_g (см. пример 14), а ее трехмерный вид показан на рис. 28. 
Решение находим, исполнив программу
>> options=gaoptimset('PlotFcns',@plotfun1,'PopulationSize',10); 
[x,fval,exit,output]=ga(@multiextr1,2,[],[],[],[],[0 0],[4 3],[],options) 
[X,Y]=meshgrid(0:0.02:4,0:0.02:3);Z=multiextr1_g(X,Y);contour(X,Y,Z,20); 
xlabel('X1');ylabel('X2'); 
Optimization terminated: average change in the fitness value less than options.TolFun. 
x = 
 0.9734 0.9732 
fval = 
116 
 -1.4979 
exit = 
 1 
output = 
 problemtype: 'boundconstraints' 
 rngstate: [1x1 struct] 
 generations: 96 
 funccount: 970 
 message: [1x86 char] 
 maxconstraint: 0 
Рис. 35. Поиск глобального максимума функции
multiextr1 алгоритмом ga
На рис. 35 хорошо видно, что последнее поколение особей находится в окрестности глобального максимума. Несмотря на наличие
гребня, максимум локализован достаточно точно: координаты оптимума (0,9734, 0,9732 ) близки к точным (1 1), а значение целевой функции в нем 1,4979 практически равно точному 1,5. 
4.6. Сравнительная характеристика решателей
Эффективность методов оценивается скоростью сходимости. 
GlobalSearch и MultiStart дают быструю сходимость к локальному оптимуму гладкой задачи благодаря использованию производ-
117 
ных. Для patternsearch доказана сходимость к локальному экстремуму, но скорость сходимости ниже, чем у методов, использующих
производные. Для генетического алгоритма сходимость не доказана. 
Сходимость к глобальному оптимуму доказана для simulannealbnd
для задач с границами на переменные при условии очень медленного
охлаждения, т.е. низкой скорости. 
Область применения решателей в зависимости от типа задачи и
способа вычислений представлена в следующей таблице. 
Цель и способ
вычислений Гладкие функции Негладкие функции
Одно локальное решение Функции Optimization Toolbox
fminbnd, patternsearch, fminsearch, ga, simulannealbnd
Много локальных
решений
GlobalSearch, 
MultiStart
Одно глобальное
решение
GlobalSearch 
Multi-Start, 
patternsearch, ga, 
simulanealbnd
patternsearch, ga, 
simulannealbnd
Одно локальное решение
с распараллеливанием
MultiStart, функции
Optimization Toolbox 
patternsearch, ga
Много локальных решений
с распараллеливанием
MultiStart 
Одно глобальное решение
с распараллеливанием
MultiStart patternsearch, ga 
Лабораторная работа № 5 
Генетический алгоритм
Задания: 
1. Усвоить схему генетического алгоритма и назначение основных
параметров популяции, алгоритма и функций графики, понять работу
функций отбора, кроссовера и мутации. 
2. Применить генетический алгоритм к функции multiextr1 на
области –3  xj  4, j = 1, 2 с целью нахождения глобальных максимумов при нескольких размерах популяции. 
118 
3. Найти глобальный максимум функции myfun. Построить зависимость оптимального значения целевой функции от доли кроссовера
при одном размере популяции. Для получения соответствующих данных можно применить цикл
record=[]; 
for n=0.05:.05:1 
 options = gaoptimset('CrossoverFraction',n, …); 
 [x fval]=ga(…,options); 
 record = [record; fval]; 
end 
4. Найти глобальный максимум функции myfun в границах –3  xj  3, 
j = 1, 2 и при дополнительных ограничениях –4x1 + 5x2  7, 3x1 + 4x2  9 
при нескольких значениях числа элитных особей. 
5. Исследовать влияние вида кроссовера (из числа стандартных) 
на поиск минимумов функции 2 2
12 1 2 fx x x x     cos(8 ) cos(8 )
1 2 ( 0,5 ) x x e   при условиях –0,5  xj  1, j = 1, 2. 
6. Факультативно: исследовать эффективность генетического алгоритма на тестовой многоэкстремальной функции Растригина второго
порядка 2 2
12 1 2 f     20 10(cos(2 ) cos(2 )) xx x x при условиях –1  xj  1. 
7. Факультативно: написать собственный кроссовер и опробовать
его на многоэкстремальной функции. 
119 
5. МНОГОКРИТЕРИАЛЬНАЯ ОПТИМИЗАЦИЯ
Во многих прикладных задачах оптимизации цель описывается не
одной, а несколькими функциями (критерями), и в этом случае говорят
о векторной оптимизации. При этом оптимальное решение такой задачи в традиционном понимании не имеет смысла. Лицо, принимающее
решения (ЛПР), стремится найти некоторое компромиссное по целевым функциям решение, удовлетворяющее его субъективным представлениям (предпочтениям) о желаемом результате. В теории многокритериальной оптимизации показано, что искать компромиссное решение следует только среди паретовских решений. Решение X* 
оптимально по Парето, если не существует другого допустимого решения X, в котором значение хотя бы одного критерия было лучше, а
других не хуже, чем в X*
. Иначе говоря, паретовские решения являются
недоминируемыми (noninferior) или неулучшаемыми. Методы многокритериальной оптимизации ориентированы на предоставление ЛПР
паретовских или, по крайней мере, слабопаретовских решений. Ниже
рассматриваются функции MATLAB, реализующие некоторые из таких методов. 
5.1. Функция gamultiobj 
Эта функция входит в состав пакета Global Optimization. Она
пытается создать множество парето-оптимальных решений минимизацией многомерной целевой функции. Допускается наличие границ на
переменные, а также линейных неравенств и равенств, но нелинейные
ограничения неприемлемы. Для минимизации используется контролируемый генетический алгоритм с элитизмом, его отличие от ga невелико. Алгоритм с элитизмом всегда предпочитает особи с лучшим значением фитнес-функции (ранга), а при контролируемости предпочитаются также особи, которые могут помочь в увеличении разнообразия
популяции, даже если они имеют более низкие значения фитнеса. Разнообразие особей улучшает сходимость к множеству Парето, оно
обеспечивается контролем числа элитных особей. Для этого используются два параметра, отличных от имеющихся в ga. Параметр
ParetoFraction ограничивает число особей на границе Парето
(элитных членов), определяя долю популяции на лучшей границе Парето, удерживаемую в процессе оптимизации. При одной границе Па-
120 
рето этот параметр игнорируется. Второй параметр, DistanceFcn, задает функцию расстояния, способствующую созданию разнообразия на
границе посредством предпочтения особям, которые относительно далеки от границы Парето. 
Изменение параметров gamultiobj выполняется через функцию
gaoptimset. Большинство параметров ga и gamultiobj идентичны
(прил. 6). Два отличительных параметра упомянуты выше. Параметр
DistanceMeasureFcn определяет функцию, которая задает меру расстояния между особями. Кроме того, для отображения границы Парето
в случае двумерной целевой функции, т.е. зависимости между функциями на найденном множестве Парето, имеется функция графики
@gaplotpareto, устанавливаемая параметром PlotFcn. Отметим
другие отличия от алгоритма ga. Прежде всего обратим внимание на
то, что способ отбора родителей не может быть выбран: используется
только турнирный вариант, причем число турниров должно быть равно
числу целевых функций. Определение элитных особей обеспечивается
сортировкой популяции, при которой недоминируемые особи размещаются выше доминируемых. В gamultiobj отсутствует выбор
функции масштабирования, а в качестве непустого значения HybridFcn может быть только функция fgoalattain, о которой речь
пойдет в следующем разделе. Наконец, в рассматриваемом алгоритме
не используется параметр времени StallTimeLimit, исчерпание которого приводит к остановке ga. 
При применении gamultiobj сначала устанавливаются необходимые значения параметров, и затем вызывается сама функция. Как и
для других функций оптимизации, имеются разные варианты вызова 
gamultiobj, зависящие от описания решаемой задачи (перечня входных аргументов) и требуемых результатов (выходных аргументов). 
Синтаксис вызовов gamultiobj в командном окне представлен ниже. 
X = gamultiobj(FITNESSFCN,NVARS) 
X = gamultiobj(FITNESSFCN,NVARS,A,b) 
X = gamultiobj(FITNESSFCN,NVARS,A,b,Aeq,beq) 
X = gamultiobj(FITNESSFCN,NVARS,A,b,Aeq,beq,LB,UB) 
X = gamultiobj(FITNESSFCN,NVARS,A,b,Aeq,beq,LB,... 
UB,options) 
X = gamultiobj(problem) 
[X,FVAL] = gamultiobj(...) 
[X,FVAL,EXITFLAG] = gamultiobj(...) 
121 
[X,FVAL,EXITFLAG,OUTPUT] = gamultiobj(...) 
[X,FVAL,EXITFLAG,OUTPUT,POPULATION] = gamultiobj(...) 
[X,FVAL,EXITFLAG,OUTPUT,POPULATION,SCORE] = ... 
gamultiobj(...), 
где FITNESSFCN – векторная фитнес-функция, X – множество локальных паретовских решений в виде матрицы с числом стобцов, равным
числу переменных, и числом строк, равным числу решений, FVAL – 
матрица значений целевых функций в X (число столбцов равно числу
целевых функций), EXITFLAG – содержит признак завершения алгоритма: 
1 – среднее изменение размаха множества Парето за
StallGenLimit поколений меньше TolFun, 
0 – прошло максимальное число поколений, 
-1 – остановлено output или plot функцией, 
-2 – не найдено допустимой точки, 
-5 – исчерпан лимит времени, 
POPULATION – конечная популяция, SCORE – значения целевых функций в конечной популяции; остальные аргументы описаны в предыдущих разделах. 
Рассмотрим примеры применения gamultiobj для приближенного нахождения множества Парето. 
Пример 18. 
Найти и построить множество Парето для двухмерной целевой
функции
42 42
1 1 21 2 2 21 f        (1 ) ( ) ; (4 ) ( ) . x xx f x xx
Для решения задачи фитнес-функцию представим в виде m-файла: 
function f = multifun(x); 
f(1)=(1-x(1))^4+(x(2)-x(1))^2; 
f(2)=(4-x(2))^4+(x(2)-x(1))^2; 
end 
а для графических построений запишем два m-файла: fun1g и fun2g. 
Составим программу, в которой все параметры установлены по
умолчанию и только размер популяции увеличим до 70. Кроме того, 
предусмотрим построение линий уровня функций с последующим нанесением получаемых генетическим алгоритмом точек и точного мно-
122 
жества Парето, а также отображение зависимости между целевыми
функциями в окрестности Парето (границы Парето). В итоге приходим
к следующей программе решения задачи: 
options=gaoptimset('PopulationSize',70); 
[x,fval]=gamultiobj(@multifun,2,[],[],[],[],[],[],... 
options); 
y=x(:,1);z=x(:,2);plot(y,z,'red.');hold on; 
[X,Y]=meshgrid(0:0.05:5);Z=fun1g(X,Y); 
contour(X,Y,Z,[0.03 0.2 0.5 0.7 1 2 3 6 9 15 25 40... 
55 80 115],'b'); 
hold on; [X,Y]=meshgrid(0:0.05:5); Z=fun2g(X,Y); 
contour(X,Y,Z,[0.01 0.05 0.1 0.3 0.6 1 2 3 6 9 15 20... 
26 35 52 75 100 130],'g'); 
 a=[1,1]; 
for k=1.1:.1:3.9 
 a=[a;[k,fzero(@(t)twograd([k,t]),[1,4])]]; 
end 
 a=[a;[4,4]];hold on; 
 plot(a(:,1),a(:,2),'k-');%Plot true Pareto frontier 
xlabel('x1'); ylabel('x2'); 
figure;plot(fval(:,1),fval(:,2),'r*');grid on; 
xlabel('f1');ylabel('f2'); 
В процессе выполнения этой программы выдавались значения целевых функций особей поколений, а в завершение – сообщение о причине останова алгоритма: 
Optimization terminated: average change in the spread of Pareto solutions less than 
options.TolFun. 
Но удобнее получить результаты в компактном виде, для чего исполним команду
>> [x,fval] 
ans = 
 x1 x2 f1 f2 /обозначения столбцов вписаны автором 
 1.0078 1.0078 0.0000 80.1648 
 3.9370 3.9270 74.4067 0.0001 
 3.9726 3.9687 78.0856 0.0000 
 1.4641 2.1668 0.5402 11.7872 
 1.1310 1.1169 0.0005 69.0963 
 4.0288 4.0280 84.1553 0.0000 
123 
 3.8881 3.8993 69.5701 0.0002 
 1.3991 1.7692 0.1623 24.9025 
 1.2630 1.3006 0.0062 53.1002 
 3.6214 3.6942 47.2294 0.0140 
 1.0399 1.0232 0.0003 78.5203 
 3.7828 3.8391 59.9763 0.0038 
 1.1747 1.1992 0.0015 61.5333 
 3.0694 3.5207 18.5429 0.2565 
 3.8449 3.8286 65.5032 0.0011 
 3.3862 3.5866 32.4608 0.0694 
 2.6681 3.3464 8.2021 0.6426 
 1.0078 1.0078 0.0000 80.1648 
 1.3987 1.6935 0.1122 28.3888 
 3.7134 3.7551 54.2090 0.0053 
 3.4833 3.5882 38.0383 0.0398 
 1.4262 2.0792 0.4594 14.0397 
 1.9411 2.5784 1.1906 4.4903 
 3.2271 3.4262 24.6421 0.1480 
 1.3915 1.4790 0.0312 40.3978 
Из этих данных следует зависимость между целевыми функциями
вблизи границы Парето, показанная на рис. 36. Мы видим, что при
смещении вдоль границы Парето на малое расстояние от минимума
одной из функций значение этой функции резко возрастает. Поэтому
область приемлемых по обеим функциям решений очень узкая, а чувствительность функций к малым изменениям решения высокая. 
На рис. 37 представлены контуры функций, на их фоне красными
ромбиками показаны полученные точки, а сплошной черной кривой – 
точное множество Парето. Очевидно, что найденные точки лишь приближенно выделяют окрестность множества Парето, причем более
точно вблизи экстремумов функций. 
При двух гладких целевых функциях касательные к линиям уровня обеих функций в точках Парето совпадают (это точки касания линий уровня) и, следовательно, градиенты функций лежат на одной
прямой, но направлены противоположно. 
124 
Рис. 36. Зависимость между целевыми функциями
в окрестности границы Парето
Рис. 37. Приближенное и точное множество Парето в примере 18 
125 
Это свойство использовано при построении точного множества
Парето и отражено в функции twograd, включенной в вышеприведенную программу. 
function g = twograd(x) 
g1=[-4*(1-x(1))^3-2*(x(2)-x(1)); 
 2*(x(2)-x(1))]; 
g2=[-2*(x(2)-x(1));-4*(4-x(2))^3+2*(x(2)-x(1))]; 
%Two gradients are opposite directed 
g=g2(1)*g1(2)-g2(2)*g1(1); 
end 
Равенство нулю последнего выражения означает противоположность градиентов, это условие реализовано в программе через функцию нахождения нулей fzero (см. п. 9.1). 
Пример 19. 
Найти и построить множество Парето для двухмерной целевой
функции
42 42
1 1 21 2 2 21 f        (1 ) ( ) ; (4 ) ( ) x xx f x xx
при условии –0,9 x1 + x2  0,5. 
В программу добавим элементы неравенства и отразим их в аргументах функции: 
A=[0,9 –1]; b=[-0.5]; 
[x,fval]=gamultiobj(@multifun,2,A,b,[],[],[],[],... 
options); 
Исполнение программы завершается выводом сообщения о причине останова: 
Optimization terminated: average change in the spread of Pareto solutions less than 
options.TolFun. 
Результаты получаем выполнением команды
>> [x,fval] 
ans = 
126 
 x1 x2 f1 f2 /обозначения столбцов вписаны автором 
 1.6080 2.0703 0.3504 14.0794 
 1.2965 1.6659 0.1442 29.8177 
 2.0346 2.9904 2.0593 1.9525 
 1.8947 2.9204 1.6927 2.4107 
 1.7055 2.2954 0.5958 8.7901 
 2.1035 3.0104 2.3054 1.7814 
 1.5977 2.1671 0.4519 11.6097 
 2.1407 3.1933 2.8011 1.5315 
 1.3930 1.7553 0.1552 25.5174 
 1.6494 2.4291 0.7858 6.6976 
 1.6126 2.5345 0.9906 5.4628 
 1.6404 2.1131 0.3917 12.8992 
 1.7789 2.4984 0.8857 5.6018 
 1.9928 2.9385 1.8660 2.1638 
 1.6321 2.0156 0.3067 15.6546 
 1.6804 2.3968 0.7276 7.1192 
 2.0511 3.0349 2.1885 1.8354 
 1.5502 1.9582 0.2581 17.5471 
 1.3682 1.7308 0.1498 26.6487 
 1.8161 2.4536 0.8500 6.1247 
 1.8075 2.7281 1.2726 3.4647 
 1.4439 1.8010 0.1664 23.5100 
 2.1047 3.0824 2.4452 1.6648 
 1.5319 1.8804 0.2015 20.3077 
 1.4497 1.8216 0.1792 22.6574 
Графическое представление зависимости функций показано на
рис. 38. Ее использование позволит ЛПР достаточно просто найти наилучшее компромиссное решение. Расположение найденных решений
относительно точного множества Парето дано на рис. 39. Здесь хорошо
видно, как на решения повлияло линейное ограничение (граница допустимого множества решений показана малиновой линией). 
127 
Рис. 38. Конечное приближение к границе Парето в примере 19 
Рис. 39. Приближенное и точное множество Парето в примере 19
128 
5.2. Метод достижения цели. Функция fgoalattain
Функция fgoalattain, входящая в пакет Optimization Toolbox, реализует метод достижения многомерной цели (целевого программирования). Идея метода состоит в том, что вместо непосредственной минимизации критериев цели ставится задача максимального
достижения желаемых уровней этих критериев. 
Пусть F(x) = (f1(x), f2(x), …, fm(x)) – вектор целевых функций, а
goal = (goal1, goal2, …, goalm) – вектор заданных целевых значений, которые желательно достичь. Чем меньше разность fi(x) – goali, тем точнее достигается i-я цель. Для объединения целей следует использовать
относительные разности, введя для этого вектор неотрицательных весов w = (w1, w2,…, wm). Обозначив максимальную относительную разность как γ, приходим к выводу, что для максимально возможного достижения целей необходимо минимизировать γ. Таким образом, задача
достижения цели формулируется в виде
γ  min, x
F(x) – w·γ ≤ goal, 
A·x ≤ b, 
Aeq·x = beq, 
C(x) ≤ 0, 
ceq(x) = 0, 
lb ≤ x ≤ ub. 
Первые m ограничений-неравенств называются целевыми ограничениями, но при задании задачи в fgoalattain они не входят в число оганичений, так как учитываются внутри алгоритма (в функции качества, подобной штрафной функции). Чем ближе вес wi к нулю, тем
жестче целевое ограничение и тем выше требование к точности достижения i-й цели. Рекомендуется устанавливать w равным abs(goal), тогда
F x  – goal
w
есть относительная величина отклонения от цели. 
Следовательно, абсолютное значение γ при γ < 0 в оптимальном решении показывает максимальное относительное отклонение от цели среди всех целей. При отрицательном γ значения всех целевых функций
лучше их целевых значений, а при положительном – значение по крайней мере одной целевой функции больше цели. Целевые функции, по
которым целевые ограничения обращаются в равенства (они опреде-
129 
ляют γ), называются активными. Через задание w ЛПР может оказывать влияние на степень достижения той или иной цели. 
Функция fgoalattain использует метод последовательного
квадратичного программирования (SQP) с модификацией в части линейного поиска и гессиана. В линейном поиске применяется функция
качества вида
1
( , ) max[0, ( ) goal ],
m
i ii i
i
x r fx w 
      
а при действиях с гессианом учитывается его особая структура (нули в
строках и столбцах, ассоциированных с переменной γ). 
Заметим, что функция fgoalattain ориентирована на задачи с
непрерывными целевыми функциями. Возможно получение решения и
при нарушениях непрерывности, если они не будут проявляться в точках, из которых делается шаг вперед. Метод достижения цели дает локальный результат. 
Решение задачи рассматриваемым методом начинается с установки желаемых параметров. Для этого применяется функция optimset. 
Краткое описание всех параметров fgoalattain и их значения по
умолчанию приведены в прил. 7. Остановимся лишь на некоторых. 
Если каких-либо целей требуется достичь максимально точно, соответствующие целевые функции размещают первыми в описании
(m-файле) многомерной цели, а параметру GoalsExactAchieve придают значение, равное числу точных целей. Например, запись в командной строке
options = optimset('GoalsExactAchieve',2);
реализует требование, чтобы первые две цели достигались с максимально возможной точностью. 
Параметры GradObj и GradConstr устанавливают в ‘on’, когда градиенты целевых функций и нелинейных ограничений задаются
аналитически. При наличии нелинейных ограничений нельзя задать
градиенты только целевых функций или только ограничений, так как в
функции качества они представлены вместе. Градиент многомерной
цели – это матрица, в которой каждый столбец есть градиент одной целевой функции (частные производные по всем переменным). Для ограничений имеем две матрицы, отдельно для неравенств и равенств. 
В каждой из них столбец матрицы содержит градиент соответствующей левой части ограничения (C(x) или ceq(x)). Аналитическое задание
градиентов ускоряет процесс решения, в противном случае все произ-
130 
водные вычисляются одним из методов конечных разностей, определяемым параметром FinDiffType. Напомним, что при аналитическом задании градиентов они описываются в одном m-файле с самой
целевой функцией или функциями ограничений. 
Синтаксис fgoalattain зависит от модели задачи и описания
результата решения. 
x = fgoalattain(fun,x0,goal,weight) 
x = fgoalattain(fun,x0,goal,weight,A,b) 
x = fgoalattain(fun,x0,goal,weight,A,b,Aeq,beq) 
x = fgoalattain(fun,x0,goal,weight,A,b,Aeq,beq,lb,ub) 
x = fgoalattain(fun,x0,goal,weight,A,b,Aeq,beq,... 
lb,ub,nonlcon) 
x = fgoalattain(fun,x0,goal,weight,A,b,Aeq,beq,... 
lb,ub, nonlcon, options) 
x = fgoalattain(problem) 
[x,fval] = fgoalattain(...) 
[x,fval,attainfactor] = fgoalattain() 
[x,fval,attainfactor,exitflag] = fgoalattain(...) 
[x,fval,attainfactor,exitflag,output] = ... 
fgoalattain(...) 
[x,fval,attainfactor,exitflag,output,lambda] = ... 
fgoalattain(...)
Смысл входных аргументов очевиден. Заметим, что функция fun
наряду с целевыми функциями может включать и градиенты. Точно
так же функция nonlcon может содержать помимо функций нелинейных ограничений и их градиенты. Значения целей goal, как и начальную точку x0, задает ЛПР, а веса weight первоначально берут равными абсолютным значениям целей. Аргумент options обязателен, если изменены какие-либо параметры через optimset, при этом для
отсутствующих аргументов устанавливается значение []. 
Выходные аргументы x и fval содержат решение и вектор значений целевых функций. Аргумент attainfactor – это γ, величина
которого показывает относительное отклонение от цели, лимитирующей дальнейшее повышение точности. Причина остановки алгоритма
содержится в exitflag: 
1 – установлена сходимость, 
4 – величина направления поиска меньше допустимой и нарушение ограничений меньше допустимого TolCon, 
131 
5 – величина производной по направлению меньше допустимой и
нарушение ограничений меньше допустимого TolCon, 
0 – число итераций или число вычислений функции превысило
максимально установленное, 
–1 – алгоритм остановлен функцией вывода, 
–2 – не найдено допустимой точки. 
Структура output содержит поля: iterations – число итераций, funcCount число вычислений функции, lssteplength – размер шага линейного поиска, stepsize – конечное смещение по x, 
algorithm – примененный алгоритм, firstorderopt – мера оптимальности первого порядка, constrviolation – максимум функций
ограничений, message – конечное сообщение. Последний выходной
аргумент lambda содержит значения множителей Лагранжа по всем
ограничениям: lower, upper, ineqlin, eqlin, ineqnonlin, 
eqnonlin. 
Пример 20. 
При двух целевых функциях
42 42
1 1 21 2 2 21 f        (1 ) ( ) , (4 ) ( ) x xx f x xx
и при условии –0,9 x1 + x2  0,5 достигнуть целевых значений goal1 = 
= 1,5, goal2 = 3. 
Составим m-файл для вычисления целевых функций и их градиентов: 
function [f,g] = multifun1(x); 
f(1)=(1-x(1))^4+(x(2)-x(1))^2; 
f(2)=(4-x(2))^4+(x(2)-x(1))^2; 
g=[-4*(1-x(1))^3-2*(x(2)-x(1)) -2*(x(2)-x(1)); 
 2*(x(2)-x(1)) -4*(4-x(2))^3+2*(x(2)-x(1))]; 
end 
Начнем поиск решения с начальной точки (3 3) и весов, равных
целям. Предварительно укажем на использование в вычислениях аналитических выражений целевых функций. В итоге последовательность
команд имеет вид
 >>x0=[3 3]; 
 A=[0.9 -1]; 
 b=[-0.5]; 
 goal=[1.5 3]; w=goal; 
132 
 options=optimset('GradObj','on'); 
[x,fval,attainfactor,exit,output]=fgoalattain(... 
@multifun1,x0,goal,w,A,b,[],[],[],[],[],options) 
В результате их выполнения получаем
x = 
 1.8671 2.8083 
fval = 
 1.4512 2.9025 
attainfactor = 
 -0.0325 
exit = 
 4 
output = 
 iterations: 8 
 funcCount: 40 
 lssteplength: 1 
 stepsize: 4.9593e-007 
 algorithm: 'goal attainment SQP, Quasi-Newton, line_search' 
 firstorderopt: [] 
 constrviolation: 5.7775e-007 
 message: [1x771 char] 
Решение получено за восемь итераций комбинацией трех алгоритмов. Поставленные цели превышены: значения обеих целевых функций меньше целей. Об этом же свидетельствует отрицательное значение аргумента attainfactor (γ). 
Теперь добавим требование точного достижения первой цели
options=optimset('GradObj','on','GoalsExactAchieve',1); 
Исполнение команд дает
x = 
 1.7778 2.8427 
fval = 
 1.5000 2.9277 
attainfactor = 
 2.5824e-023 
exit = 
 4 
output = 
 iterations: 9 
133 
 funcCount: 44 
 lssteplength: 1 
 stepsize: 6.5882e-012 
 algorithm: 'goal attainment SQP, Quasi-Newton, line_search' 
 firstorderopt: [] 
 constrviolation: 5.0931e-012 
 message: [1x771 char] 
Как видим, первая цель достигнута точно. Значение первой целевой функции на очень малую величину больше 1,5, поэтому attainfactor оказался положительной, но практически равной нулю величиной. При этом и вторая цель достигается с большей точностью. 
Пример 21. 
При трех целевых функциях
42 4 2 42
1 1 21 2 1 21 3 2 21 f            (1 ) ( ) , (5 ) (2,5 ) , (4 ) ( ) x xx f x xx f x xx
достигнуть целевых значений goal1 = 15, goal2 = 13, goal3 = 19. 
Запишем m-файл функций: 
function f = multifun2(x); 
f(1)=(1-x(1))^4+(x(2)-x(1))^2; 
f(2)=(5-x(1))^4+(2.5*x(2)-x(1))^2; 
f(3)=(4-x(2))^4+(x(2)-x(1))^2; 
end 
Выполним команды
>> x0=[1 3];goal=[15 13 19]; w=goal; 
[x,fval,attainfactor,exit,output]=fgoalattain(@multifun2,x0,goal,w) 
x = 
 3.0506 1.8147 
fval = 
 19.2103 16.6489 24.3330 
attainfactor = 
 0.2807 
exit = 
 4 
output = 
iterations: 7 
funcCount: 28 
lssteplength: 1 
stepsize: 1.1515e-007 
algorithm: 'goal attainment SQP, Quasi-Newton, line_search' 
134 
 firstorderopt: [] 
 constrviolation: 2.6497e-007 
 message: [1x771 char] 
Как видно из полученного отчета, значения всех целевых функций
больше желаемых, максимальное отклонение составляет 28 % (см. attainfactor). При этом все целевые ограничения оказались активными, что является признаком недоминируемости полученного решения. 
Стремясь улучшить значения первых двух целевых функций, введем
опцию 'GoalsExactAchieve',2. После выполнения измененной
программы имеем
x = 
 3.0506 1.8147 
fval = 
 19.2103 16.6489 24.3330 
attainfactor = 
 0.2807 
Решение не изменилось, т.е. повысить точность достижения двух
целей таким путем не удалось. Попробуем улучшить только первую
цель, задав 'GoalsExactAchieve' равным 1. Исполнение команд
показало, что и в этом случае решение не меняется. Тогда проверим
влияние весов: изменим вес 1-й цели с 15 до 5, оставив остальные веса
без изменения, и исключим 'GoalsExactAchieve'. 
>> x0=[1 3];goal=[15 13 19]; w=[5 13 19]; 
[x,fval,attainfactor]=fgoalattain(@multifun2,x0,goal,w). 
В результате выполнения этих команд получаем
x = 
 2.9863 1.7553 
fval = 
 17.0805 18.4092 26.9058 
attainfactor = 
 0.4161 
Таким образом, уменьшение веса первой цели привело к лучшему
значению первой целевой функции, но это стало возможным за счет
ухудшения двух других функций. Интересно отметить, что в полученном решении все целевые ограничения снова оказались активными
(все отклонения равны ). Это позволяет утверждать, что решение является паретовским по функциям, являющимся относительными отклонениями при данных весах. 
135 
5.3. Функция fminimax
Второй метод решения многокритериальной задачи заключается в
минимизации наибольшего значения из всех целевых функций. Он
реализован в функции fminimax и предназначен для решения задач
вида
max f (x) i i
 min, x
A·x ≤ b, 
Aeq·x = beq, 
C(x) ≤ 0, 
ceq(x) = 0, 
lb ≤ x ≤ ub. 
Критерий в представленной форме не является гладким, что вызывает большие трудности. Поэтому в алгоритме исходная задача сначала преобразуется в обычную общую задачу нелинейного программирования добавлением неравенств fi(x) < γ и переходом к минимизации γ. 
В результате получается частный случай задачи достижения цели, когда все целевые значения равны 0 и все веса равны 1. Далее новая задача решается алгоритмом последовательного квадратичного программирования (SQP) с теми же модификациями, что и в функции
fgoalattain. 
Для установки значений параметров, отличных от принятых по
умолчанию, применяется та же функция optimset. Список параметров функций fminimax и fgoalattain отличается только одним параметром (см. прил. 7). Вместо параметра GoalsExactAchieve в
fminimax добавлен параметр MinAbsMax. Его значение, которое не
может быть больше числа целевых функций, показывает число целевых функций, по которым при минимизации берутся их абсолютные
значения. Такие функции в m-файле должны находиться перед остальными. Как и в предыдущем методе, при наличии нелинейных ограничений использовать аналитические выражения градиентов имеет
смысл только в случае их задания как для целевых функций, так и для
нелинейных ограничений. 
Синтаксис обращения к функции fminimax представляется в разных вариантах в зависимости от числа входных и выходных аргументов. 
136 
x = fminimax(fun,x0) 
x = fminimax(fun,x0,A,b) 
x = fminimax(fun,x,A,b,Aeq,beq) 
x = fminimax(fun,x,A,b,Aeq,beq,lb,ub) 
x = fminimax(fun,x0,A,b,Aeq,beq,lb,ub,nonlcon) 
x = fminimax(fun,x0,A,b,Aeq,beq,lb,ub,nonlcon,options) 
x = fminimax(problem) 
[x,fval] = fminimax(...) 
[x,fval,maxfval] = fminimax(...) 
[x,fval,maxfval,exitflag] = fminimax(...) 
[x,fval,maxfval,exitflag,output] = fminimax(...) 
[x,fval,maxfval,exitflag,output,lambda] = fminimax(...) 
Обозначения входных аргументов и их смысл описаны в предыдущих главах. Как и раньше, целевые функции должны быть непрерывными. Все выходные аргументы и их содержание идентичны таким
же в функции fgoalattain, за исключение аргумента maxfval, который содержит максимальное значение из всех целевых функций в полученном решении (значение γ). 
Результатом решения может быть локальный минимум. 
Пример 22. 
Найти решение, минимизирующее максимальное значение четырех функций
2 2
1 12 1 2
2 2
2 12
3 12
4 12
( ) 2 48 40 304,
() 3 ,
( ) 3 18,
() .
fx x x x x
fx x x
fx x x
fx x x
   
 
 
 
Сначала записываем функции в m-файл: 
function f=fourobj(x) 
f(1)=2*x(1)^2+x(2)^2-48*x(1)-40*x(2)+304; 
f(2)=-x(1)^2-3*x(2)^2; 
f(3)=x(1)+3*x(2)-18; 
f(4)=-x(1)-x(2); 
end 
Затем обращаемся к функции fminimax
>> x0=[0.2 0.1];... 
[x,fval,maxfval]=fminimax(@fourobj,x0) 
и получаем результаты решения: 
137 
Local minimum possible. Constraints satisfied. 
x = 
 8.8458 1.0746 
fval = 
 -5.9305 -81.7118 -5.9305 -9.9204 
maxfval = 
 -5.9305 
Очевидно, что значения целевых функций сильно отличаются по
абсолютной величине: размах 81,7118 – 5,9305 = 75,7813. Если желательно уменьшить эти различия, то можно, например, потребовать, 
чтобы в минимизации участвовали абсолютные значения первых трех
функций. Это требование выражаем через параметр MinAbsMax, присваивая ему значение 3: 
>> x0 = [0.2; 0.1]; 
options = optimset('MinAbsMax',3); 
[x,fval,maxfval] = fminimax(@fourobj,x0,[],[],[],[],[],[],[],options) 
x = 
 4.9256 2.0796 
fval = 
 37.2356 -37.2356 -6.8357 -7.0052 
maxfval = 
 37.2356 
Учет нового требования существенно уменьшил разброс абсолютных значений целевых функций (размах уменьшился до 30,4). 
Лабораторная работа № 6 
Решение многокритериальных задач
Задания: 
1. Рассмотреть особенности решения многокритериальных задач. 
Уяснить смысл решения, множества и границы Парето. 
2. Найти множество и границу Парето для двух функций без ограничений: 
4 2 4 22
1 1 1 12 2 1 2
4 22 4
2 2 1 2 1 12
( ) 10 ,
() .
f x x x xx x x x
f x x x x x xx
  
 
138 
3. Исследовать влияние на решение п. 2 значений параметра
CrossoverFraction и размера популяции, а также смены кроссовера
(факультативно). 
4. Повторить п. 2 при условии 2/3x1 – x2  3. 
5. Найти решение по функциям из п. 2 при заданных целевых значениях –30 и 4. Попытаться достигнуть точно одну из этих целей. Повторить для целевых значений –25 и 10. 
6. Найти решение по функциям из п. 2 с помощью fminimax. Повторить при требовании минимизации максимальных абсолютных значений. 
7. Найти решение для целевых функций из примера 22 с наименьшим размахом абсолютных значений всех функций. 
139 
6. ЛИНЕЙНОЕ ПРОГРАММИРОВАНИЕ. ФУНКЦИЯ LINPROG
Если целевая функция и все функции ограничений задачи линейные относительно x, а переменные x непрерывны, имеем задачу линейного программирования. Функция linprog предназначена для решения линейных задач общего вида: 
f T
x  min, 
A  x  b, 
Aeq  x = beq, 
lb  x  ub, 
где f – вектор коэффициентов целевой функции (линейной формы) 
размерности n. Для решения таких задач в функции linprog имеется
три алгоритма: один для задач большой размерности (Large Scale) и
два для средних задач (Medium Scale). 
Алгоритм Large Scale реализует прямо-двойственный метод
внутренней точки. Важно подчеркнуть, что он ориентирован на задачи
с разреженными матрицами A и Aeq. На предварительных шагах алгоритм выполняет преобразование исходной задачи: 
– все переменные ограничиваются снизу нулем; 
– все условия приводятся к равенствам; 
– фиксированные переменные, равные своим границам, удаляются; 
– строки и столбцы матрицы ограничений из нулей удаляются; 
– матрица ограничений приобретает полный структурный ранг; 
– при значительном числе единичных строк матрицы условий соответствующие переменные вычисляются и строки удаляются. 
Модель преобразованной задачи, являющейся далее прямой задачей, имеет вид
f T
x  min, A  x = b, 0  x  u. 
После введения в прямые ограничения переменных s, называемых дополнительными или слабыми (slack), получаем
f T
x  min, A  x = b, x + s = u, x  0, s  0. 
Этой задаче соответствует двойственная задача
bT
y – u
T
w  max, AT
 y – w + z = f, z  0, w  0, 
где y и w – двойственные переменные, а z – слабая переменная двойственной задачи. 
140 
Условия оптимальности обеих задач представляют собой систему
равенств
( , , , , ) 0, 0, 0, 0, 0, T
i i
i i
Ax b
xsu
Fxyzsw Ay w z f x z s w
x z
s w
         
              
    
в которой первые три линейных равенства являются условиями допустимости, а последние два квадратичных равенства – условиями дополняющей нежесткости. Сумму x
T
z + s
T
w называют интервалом (зазором) 
двойственности (duality gap), она характеризует невязку условий
дополняющей нежесткости. 
Алгоритм решает одновременно прямую и двойственную задачи, 
применяя к линейно-квадратичной системе F(x, y, z, s, w) = F(v) = 0 
ньютоноподобный метод при сохранении положительности x, z, s, и w
(отсюда название «метод внутренней точки»). Сначала алгоритм вычисляет направление предсказания
vp = –(FT
(v))–1F(v), 
которое является направлением Ньютона, затем корректирующее направление
vc = –(FT
(v))–1F(v + vp) – eˆ,
где  > 0 – центрирующий параметр (подбирается); eˆ – вектор из нулей
и двух единиц, соответствующих двум квадратичным уравнениям в F. 
Новое значение v вычисляется по формуле
v
+ = v + a(vp + vc), 
где a > 0 – параметр длины шага, выбираемый так, чтобы [x
+
; z+
; s+
;
w+
] > 0. При определении направлений используется факторизация
матрицы A (декомпозиция в произведение более удобных матриц). В
зависимости от свойств матрицы выполняется факторизация по Чолеску (Cholesky), Шермону – Моррисону или LDL. Шаги повторяются до
установления сходимости итераций. Условием останова алгоритма является выполнение неравенства
        , max 1, max 1, max 1, max 1, ,
TT T
b u f
TT T
r r r f x by uw tol
bfu f x by uw
 
   
141 
где rb = Ax – b, rf = AT
y – w + z – f, ru = x + s – u – невязки уравнений
прямой и двойственной задач и ограничений сверху, а f T
x – bT
y + uT
w – 
разность значений целевых функций прямой и двойственной задач, tol – 
допустимая величина суммы относительных невязок и разности целевых функций. Эта сумма – показатель относительной ошибки выполнения условий оптимальности. 
Для решения задач среднего размера применяются алгоритмы активного набора (active-set) и симплекс (simplex). 
Алгоритм active-set – это вариант алгоритма последовательного
квадратичного программирования (SQP), используемого в fmincon. Отличие лишь в том, что критерий линейной задачи не содержит квадратичную форму. На каждой главной итерации SQP-метода решается
квадратичная задача с линейной целевой функцией. Процедура решения
состоит из двух фаз. На первой фазе находится допустимая точка (если
она есть). На второй фазе генерируется последовательность допустимых
точек, сходящаяся к решению. Активный набор Ak (строки матрицы A) 
соответствует активным ограничениям в точке решения (точка лежит на
их границе). Ak обновляется на каждой итерации k и используется при
формировании базиса для направления поиска. Ограничения равенства
всегда входят в активный набор. Направление поиска ˆ
k d используется
для минимизации целевой функции при сохранении активных ограничений. Допустимое подпространство для ˆ
k d формируется из базиса Zk, 
чьи столбцы ортогональны набору Ak , т.е. Ak Zk = 0. Таким образом, при
минимизации гарантируется сохранение активных ограничений (продвижение идет по границе этих ограничений). 
Матрица Zk формируется из последних m – l столбцов матрицы Q, 
где m – общее число ограничений; l – число активных ограничений; Q – 
декомпозиция QR матрицы : .
0
T T T
k k
R
A QA        Направление ˆ
k d есть линейная комбинация столбцов Zk для некоторого вектора p: ˆ
k d = Zkp. Подставив ˆ
k d в квадратичную функцию, получаем
1 () , 2
TT T
kk k q p p Z HZ p c Z p  
142 
где H – гессиан; c – коэффициенты линейной формы целевой функции. 
Дифференцируя по p, имеем
() , T T
kk k   q p Z HZ p Z c
где q(p) есть проекция градиента целевой функции в подпространстве, определяемом Zk; T Zk k HZ – проекционный гессиан. Полагая гессиан
положительно определенной матрицей, что имеет место в SQP, минимум q(p) находим из условия q(p) = 0, которое достигается решением
относительно p системы линейных уравнений
 . T T Zkk k HZ p Z c  
Очередная точка минимизирующей последовательности находится по
формуле
1 ˆ , kkk x x d    где ˆ . k k d Zp 
Если можно взять α, доставляющее минимум целевой функции в
нуль пространстве Ak , то это и будет решением квадратичной задачи
(QP). Иначе α определяется из условия достижения самого близкого из
неактивных ограничений, и это ограничение включается в активный
набор следующей итерации. В этом случае α вычисляется по формуле
( ) min , ˆ
ik i
i i k
Ax b
A d
  
     
в которой участвуют только неактивные ограничения и ˆ 0. A di k 
Когда в активный набор включены независимые ограничения, 
множители Лагранжа λk находятся из системы линейных уравнений
. T
k A c k 
Если все λk положительны, то точка xk – оптимальное решение
квадратичной задачи. Если же есть отрицательный множитель λk и он
соответствует неравенству, то последнее удаляется из активного набора и следует новая итерация. 
Второй алгоритм, используемый для задач среднего размера, реализует хорошо известный симплекс-метод Г. Данцига (George Dantzig). 
Он описан во всех учебниках по линейному программированию и
здесь не рассматривается. 
143 
Для решения линейной задачи с помощью функции linprog необходимо подготовить исходные данные, представляющие задачу, установить нужные значения параметров или принять их по умолчанию
и вызвать функцию. Синтаксис обращения к функции linprog зависит от количества входных и выходных аргументов функции: 
x = linprog(f,A,b) 
x = linprog(f,A,b,Aeq,beq) 
x = linprog(f,A,b,Aeq,beq,lb,ub) 
x = linprog(f,A,b,Aeq,beq,lb,ub,x0) 
x = linprog(f,A,b,Aeq,beq,lb,ub,x0,options) 
x = linprog(problem) 
[x,fval] = linprog(...) 
[x,fval,exitflag] = linprog(...) 
[x,fval,exitflag,output] = linprog(...) 
[x,fval,exitflag,output,lambda] = linprog(...) 
Смысл всех входных и выходных аргументов ясен из модели задачи
и предыдущих разделов. Стартовая точка x0 задается только для алгоритма active-set, другие алгоритмы ее игнорируют. Индикатор остановки алгоритма exitflag может принимать следующие значения: 
1 – получено решение, 
0 – число итераций превысило MaxIter, 
-2 – не найдена допустимая точка, 
-3 – критерий не ограничен, 
-4 – алгоритм столкнулся со значениями NaN, 
-5 – обе задачи не имеют допустимых решений, 
-7 – направление поиска стало слишком малым при отсутствии
прогресса. 
Бóльшая часть параметров оптимизации функции linprog, устанавливаемых через optimset, является общей для всех алгоритмов. 
Это Diagnostics, Display ('off', 'iter', 'final'), LargeScale
(по умолчанию 'on'), MaxIter (85 для большого алгоритма, 10 × 
× число переменных для симплекса и 10 × max (число переменных, 
число неравенств + число границ) для active-set), TolFun (1e-8 для
большого алгоритма, 1e-6 для симплекса, в active-set не используется). Параметр simplex присущ только средним алгоритмам, его значение 'on' соответствует симплекс-методу, 'off' (по умолчанию) – 
active-set. 
144 
Пример 23. 
Найти минимум функции
f(x) = 8x11 + 14x12 + 6x13 + 18x21 + 10x22 + 26x23 + 22x31 + 16x32 + 
+ 18x33 + 14x41 + 24x42 + 40x43 
при условиях
x11 + x12 + x13  70, 
x21 + x22 + x23  84, 
x31 + x32 + x33  40, 
x41 + x42 + x43  150, 
x11 + x21 + x31 + x41 = 56, 
x12 + x22 + x32 + x42 = 74, 
x13 + x23 + x33 + x43 = 100, 
xi  0. 
Сначала подготовим входные аргументы, описывающие задачу: 
f=[8; 14; 6; 18; 10; 26; 22; 16; 18; 14; 24; 40]; 
A=[1 1 1 0 0 0 0 0 0 0 0 0 
 0 0 0 1 1 1 0 0 0 0 0 0 
 0 0 0 0 0 0 1 1 1 0 0 0 
 0 0 0 0 0 0 0 0 0 1 1 1]; 
b=[70; 84; 40; 150]; 
Aeq= [1 0 0 1 0 0 1 0 0 1 0 0 
 0 1 0 0 1 0 0 1 0 0 1 0 
 0 0 1 0 0 1 0 0 1 0 0 1]; 
beq=[56; 74; 100]; 
lb=zeros(12,1); ub=[]; 
Затем выберем алгоритм active-set: 
options=optimset('LargeScale', 'off'); 
начальную точку x0=5*ones(12,1) и вызовем функцию lingprog: 
>>[x,fval,exitflag,output,lambda] = linprog(f,A,b,Aeq,beq,lb,ub,x0,options) 
В результате выполнения функции получили отчет: 
Optimization terminated. 
x = 
 0 
145 
 0.0000 
 70.0000 
 0 
 74.0000 
 0.0000 
 0.0000 
 -0.0000 
 30.0000 
 56.0000 
 0 
 0.0000 
fval = 
 2.4840e+003 
exitflag = 
 1 
output = 
 iterations: 11 
 constrviolation: 2.1221e-015 /нарушение ограничений
 algorithm: 'medium-scale: active-set' 
 cgiterations: [] /число итераций внутреннего
 /алгоритма CG
 message: 'Optimization terminated.' 
lambda = 
 lower: [12x1 double] 
 upper: [12x1 double] 
 eqlin: [3x1 double] 
 ineqlin: [4x1 double] 
Как следует из отчета, решение получено за 11 итераций при допустимо малом нарушении ограничений. Раскроем значения некоторых lambda: 
>> lambda.lower 
ans = 
 6.0000 
 16.0000 
 0 
 4.0000 
 0 
146 
 8.0000 
 8.0000 
 6.0000 
 0 
 0 
 14.0000 
 22.0000 
>> lambda.ineqlin 
ans = 
 12.0000 
 0 
 0 
 0 
>> lambda.eqlin 
ans = 
 -14.0000 
 -10.0000 
 -18.0000 
Множители lambda имеют смысл двойственных переменных. 
В данном примере они показывают, что восемь переменных находятся
на нижней границе, первое неравенство также на границе, т.е. является
активным в оптимальной точке, и все равенства активны. Величина
lambda говорит о значимости соответствующих ограничений. 
Решим эту же задачу симплекс-методом. Для этого в optimset
укажем явно симплекс-алгоритм и в linprog снимем задание начальной точки. Тогда имеем
>>options=optimset('LargeScale', 'off','simplex','on'); 
[x,fval,exitflag,output] = linprog(f,A,b,Aeq,beq,lb,ub,[],options) 
Optimization terminated. 
x = 
 0 
 0 
 70 
 0 
 74 
 0 
147 
 0 
 0 
 30 
 56 
 0 
 0 
fval = 
 2484 
exitflag = 
 1 
output = 
 iterations: 3 
 algorithm: 'medium scale: simplex' 
 cgiterations: [] 
 message: 'Optimization terminated.' 
 constrviolation: 0 
Как видим, симлекс-алгоритм нашел решение всего за три итерации, и при этом нарушений ограничений нет. Оба алгоритма дали одинаковые решения. 
148 
7. ЦЕЛОЧИСЛЕННОЕ ПРОГРАММИРОВАНИЕ. 
ФУНКЦИЯ BINTPROG
Функция bintprog предназначена для решения задач целочисленного программирования с бинарными (булевыми) переменными, 
представленных в форме
f T
x  min 
A x  b, 
Aeq x = beq, 
x=
1
0
. 
Алгоритм основан на хорошо известном методе ветвей и границ. 
В ходе решения строится бинарное дерево поиска, узлы которого соответствуют ослабленным (непрерывным) задачам линейного программирования, в которых условие бинарности переменных заменено более
слабым 0  x  1. 
Если значение критерия очередной ЛП-задачи лучше уже достигнутого в целочисленном решении, называемого рекордом, и есть нецелые переменные, то происходит ветвление. На одной ветви ветвящая
переменная равна 0, на другой – 1. Выбор переменной для ветвления
зависит от значения параметра BranchStrategy. Если оно равно
'mininfeas', выбирается переменная, значение которой наиболее
близко к нулю или единице. Когда же параметр равен 'maxinfeas'
(установлено по умолчанию), берется переменная со значением, наиболее близким к 0,5. 
В случаях, когда ЛП-задача узла: а) неразрешима, б) дает целочисленное решение, в) имеет значение критерия не лучше рекорда, узел
удаляется из дерева и осуществляется переход в другой узел. Стратегия перехода зависит от установки параметра NodeSearchStrategy.
При значении 'df' применяется стратегия поиска «в глубину»: если у
узла есть один нерассмотренный непосредственный потомок, то выбирается его узел, иначе алгоритм переходит к узлу на один уровень выше и выбирает узел его непосредственного потомка. Когда параметр
равен 'bn' (установка по умолчанию), применяется стратегия лучшего узла: выбирается узел, имеющий лучшую нижнюю оценку. 
149 
При получении целочисленного решения со значением критерия
лучше рекорда рекорд обновляется: ему присваивается значение критерия. 
Вызов функции bintprog производится в соответствии с синтаксисом: 
x = bintprog(f) 
x = bintprog(f,A,b) 
x = bintprog(f,A,b,Aeq,beq) 
x = bintprog(f,A,b,Aeq,beq,x0) 
x = bintprog(f,A,b,Aeq,Beq,x0,options) 
x = bintprog(problem) 
[x,fval] = bintprog(...) 
[x,fval,exitflag] = bintprog(...) 
[x,fval,exitflag,output] = bintprog(...). 
Если начальная точка x0 окажется недопустимой, алгоритм возьмет в качестве нее свою точку по умолчанию. Из всех остальных входных и выходных аргументов уточняющих пояснений требуют только
выходы exitflag и output. Индикатор останова алгоритма может
иметь значения: 
1 – достигнута сходимость к решению x, 
0 – число итераций превысило допустимое MaxIter (по умолчанию 100000 × число переменных), 
-2 – задача неразрешима (условия противоречивы), 
-4 – число исследованных узлов превысило допустимое MaxNodes (по умолчанию 1000 × число переменных), 
-5 – время поиска превысило допустимое MaxTime (по умолчанию 7200 с CPU), 
-6 – число итераций решателя ЛП-задачи в узле превысило допустимое MaxRLP (по умолчанию 100 × число переменных). 
Структура output включает поля, в которых содержится число
итераций, число просмотренных узлов, время работы алгоритма, имя
алгоритма, стратегии ветвления и выбора узла, сообщение об останове. 
Изменение значений параметров оптимизации может производиться с помощью функции optimset. Помимо упомянутых выше параметров функция bintprog имеет еще такие параметры, как Display и Diagnostic, а также: NodeDisplayInterval – интервал
(число узлов), через который выводится отчет в режиме 'iter'(по
150 
умолчанию 20), TolFun – конечная чувствительность (допустимость) 
по целевой функции (1.0e-3), TolXInteger – допустимое отклонение
числа от целого, в пределах которого число считается целым (1.0e-8), 
TolRLPFun – конечная чувствительность по целевой функции в алгоритме ЛП (1.0e-6). 
Рассмотрим пример использования функции bintprog. 
Пример 24. 
Найти максимум функции
f(x) = 23x1 + 41x2 + 18x3 + 25x4 + 30x5
при условиях
4x1 + x2 + 2x3 + x4 + 2x5 = 4, 
7x1 + 8x2 + 6x3  15, 
11x2 + 5x3 + 12x4 + 9x5  27, 
x=
1
0
. 
Сначала запишем входные аргументы в требуемом формате: 
f=[-23; -41; -18; -25; -30]; 
A=[7 8 6 0 0; 0 11 5 12 9]; 
b=[15; 27]; 
Aeq=[4 1 2 1 2]; beq=[4]; 
Для получения решения обращаемся к функции bintprog: 
[x,fval,exitflag,output] = bintprog(f,A,b,Aeq,beq) 
После выполнения алгоритма получаем
x = 
 0 
 0 
 1 
 0 
 1 
fval = 
 -48 / значение целевой функции с обратным знаком
exitflag = 
 1 
output = 
 iterations: 25 
151 
 nodes: 27 
 time: 1.6875 
 algorithm: 'LP-based branch-and-bound' 
 branchStrategy: 'maximum integer infeasibility' 
 nodeSrchStrategy: 'best node search' 
 message: 'Optimization terminated.' 
Отчет показывает, что решение найдено за 25 итераций алгоритмом ветвей и границ, основанным на решении ЛП-задач. При этом
просмотрено 27 узлов, использованы стратегии ветвления maxinfeas
и выбора узлов bn. 
152 
8. КВАДРАТИЧНОЕ ПРОГРАММИРОВАНИЕ. 
ФУНКЦИЯ QUADPROG
Задачи, в которых целевая функция является квадратичной, а все
ограничения линейные, называют задачами квадратичного программирования (КП). Для их решения в Toolbox Optimization имеется
функция quadprog. 
Задача КП ставится в виде
2
1
x
T
Hx+f T
x  min 
при условиях
A x  b, 
Aeq x = beq, 
lb  x  ub, 
где H – квадратная матрица (гессиан), остальные обозначения не требуют пояснений. 
В зависимости от размера задачи и свойств матриц функция
quadprog применяет Large Scale или Medium Scale алгоритм. 
Первый алгоритм предназначен для задач большой размерности
при наличии только ограничений на переменные или только ограничений-равенств. При этом матрицы H и Aeq должны быть разреженными, а линейные равенства независимыми (число равенств не может
быть больше числа переменных). Этот алгоритм установлен по умолчанию, но если задача не соответствует условиям его применимости, 
происходит автоматический переход на алгоритм Medium Scale. 
Алгоритм Large Scale построен по методу подпрастранства доверительной области (subspace trust-region method), описанному в предыдущих главах. Напомним, что на каждой итерации решается
подзадача минимизации на выделенном подпространстве S, в результате чего находится очередной шаг к строго допустимому решению задачи. Определение двумерного подпространства S требует решения
большой положительно определенной линейной системы Hp = –g. Решение этой системы находится методом предобусловленных сопряженных градиентов (PCG). Предобусловливатель (preconditioner) для
H – это симметричная положительно определенная матрица M такая, 
что M = C2
и C-1HC –1 – хорошо обусловленная матрица или матрица с
153 
кластеризованными собственными значениями. Итерации PCG выполняются на каждой итерации основного алгоритма (по умолчанию). 
Второй способ решения линейной системы основан на прямой факторизации матрицы H (direct solver). 
Алгоритм Medium Scale реализует метод активного набора (active-set), известного также как метод проекций. Его описание приведено в предыдущих разделах. Алгоритм состоит из двух этапов: на первом этапе находится допустимая начальная точка, на втором генерируется последовательность допустимых точек, сходящаяся к решению. 
Для решения квадратичной задачи с параметрами, установленными по умолчанию, достаточно ввести данные задачи и вызвать функцию quadprog в соответствующем задаче синтаксисе: 
x = quadprog(H,f,A,b) 
x = quadprog(H,f,A,b,Aeq,beq) 
x = quadprog(H,f,A,b,Aeq,beq,lb,ub) 
x = quadprog(H,f,A,b,Aeq,beq,lb,ub,x0) 
x = quadprog(H,f,A,b,Aeq,beq,lb,ub,x0,options) 
x = quadprog(problem) 
[x,fval] = quadprog(...) 
[x,fval,exitflag] = quadprog(...) 
[x,fval,exitflag,output] = quadprog(...) 
[x,fval,exitflag,output,lambda] = quadprog(...) 
Здесь обозначения имеют тот же смысл, что и в ранее рассмотренных функциях. Заметим только, что еcли границы противоречивы, то в
качестве решения х выводится х0 (компонентам, нарушающим границу, придается допустимое значение), а в качестве fval – []. Значения
индикатора exitflag указывают на причину останова алгоритма: 
1 – получена сходимость к решению х; 
3 – изменение значения целевой функции стало меньше допустимого; 
4 – найден локальный минимум; 
0 – число итераций превысило допустимое MaxIter; 
-2 – условия противоречивы; 
-3 – критерий неограничен; 
-4 – в текущем направлении поиска нельзя улучшить функцию; 
-7 – модуль направления поиска стал слишком мал. 
154 
Выходная структура output содержит поля: число итераций, название алгоритма, общее число итераций PCG в Large Scale
(cgiterations), меру оптимальности 1-го порядка для Large Scale
(firstorderopt), величину нарушения ограничений в Medium Scale
(constrviolation). 
На процесс минимизации можно влиять через параметры функции
quadprog. Изменение значений параметров производится, как и раньше, с помощью функции optimset. Часть парметров являются общими для обоих алгоритмов. К ним относятся Display, Diagnostics, 
Large Scale и MaxIter. Параметры, присущие только алгоритму
Large Scale, приведены в прил. 8. Параметром MaxPCGIter можно
ограничивать число итераций PCG на одну итерацию основного алгоритма. Уменьшение этого параметра приводит к увеличению числа основных итераций. Установка параметра PrecondBandWidth в Inf
означает замену PCG прямой факторизацией Чолеску. 
Пример 25. 
Найти минимум функции
1
2 2
2 1 2 12 F x x x x x xx ( ) 10 12 2 4 4   
при условиях
x1 + 3x2  12, 
x1 + x2  3, 
–x1 + x2  2, 
x1  0, x2  0. 
Для решения задачи составляем программу, в которой задаем начальную точку в допустимой области, заносим данные задачи в виде H, 
f, A, b и обращаемся к функции quadprog с указанием в ней нулевых
нижних границ. 
>> x0=[4 1];H=[4 -4;-4 8];f=[10;-12];A=[1 3;-1 -1;-1 1];b=[12;-3;2]; 
[x,fval,exitflag,output] = quadprog(H,f,A,b,[],[],[0 0],[],x0) 
В результате выполнения этой программы получаем
Warning: Large-scale algorithm does not currently solve this problem formulation, using medium-scale algorithm instead. 
Optimization terminated. 
x = 
155 
 0.7000 
 2.3000 
fval = 
 -4.9000 
exitflag = 
 1 
output = 
 iterations: 2 
 constrviolation: -4.4409e-016 
 algorithm: 'medium-scale: active-set' 
 firstorderopt: [] 
 cgiterations: [] 
 message: 'Optimization terminated.' 
В начальном сообщении поясняется, что постановка задачи не соответствует принятой для алгоритма Large Scale и потому он заменен на алгоритм Medium Scale. Этим алгоритмом решение найдено за
две итерации при практически точном соблюдении ограничений
(см. constrviolation). Если не задавать начальную точку, то результат не изменится. В этом случае алгоритм сам определяет начальную
допустимую точку. 
Теперь возьмем начальную точку вне допустимой области: 
>> x0=[0 4];H=[4 -4;-4 8];f=[10;-12];A=[1 3;-1 -1;-1 1];b=[12;-3;2]; 
[x,fval,exitflag,output] = quadprog(H,f,A,b,[],[],[0 0],[],x0) 
Optimization terminated. 
x = 
 0.7000 
 2.3000 
fval = 
 -4.9000 
exitflag = 
 1 
output = 
 iterations: 3 
 constrviolation: -4.4409e-016 
 algorithm: 'medium-scale: active-set' 
 firstorderopt: [] 
 cgiterations: [] 
 message: 'Optimization terminated.' 
156 
Как видно, получено такое же решение, но за три итерации. Очевидно, первая (дополнительная) итерация потребовалась для вхождения в допустимую область. 
Обе начальные точки и точка найденного минимума (обозначена *) 
показаны на рис. 40 на фоне линий уровня. Как и следовало ожидать, 
оптимум лежит на границе. 
Рис. 40. Решение квадратичной задачи из примера 25 
Чтобы увидеть работу алгоритма Large Scale, изменим условия
рассмотренной задачи, удалив линейные неравенства и добавив верхние ограничения на переменные: 
>> x0=[4 1];H=[4 -4;-4 8];f=[10;-12]; 
[x,fval,exitflag,output] = quadprog(H,f,[],[],[],[],[0 0],[5 5],x0) 
x = 
 0.0000 
 1.5000 
fval = 
 -9.0000 
exitflag = 
 3 
output = 
 iterations: 8 
 constrviolation: 0 
157 
 algorithm: 'large-scale: reflective trust-region' 
 firstorderopt: 1.5419e-013 
 cgiterations: 7 
 message: [1x87 char] 
Решение снова получено на границе допустимой области. На поиск минимума затрачено восемь основных итераций и семь итераций
PCG. Алгоритм reflective trust-region оказался очень трудоемким. Действительно, если в этом же примере выключить Large 
Scale, то получим
>> options= optimset('LargeScale','off');x0=[4 1];H=[4 -4;-4 8];f=[10;-12]; 
[x,fval,exitflag,output] = quadprog(H,f,[],[],[],[],[0 0],[5 5],x0,options) 
x = 
 0 
 1.5000 
fval = 
 -9 
exitflag = 
 1 
output = 
 iterations: 2 
 constrviolation: 0 
 algorithm: 'medium-scale: active-set' 
 firstorderopt: [] 
 cgiterations: [] 
 message: 'Optimization terminated.' 
Как видим, здесь такое же решение получено за две итерации. Поэтому рекомендуется начинать решение и больших задач с использования алгоритмов Medium Scale. 
Лабораторная работа № 7 
Решение задач математического программирования
Задания: 
1. Ознакомиться с функциями linprog, bintprog и quadprog и
методами, используемыми в них. Уяснить назначение основных параметров функций. 
158 
2. Двумя методами Medium Scale решить задачу линейного программирования 
f(x) = 1050x11 + 1740x12 + 1395x13 + 644x14 + 840x21 + 1320x22 + 
+ 1260x23 + 529x24 + 770x31 + 1440x32 + 900x33 + 414x34 + 840x41 + 
+ 1380x42 + 945x43 + 621x44  min, 
x11 + x21 + x31 + x41 = 2, 
x12 + x22 + x32 + x42 = 1, 
x13 + x23 + x33 + x43 = 2, 
x14 + x24 + x34 + x44 = 1, 
35x11 + 60x12 + 45x13 + 23x14  62, 
35x21 + 60x22 + 45x23 + 23x24  90, 
35x31 + 60x32 + 45x33 + 23x34  50, 
35x41 + 60x42 + 45x43 + 23x44  120, 
xij  0. 
Повторить решение из разных начальных точек. Сравнить результаты решения. 
3. Задачу из предыдущего пункта решить при условии бинарности
всех переменных. Сравнить показатели решений при различных стратегиях ветвления и перехода. Повторить решение для нахождения максимума целевой функции. 
4. Алгоритмами Large Scale и Medium Scale решить задачу
квадратичного программирования 222
1 2 3 1 2 3 12 13 23 F x x x x x x x xx xx xx ( ) 3 5 10 8 2 5 6 2 min,        
–0,5  x1  5, 0  x2  5, –1  x3  5. 
Выяснить, какую информацию дают значения lambda. 
5. Решить задачу квадратичного программирования из предыдущего пункта, добавив линейные неравенства
2x1 + 3x2 + x3  15, 
x1 + x2 + x3  –0,2. 
Объяснить значения lambda. 
159 
9. ДРУГИЕ ФУНКЦИИ ПАКЕТА TOOLBOX OPTIMIZATION
Помимо функций, предназначенных для решения общих задач
безусловной оптимизации и математического программирования, пакет Toolbox Optimization включает функции для решения ряда
специальных задач, которые ставятся как оптимизационные. В частности, это задачи решения уравнений и задачи на методы наименьших
квадратов и аппроксимации (подбора кривых). Соответствующие
функции будут рассмотрены без описания алгоритмов и несущественных деталей. 
9.1. Нахождение корней функции одной переменной
Эту задачу решает функция fzero. При этом полагается, что
функция непрерывная и в точках корней пересекает ось x, а пользователь может задать точку вблизи искомого корня или интервал, на концах которого функция имеет разные знаки. Поиск осуществляется алгоритмом, использующим комбинацию методов деления отрезка пополам, секущих и обратной квадратичной интерполяции. 
Синтаксис вызова функции fzero: 
x = fzero(fun,x0) 
x = fzero(fun,x0,options) 
x = fzero(problem) 
[x,fval] = fzero(...) 
[x,fval,exitflag] = fzero(...) 
[x,fval,exitflag,output] = fzero(...) 
Как и в предыдущих разделах, аргумент fun задает функцию в виде имени m-файла или анонимно. x0 – точка, вблизи которой предполагается корень, или вектор с двумя элементами, задающими интервал. 
Последний всегда должен быть конечным. За корень х принимается
значение вблизи точки, где функция меняет знак. Только при
exitflag=1 найденная точка является корнем функции. Структура
output помимо общего числа итераций, числа вычислений функции и
алгоритма содержит число итераций для нахождения интервала, содержащего корень (intervaliterations). 
Функция fzero имеет параметры, позволяющие подключать
функции вывода и графики (OutputFcn, PlotFcns), изменять уровень выводимой информации (Display) и допустимое значение по х
160 
(TolX). Кроме того, при включении параметра FunValCheck ('on') 
будет выдаваться ошибка, когда значение целевой функции окажется
комплексным, Inf или NaN. 
Пример 26. 
1. Найти корень функции
f(x) = x
2
 + x – 1. 
Решение при задании точки
>> [x,fval]=fzero('x.^2+x-1',0.6) 
x = 
 0.6180 / это отношение золотого сечения
fval = 
 -1.1102e-016 
Решение при задании интервала
>> [x,fval]=fzero('x.^2+x-1',[0 1]) 
x = 
 0.6180 
fval = 
 0 
2. Найти корень функции
f(x) = 2x
3
 – 7 x – 6. 
Решение
>> [x,fval]=fzero('2*x.^3-7*x-6',[1 5]) 
x = 
 2.2047 
fval = 
 -1.7764e-015 
9.2. Решение системы нелинейных уравнений
Задача определяется выражением
F(x) = 0, 
где x – вектор переменных; F(x) – векторная нелинейная функция. 
Таким образом, речь идет о нахождении корня системы нелинейных уравнений. Для решения такой задачи предназначена функция
fsolve. В ней реализованы три алгоритма: Trust-region dogleg, 
Trust-region-reflective и Levenberg-Marquardt. Все они способны решать задачи большой размерности (Large Scale). Trustregion dogleg установлен по умолчанию, но он может использо-
161 
ваться только когда число уравнений равно числу неизвестных. При
выборе другого алгоритма его следует указать в параметре Algorithm. 
Синтаксис обращения к функции fsolve: 
x = fsolve(fun,x0) 
x = fsolve(fun,x0,options) 
x = fsolve(problem) 
[x,fval] = fsolve(fun,x0) 
[x,fval,exitflag] = fsolve(...) 
[x,fval,exitflag,output] = fsolve(...) 
[x,fval,exitflag,output,jacobian] = fsolve(...). 
Входной аргумент fun – это имя m-файла, в котором вычисляется
F(x) и, возможно, Якобиан. Последний представляет собой матрицу, 
строками которой являются градиенты Fi(x). Якобиан также может
быть выходным аргументом (в последнем варианте обращения). Индикатор останова exitflag может принимать значения: 
1 – установлена сходимость к х; 
2 – изменение х меньше допустимой величины; 
3 – изменение невязки меньше допустимой величины; 
4 – величина направления поиска меньше заданной; 
0 – число итераций или вычислений функции превысило максимально допустимое; 
-1 – останов по причине функции вывода; 
-2 – алгоритм сходится к точке, не являющейся корнем; 
-3 – радиус доверительной области стал слишком малым; 
-4 – невозможно существенно уменьшить невязку в направлении
текущего поиска. Структура output содержит поля, стандартные для
рассматриваемых алгоритмов. 
Параметры функции fsolve, общие и индивидуальные для алгоритмов, приведены в прил. 9. С их помощью можно влиять на процесс
решения. При выборе алгоритма Levenberg-Marquardt можно также
изменить его внутренний параметр , который по умолчанию равен
0,01, указав его в значении Algorithm за именем алгоритма, например
{'levenberg-marquardt',.003}. 
Пример 27. 
1. Решить систему
1 2
2 1
12 2
1 12
2 ,
2 .
x x
x x
x xxe e
x xx e e
 
 
   
  
162 
Перепишем эту систему в требуемой форме: 
1 2
2 1
12 2
1 12
2 0,
2 0.
x x
x x
xx x e e
x xx e e
 
 
    
  
Составим функцию для вычисления левых частей системы: 
function F = equ(x) 
F=[2*x(1)*x(2)-x(2)-exp(-x(1))+exp(-x(2)); 
x(1)-2*x(1)*x(2)-exp(-x(2))+exp(-x(1))]; 
Задав начальную точку, запускаем решение: 
>>x0=[1 1];[x,fval,exit]=fsolve(@equ,x0) 
Equation solved. 
x = 
 0.5000 0.5000 
fval = 
 1.0e-009 * / общий множитель
0.1164 
 -0.1164 
exit = 
 1 
Результаты показывают, что решение системы получено с высокой
точностью (значения обеих функций практически равны нулю). 
2. Решить систему, заданную в матричном виде: 
X × X – 0,5X = 
6 2 . 1 4
     
Сначала записываем m-файл, содержащий вычисляемую функцию: 
function F =equ2(x) 
F=x*x-0.5*x-[6 2;1 4]; 
Затем выбираем в качестве решателя алгоритм LevenbergMarquardt, задаем начальную точку x0 с нулевыми значениями элементов и запускаем программу: 
>>x0=zeros(2,2); 
options=optimset('Algorithm','levenberg-marquardt'); 
[x,fval,exit, output]=fsolve(@equ2,x0,options) 
Equation solved. 
x = 
 -2.1914 -0.4513 
163 
 -0.2257 -1.7401 
fval = 
 1.0e-010 * 
 0.1295 0.1672 
 0.0682 -0.0274 
exit = 
 1 
output = 
iterations: 5 
funcCount: 32 
stepsize: 1.1077e-007 
cgiterations: [] 
firstorderopt: 7.6386e-011 
algorithm: 'Levenberg-Marquardt' 
message: [1x685 char] 
Как видим, система имеет решение и получено оно за пять итераций. Погрешность найденного решения (fval) пренебрежимо мала. 
Если система уравнений линейная AX = B и число уравнений равно
числу переменных, решение получить проще, используя оператор левого матричного деления \, т.е. имеем X = A\B. Эта формула справедлива, 
так как в рассматриваемом случае A\ дает обратную матрицу A–1. 
Пример 28. 
Решить систему уравнений
1 23
123
12 3
8 – 3 6,
4 5 2 13,
–7 9 5.
x xx
xxx
xx x
  

 

  
Решение: 
>> A=[8 -3 1;4 5 -2;-7 1 9]; B=[6;13;5]; 
X=A\B 
Сразу получаем ответ: 
X = 
 1.3534 
 2.0686 
 1.3784 
164 
9.3. Нелинейная задача наименьших квадратов
Задача состоит в минимизации суммы квадратов функций


n
i
i F x f x
1
2 ( ) ( )
при условии lb  x  ub. 
Для решения этой задачи предназначена функция lsqnonlin. Основные алгоритмы, используемые в ней: рефлексивный алгоритм доверительных областей (trust-region-reflective algorithm) и алгоритм Левенберга – Марквардта (Levenberg-Marquardt algorithm). 
Первый алгоритм, установленный по умолчанию, применим, когда размерность F не меньше числа переменных, а второй алгоритм неприменим при наличии границ на переменные. Для обоих алгоритмов необходимо, чтобы функции fi(x) были непрерывными. Параметры этих алгоритмов рассматривались ранее. 
Синтаксис вызова функции lsqnonlin: 
x = lsqnonlin(fun,x0) 
x = lsqnonlin(fun,x0,lb,ub) 
x = lsqnonlin(fun,x0,lb,ub,options) 
x = lsqnonlin(problem) 
[x,resnorm] = lsqnonlin(...) 
[x,resnorm,residual] = lsqnonlin(...) 
[x,resnorm,residual,exitflag] = lsqnonlin(...) 
[x,resnorm,residual,exitflag,output] = lsqnonlin(...) 
[x,resnorm,residual,exitflag,output,lambda] = ... 
lsqnonlin(...) 
[x,resnorm,residual,exitflag,output,lambda,... 
jacobian] = lsqnonlin(...) 
Большинство входных и выходных аргументов функции имеют
тот же смысл, что и в ранее рассмотренных функциях. Заметим, что
под fun понимается функция, вычисляющая все fi(x). Новыми выходными аргументами являются resnorm и residual. Первый из них – 
это значение F(x) в оптимальном решении, а residual – остатки, т.е. 
значения fi(x) в оптимальном решении. 
165 
Пример 29. 
Найти минимум функции
F(x) = (6 – x1)
2
 + (x1 – 2)2
 + (x2 – 1)2
 + (x2 – 3)2
. 
Для решения этой задачи записываем m-функцию
function f=squar(x) 
f(1)=6-x(1); 
f(2)=x(1)-2; 
f(3)=x(2)-1; 
f(4)=x(2)-3; 
и, задав начальную точку, вызываем функцию lsqnonlin: 
>> x0=[1 1];[x,resnorm,residual] = lsqnonlin(@squar,x0) 
Local minimum found. / найден локальный минимум
x = 
 4 2 
resnorm = 
 10 / значение F(x)
residual = 
 2 2 1 -1 / значения f(1), f(2), f(3), f(4)
Пример 30. 
Найти минимум функции
1 2
5
2
12 1
1
( ) (3 5 ) . kx kx
k
F x x xe xe k 
  
Решение: 
1. Записываем m-файл
function F=squar1(x) 
k=1:5; 
F=3*x(1)-x(2)*exp(k*x(1))+x(1)*exp(k*x(2))-5*k; 
2. Вызываем функцию lsqnonlin из выбранной начальной точки: 
>> x0=[-2 0];[x,resnorm,residual] = lsqnonlin(@squar1,x0) 
Local minimum possible. / возможно, найден локальный минимум
x = 
 0.3425 -4.5046 
resnorm = 
 10.1099 
residual = 
 2.3758 -0.0365 -1.3867 -1.2459 0.9946 
166 
9.4. Задача аппроксимации
Рассматривается следующая задача: имеется множество данных, 
отражающих неизвестную зависимость, и необходимо подобрать
функцию (или функции), наиболее близкую к этим данным. Обычно
эта задача решается так: задают вид функции, а ее параметры подбираются методом наименьших квадратов (в этом случае говорят о задаче подгонки кривой). Такой вариант решения реализует функция
lsqcurvefit. 
Формулировка задачи: найти такие коэффициенты x, при которых
выражение
2 ( (, ) ) i i
i
 F x xdata ydata 
достигает минимума. Здесь xdatai и ydatai – известные входные и наблюдаемые выходные данные, а F – некоторая принятая функция с неизвестными коэффициентами x. Возможно также задание границ в виде lb  x  ub. Алгоритмы, используемые в lsqcurvefit, такие же, как
в функции lsqnonlin. 
Синтаксис вызова функции lsqcurvefit:
x = lsqcurvefit(fun,x0,xdata,ydata) 
x = lsqcurvefit(fun,x0,xdata,ydata,lb,ub) 
x = lsqcurvefit(fun,x0,xdata,ydata,lb,ub,options) 
x = lsqcurvefit(problem) 
[x,resnorm] = lsqcurvefit(...) 
[x,resnorm,residual] = lsqcurvefit(...) 
[x,resnorm,residual,exitflag] = lsqcurvefit(...) 
[x,resnorm,residual,exitflag,output] = ... 
lsqcurvefit(...) 
[x,resnorm,residual,exitflag,output,lambda] = ... 
lsqcurvefit(...) 
[x,resnorm,residual,exitflag,output,lambda,... 
jacobian] = lsqcurvefit(...) 
Используемые здесь входные и выходные аргументы не требуют
пояснений, так как уже встречались ранее. Заметим только, что под
fun понимается функция F(x, xdata), а не минимизируемое выражение. 
167 
Пример 31. 
Получены данные измерений входной и выходной величины черного ящика. Значения на входе: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 
15; на выходе: 1,79, 3,22, 4,10, 4,83, 5,21, 5,25, 4,85, 4,50, 4,05, 3,31, 
2,70, 2,00, 1,45, 0,75, 0,29. Требуется описать зависимость выхода от
входа в классе функций ( ) sin( ) . x F x k xe  
Очевидно, что в такой постановке задача сводится к нахождению
неизвестных коэффициентов функции k, α и . Сначала для вычисления значений заданной функции создаем m-файл: 
function F=squar2(x,xdata) 
F=x(1)*sin(x(2)*xdata).*exp(x(3)*xdata); 
где искомые коэффициенты обозначены как x(1), x(2) и x(3) соответственно. 
Затем исполняем программу: 
>> x0=[5; 1; -0.5];xdata=[1 2 3 4 5 6 7 8 9 10 11 12 13 14 15]; 
ydata=[1.79 3.22 4.10 4.83 5.21 5.25 4.85 4.50 4.05 3.31 2.70 2.00 … 
1.45 0.75 0.29]; 
[x,resnorm] = lsqcurvefit(@squar3,x0,xdata,ydata) 
Local minimum possible. 
x = 
 9.8913 
 0.2016 
 -0.0975 
resnorm = 
 0.0467 
Из отчета следует, что k = 9,8913, α = 0,2016 и  = –0,0975. Значение resnorm и рис. 41 показывают, что полученная функция
0,0975 ( ) 9,8913sin(0,2016 ) x F x xe  хорошо аппроксимирует представленные данные. 
168 
Рис. 41. Аппроксимация данных подходящей функцией
9.5. Неотрицательный линейный метод наименьших квадратов
Постановка задачи: 
2
2 minx Cx d  
при условии x  0. Предполагается, что система недоопределена или
переопределена, т.е. число строк не равно числу переменных. 
Для решения этой задачи предназначена функция lsqnonneg. Решение ищется с использованием базисных векторов и нахождением
ассоциированных с ними элементов lambda. На каждой итерации базисный вектор, которому соответствует наибольшее значение lambda, 
заменяется небазисным. Решение завершается, когда lambda  0. 
Синтаксис вызова lsqnonneg: 
x = lsqnonneg(C,d) 
x = lsqnonneg(C,d,options) 
x = lsqnonneg(problem) 
[x,resnorm] = lsqnonneg(...) 
[x,resnorm,residual] = lsqnonneg(...) 
[x,resnorm,residual,exitflag] = lsqnonneg(...) 
[x,resnorm,residual,exitflag,output] = lsqnonneg(...) 
[x,resnorm,residual,exitflag,output,lambda] = ... 
lsqnonneg(...)
169 
Смысл всех обозначений очевиден. Элементы lambda(i)  0, когда
x(i) = 0, и равны нулю при x(i) > 0. 
Пример 32. 
Найти решение задачи неотрицательных наименьших квадратов с
тремя переменными и четырьмя равенствами при следующих C и d: 
5 3 2 15
69 1 9 , . 483 4
10 5 7 11
C d
                      
Введя исходные данные и обратившись к функции lsqnonneg, 
получаем
>> C=[5 -3 2;6 9 -1;4 8 3;10 5 -7]; 
d=[15;9;4;11]; 
[x,resnorm] = lsqnonneg(C,d) 
x = 
 1.6623 
 0 
 0.7264 
resnorm = 
 51.0769 
Если снять ограничение неотрицательности переменных, то решение можно получить с помощью оператора левого матричного деления \. 
Для нашего примера имеем
>> C=[5 -3 2;6 9 -1;4 8 3;10 5 -7]; 
d=[15;9;4;11]; x=C\d 
Получаем решение: 
x = 
 2.1397 
 -0.6322 
 0.8747 
Подсчитаем resnorm=(C*x-d)'*(C*x-d)=13.6183 (' – символ транспонирования). Как видим, решение существенно улучшилось за счет
возможности более широкого выбора значений переменных. 
170 
9.6. Линейная задача наименьших квадратов
с ограничениями
Рассмотренная выше задача является частным случаем более общей задачи, модель которой имеет вид
2 1
2 2 minx Cx d  
при условиях
A  x  b, 
Aeq  x = beq, 
lb  x  ub. 
В такой постановке задача решается с помощью функции пакета
lsqlin. При отсутствии равенств и неравенств и числе строк матрицы
C не меньше числа столбцов применяется алгоритм Large Scale, 
основанный на subspace trust-region method. Этот алгоритм установлен по умолчанию. Если указанные условия не выполняются или
алгоритм Large Scale выключен (опция 'off'), решение ищется алгоритмом Medium Scale как в функции quadprog. Параметры функции lsqlin аналогичны ранее рассмотренным параметрам для таких
алгоритмов. 
Синтаксис обращения к функции lsqlin: 
x = lsqlin(C,d,A,b) 
x = lsqlin(C,d,A,b,Aeq,beq) 
x = lsqlin(C,d,A,b,Aeq,beq,lb,ub) 
x = lsqlin(C,d,A,b,Aeq,beq,lb,ub,x0) 
x = lsqlin(C,d,A,b,Aeq,beq,lb,ub,x0,options) 
x = lsqlin(problem) 
[x,resnorm] = lsqlin(...) 
[x,resnorm,residual] = lsqlin(...) 
[x,resnorm,residual,exitflag] = lsqlin(...) 
[x,resnorm,residual,exitflag,output] = lsqlin(...) 
[x,resnorm,residual,exitflag,output,lambda] = ... 
lsqlin(...) 
Входные аргументы функции описывают задачу, а выходные аргументы здесь те же, что в функции lsqnonneg. Положительные значения exitflag говорят о нормальном завершении поиска решения. 
171 
Пример 33. 
Найти решение задачи наименьших квадратов с ограничениями
при следующих данных: 
5 3 2 15
69 1 9 , , 483 4
10 5 7 11
C d
                      
x1 – 0,5x2 + 3x3  9, 
–2x1 + 6x2 + 2,3x3  5,5, 
–0,5  xj  2, j = 1, 2, 3. 
Для решения задачи записываем все входные аргументы и вызываем функцию lsqlin: 
>> C=[5 -3 2;6 9 -1;4 8 3;10 5 -7];... 
d=[15;9;4;11]; A=[1 0.5 3;-2 6 2.3];b=[9;5.5];... 
lb=-0.5*ones(3,1);ub=2*ones(3.1);... 
[x,resnorm,residual,exitflag,output,lambda] = lsqlin(C,d,A,b,[],[],lb,ub) 
Optimization terminated. 
x = 
 2.0000 
 -0.5000 
 0.8095 
resnorm = 
 15.4643 
residual = /остатки по четырем равенствам (Cx – d)
 -1.8810 
 -2.3095 
 2.4286 
 0.8333 
exitflag = 
 1 
output = 
 iterations: 3 
 constrviolation: 0 
 algorithm: 'medium-scale: active-set' 
 firstorderopt: [] 
172 
 cgiterations: [] 
 message: 'Optimization terminated.' 
>> lambda.lower 
0 
8.4524 
0 
>> lambda.upper 
5.2143 
0 
0 
>> lambda.ineqlin 
0 
0 
Как следует из полученного отчета, решение найдено за три основные итерации алгоритмом Medium Scale: active-set без использования PCG. Значения lambda показывают, что решение лежит на
одной нижней и одной верхней границе и внутри области, задаваемой
линейными неравенствами. 
Лабораторная работа № 8 
Решение уравнений и метод наименьших квадратов
Задания: 
1. Ознакомиться с назначением и синтаксисом функций fzero, 
fsolve, lsqnonlin, lsqcurvefit, lsqnonneg и lsqlin. 
2. Найти все корни и стационарные точки функции
fx x x ( ) sin 0,5 0,5   на интервале 0  x  3. 
3. Решить систему
X +0,5X×X – 0,1X×X×X= 5 2 . 1 4
      
4. Найти минимум функции
1 2
4
0,5 2
12 12
0
( ) ( ). t t x x
t
F x x x x x te

  
5. Пусть выход y некоторого объекта связан с входом x зависимостью
x y x xe x     
173 
в диапазоне 0  x  6. Задать ряд значений x (24 или 30 точек) и при
значениях параметров α = –0,1,  = –0,2,  = 2 получить соответствующий ряд y. К этому ряду добавить помехи, используя случайную величину с равномерным распределением в диапазоне от –0,2 до 0,2 и нулевым математическим ожиданием, для чего использовать функцию
rand. По данным выхода с помехами y
 и входа x восстановить значения параметров α,  и  двумя алгоритмами, сравнить результаты и
представить их графически. 
174 
СПИСОК РЕКОМЕНДУЕМОЙ ЛИТЕРАТУРЫ
По MATLAB
1. Дьяконов В.П. MATLAB 7.*/R2006/R2007: самоучитель. – М.: 
ДМК Пресс, 2008. 
2. Дьяконов В.П. MATLAB 6.5 SP1/7+Simulink 5/6 в математике и
моделировании. – М.: СОЛОН-Пресс, 2005. 
По методам оптимизации
3. Аоки М. Введение в методы оптимизации: пер. с англ. – М.: 
Наука, 1977. 
4. Аттетков А.В., Галкин С.В., Зарубин В.С. Методы оптимизации: учебник для вузов / под ред. В.С. Зарубина. – 2-е изд., стер. – М.: 
Изд-во МГТУ им. Н.Э. Баумана, 2003. 
5. Базара М., Шетти К. Нелинейное программирование. Теория и
алгоритмы: пер. с англ. / под ред. Д.Б. Юдина. – М.: Мир, 1982. 
6. Гладков Л.А., Курейчик В.В., Курейчик В.М. Генетические алгоритмы: учеб. пособие для вузов / под ред. В.М. Курейчика. – 2-е
изд., испр. и доп. – М.: Физматлит, 2006. 
7. Гольдштейн А.Л. Исследование операций: многокритериальные задачи: конспект лекций. – Пермь: Изд-во Перм. гос. техн. ун-та, 
1995. 
8. Жиглявский А.А., Жилинскас А.Г. Методы поиска глобального
экстремума. – М.: Наука, 1991. 
9. Карманов В.Г. Математическое программирование: учеб. пособие для вузов. – 6-е изд., испр. – М.: Физматлит, 2008. 
10. Корнеенко В.П. Методы оптимизации: учебник. – М.: Высш. 
шк., 2007. 
11. Подиновский В.В., Ногин В.Д. Парето-оптимальные решения
многокритериальных задач. – М.: Наука, 1982. 
12. Реклейтис Г., Рейвиндран А., Рэгсдел К. Оптимизация в технике: в 2 кн.: пер. с англ. – М.: Мир, 1986. 
13. Соболь Б.В., Месхи Б.Ч., Каныгин Г.И. Методы оптимизации: 
практикум. – Ростов-н/Д: Феникс, 2009. 
14. Федунец Н.И., Черников Ю.Г. Методы оптимизации: учеб. 
пособие для вузов. – М.: Изд-во МГГУ, 2009. 
175 
ПРИЛОЖЕНИЕ 1
Параметры fminunc
Параметры, общие для Large Scale и Medium Scale
Параметр Описание Значение по
умолчанию
Display Задает уровень выводимой информации: 
'off'– нет вывода, 'final' – только
итоговый отчет, 'iter'– по каждой итерации, 'iter-detailed' – детальный,
'notify' – вывод только о несходимости,
'notify-detailed', 'final-detailed'
'final'
DerivativeCheck Сравнение аналитического градиента с конечно-разностным: 'off', 'on'
'off' 
Diagnostics Диагностическая информация о целевой
функции: 'off', 'on'
'off' 
DiffMaxChange Максимальное приращение переменных
при конечно-разностном вычислении градиента
0.1 
DiffMinChange Минимальное приращение переменных
при конечно-разностном вычислении градиента
1e-8 
FunValCheck Контроль типа возвращаемого значения
целевой функции: 'off', 'on'
'off' 
GradObj Использование аналитического градиента: 
'on', 'off' – конечно-разностный метод
'off' 
LargeScale Тип алгоритма: 'on' – Large Scale, 
'off' – Medium Scale
'on' 
MaxFunEvals Максимальное число вычислений функции 100 × число
переменных
176 
MaxIter Максимальное число итераций 400 
OutputFcn Имя пользовательской функции вывода,
вызываемой на каждой итерации
[] 
PlotFcns Имя функции вывода графики: 
@optimplotx, @optimplotfunccount, 
@optimplotfval, 
@optimplotstepsize,
@optimplotfirstorderopt, 
функция пользователя
[] 
TolFun, TolX Конечное допустимое значение функции и x 1e-6 
TypicalX Вектор типовых значений x. Для масштабирования при конечно-разностном способе
Все = 1 
Параметры только для Medium Scale
Параметр Описание Значение по
умолчанию
FinDiffType Способ вычисления конечной разности
для градиентов: 'forward' (сдвигом
вперед), 'central'
'forward' 
HessUpdate Метод выбора направления поиска в квазиньютоновском алгоритме: 'bfgs',
'dfp', 'steepdesc'
'bfgs'
InitialHessMatrix Задание начальной матрицы (только при
установке InitialHessType в 'usersupplied'): положительный скаляр (все
элементы), положительный вектор (диагональная матрица со значениями вектора) 
___ 
InitialHessType Тип начальной матрицы в квазиньютоновском методе: 'identity',
'scaled-identity', пользователя
'scaledidentity' 
177 
Параметры только для Large Scale
Параметр Описание Значение по
умолчанию
Hessian Способ вычисления гессиана: 'on' –
аналитически, 'off' – конечными разностями
'off' 
HessMult Задает функцию, вычисляющую произведение матрицы Гессе на вектор (при
установке Hessian -'on')
___ 
HessPattern Образец разреженности гессиана, используемый для аппроксимации матрицы разреженными конечными разностями для
большеразмерных задач. При неизвестной
структуре HessPattern устанавливают
на плотную матрицу с использованием
полных конечных разностей
Плотная
матрица
MaxPCGIter Максимальное число итераций метода
предобусловленного сопряженного градиента (PCG) 
Число переменных/2
PrecondBandWidth Параметр PCG. При установке в Inf скорее используется прямая факторизация,
чем CG
Диагональная
предобусловленность
TolPCG Конечная допустимая величина для итерации PCG (в критерии окончания) 
0.1 
ПРИЛОЖЕНИЕ 2 
Параметры fmincon
Параметры, общие для всех алгоритмов
Параметр Описание Значение по
умолчанию
Algorithm Выбор алгоритма: 
'trust-region-reflective', 'activeset', 'interior-point', 'sqp'
'trustregionreflective'
178 
DerivativeCheck,
Diagnostics,
DiffMaxChange,
DiffMinChange,
Display, FinDiffType, FunValCheck, GradObj,
MaxFunEvals,
MaxIter, OutputFcn, TolFun,
TolX, TypicalX 
То же, что для fminunc (прил. 1) Прил. 1 
GradConstr 'on' – использовать аналитический градиент функций нелинейных ограничений,
'off'– вычисление через конечные разности
'off'
PlotFcns Задает функцию графики: 
@optimplotx, @optimplotfunccount, 
@optimplotfval, 
@optimplotconstrviolation, @optimplotstepsize, @optimplotfirstorderopt
[] 
TolCon Допустимое нарушение ограничения 1e-6
UseParallel 'always'– вычисление градиентов в параллель, 'never' – нет
'never' 
Параметры для Trust-Region-Reflective
Параметр Описание Значение по
умолчанию
Hessian, HessMult 
HessPattern, MaxPCGIter,PrecondBandWidth, TolPCG
То же, что для Large Scale fminunc
(прил. 1) 
Прил. 1 
Параметры для Active-Set
Параметр Описание Значение по
умолчанию
MaxSQPIter Максимальное число SQP-итераций 10×число
переменных
179 
RelLineSrchBnd Коэффициент в ограничении длины шага
поиска, так что общее смещение по x ограничивается 
|Δx(i)| ≤ relLineSrchBnd·max(|x(i)|.|typicalx(i)|)
[] 
RelLineSrchBndDuration 
Число итераций, на которых граница, определяемая RelLineSrchBnd, будет активной
1 
TolConSQP Допустимое нарушение ограничений во
внутренних итерациях SQP
1e-6
Параметры для Interior-Point
Параметр Описание Значение по
умолчанию
AlwaysHonorConstraints
Установка 'bounds' обеспечивает выполнение ограничений на каждой итерации, 'none' – требование снимается
'bounds'
HessFcn Задает функцию вычисления гессиана, когда параметр Hessian равен 'user-supplied' 
____ 
Hessian Способ вычисления гессиана: 
'bfgs', 'fin-diff-grads' (конечными разностями), 'lbfgs',
{'lbfgs',Positive Integer}
(оба bfgs с ограничением на
число учитываемых прошедших
итераций),'user-supplied' (по
функции пользователя) 
'bfgs'
HessMult Управляет функцией пользователя
при установке Hessian в 'usersupplied'
___ 
InitBarrierParam Начальное значение барьера 0.1 
InitTrustRegionRadius 
Начальный радиус доверительной
области
число
переменных
MaxProjCGIter Допустимое число внутренних итераций метода проектируемых сопряженных градиентов
2 × (число
переменных
минус число
равенств) 
180 
ObjectiveLimit Если значение цлевой функции становится меньше ObjectiveLimit,
итерации останавливаются – задача
неограничена
-1e20
ScaleProblem Установка в 'obj-and-constr'
приводит к нормализации всех ограничений и целевой функции,
в 'none' – нормализация отключена
'obj-andconstr' 
SubproblemAlgorit
hm 
Вычисление шага итерации при
'ldl-factorization' быстрее,
чем при 'cg' (сопряженный градиент), но 'cg' может быть быстрее при больших задачах с плотным
гессианом
'ldlfactorization'
TolProjCG Относительная допустимость для
внутренних итераций алгоритма
проекции сопряженного градиента
0.01 
TolProjCGAbs Абсолютная допустимость для
внутренних итераций PCG
1e-10 
Параметры для SQP
Параметр Описание Значение по
умолчанию
ObjectiveLimit 
ScaleProblem
Так же, как для Interior-Point – 
ПРИЛОЖЕНИЕ 3 
Параметры GlobalSearch и MultiStart
Параметры, общие для GlobalSearch и MultiStart
Параметр Описание Значение по
умолчанию
Display Задает уровень выводимой информации
об итерациях: 'off' – нет вывода, 'final' – только итоговый отчет, 'iter' –
по каждой глобальной итерации
'final'
181 
TolFun Величина неразличимости значений целевых функций
1e-6
TolX Величина неразличимости точек по расстоянию между ними. Решения идентичны, если удовлетворяются одновременно
TolFun и TolX
1e-6
MaxTime Максимальное время выполнения в секундах Inf
StartPointsToRun Выбор точек, используемых для запуска: 
'all' – все стартовые точки, 'bounds' –
только удовлетворяющие границам,
'bounds-ineqs' – удовлетворяющие границам и неравенствам. Используется на
второй стадии алгоритма
'all'
Параметры только для GlobalSearch
Параметр Описание Значение по
умолчанию
NumTrialPoints Число потенциально стартовых точек для
исследования (в дополнение к x0). Для
запуска используются те из них, что проходят проверки
1000 
BasinRadiusFactor 
Для уменьшения радиуса бассейна используется коэффициент (1-
BasinRadiusFac-tor)
0.2 
DistanceThreshold
Factor 
Множитель для определения, находится
ли пробная точка в существующем бассейне 
0.75 
MaxWaitCycle Число последовательных пробных точек. 
Если для них функция штрафа достигает
порога штрафа, то порог увеличивается
посредством PenaltyThresholdFactor;
если они принадлежат бассейну, то
уменьшается радиус этого бассейна посредством BasinRadiusFactor
20 
PenaltyThresholdFactor 
Используется для увеличения порога
штрафа
0.2 
NumStageOnePoints 
Число стартовых точек на первой стадии
алгоритма
200 
182 
Параметры только для MultiStart 
Параметр Описание Значение по
умолчанию
UseParallel Определяет способ вычислений в поиcке: 
’never’ – однопроцессорный, 'always' –
распределение стартовых точек по многим
процессорам
’never’
ПРИЛОЖЕНИЕ 4 
Параметры Direct Search
Параметр Описание Значение по
умолчанию
Cache При включении ('on') сохраняется история
окружения и точки, близкие к нему, повторно не проверяются. При стохастической
функции 'on' не рекомендуется
'off' 
CacheSize Размер памяти на историю 1e4 
CacheTol Определяет близость текущих точек к точкам истории, при непревышении которой
точки не проверяются (если 'Cache' установлен в 'on')
Eps 
(2^(-52)) 
CompletePoll Проверка точек окружения, всех ('on') или
до лучшей ('off')
'off' 
CompleteSearch Поиск точек окружения: 'on'– всех, 'off' –
до лучшей
'off' 
Display Уровень вывода результатов: 'off',
'iter', 'diagnose', 'final'
'final' 
InitialMeshSize 
Начальный размер окружения 1.0 
InitialPenalty Начальное значение параметра штрафа 10 
MaxFunEvals Максимальное число вычислений целевой
функции
2000 × число
переменных
MaxIter Максимальное число итераций 100 × число
переменных
MaxMeshSize Максимальный размер окружения Inf 
MeshAccelerator 
'on'- ускорять, 'off'- не ускорять сходимость вблизи минимума 
'off' 
183 
MeshContraction 
Коэффициент сокращения окружения при
неуспешной итерации
0.5 
MeshExpansion Коэффициент расширения окружения при
успешной итерации
2.0 
MeshRotate Вращать образец до того, как точку объявить минимумом
'off' 
OutputFcn Пользователь определяет функцию, вызываемую на каждой итерации (@psoutputhistory)
[] 
PenaltyFactor Коэффициент изменения штрафа 100 
PlotFcn Задает функцию вывода графика:
@psplotbestf, @psplotmeshsize,
@psplotfuncount, @psplotbestx 
[] 
PlotInterval Определяет число интервалов, через которое
вызывается функция графики
1 
PollingOrder Порядок опроса точек: 'Random', 'Success', 'Consecutive'
'Consecutive' 
PollMethod Вариант метода: 
'GPSPositiveBasis2N', 'GPSPositiveBasisNp1', 'GSSPositiveBasis2N',
'GSSPositiveBasisNp1', 'MADSPositiveBasis2N','MADSPositiveBasisNp1'
'GPSPositiveBasis2N' 
ScaleMesh Автоматическое масштабирование переменных ('on', 'off') 
'on' 
SearchMethod С дополнительным поиском:
@GPSPositiveBasis2N, 
@GPSPositiveBasisNp1, 
@GSSPositiveBasis2N, GSSPositiveBasisNp1, @MADSPositiveBasis2N, 
@MADSPositiveBasisNp1, @searchga, 
@searchlhs, @searchneldermead,[]
[] 
TimeLimit Общее время оптимизации, с Inf 
TolBind Допустимость по границам 1e-3 
TolCon Допустимость по ограничениям 1e-6 
TolFun Допустимость по целевой функции 1e-6 
TolMesh Допустимость по размеру окружения 1e-6 
olX Допустимость по переменной 1e-6 
UseParallel Распараллеливать вычисления по точкам
('always') или нет ('never') 
'never' 
Vectorized Определять, является ли функция векторной
('on') 
'off' 
184 
ПРИЛОЖЕНИЕ 5 
Параметры Simulated Annealing
Параметр Описание Значение по
умолчанию
AcceptanceFcn Задает функцию, определяющую, принята
ли новая точка в качестве текущей
@acceptancesa 
AnnealingFcn Задает функцию, используемую для генерации новых точек: собственная,
@annealingboltz, @annealingfast
@annealing
fast 
DataType Тип переменной: 'custom', 'double' 'double' 
Display Уровень вывода: 'off', 'iter', 'diagnose', 'final' 
'final' 
DisplayInterval Интервал в итерациях между выводами 10 
HybridFcn Задает функцию, запускаемую автоматически в течение или конце итераций решателя: собственная, @fminsearch,
@patternsearch, @fminunc,
@fmincon, []
[] 
HybridInterval Задает интервал (если не 'end' или
'never'), на котором вызывается HybridFcn: целое число, 'never', 'end'
'end' 
InitialTemperature 
Задает начальную температуру 100 
MaxFunEvals Задает максимальное число вычислений
целевой функции
3000 × число
переменных
MaxIter Задает максимальное число итераций Inf 
ObjectiveLimit Желаемое минимальное значение целевой
функции
-Inf 
OutputFcns Задает функцию(и), получающую(ие) данные итерации и возможно изменяющую(ие) параметры процесса: собственная, [] 
[] 
PlotFcns Задает функцию(и) графики, вызываемую(ые) в течение итераций: собственная, 
@saplotbestf, @saplotbestx , 
@saplotf , @saplotstopping, 
@saplottemperature, []
[] 
PlotInterval Задает число итераций, через которое вызывается функция графики
1 
185 
ReannealInterval Задает интервал, через который происходит переотжиг
100 
StallIterLimit Задает число итераций, по которому вычисляется среднее значение изменения
функции
500 × число
переменных
TemperatureFcn Задает функцию обновления графика температуры: собственная, @temperatureboltz, @temperaturefast, @temperatureexp
@temperatureexp 
TimeLimit Задает предел времени работы алгоритма, с Inf 
TolFun Задает допустимое значение функции 1e-6 
ПРИЛОЖЕНИЕ 6 
Параметры Genetic Algorithm (ga и gamultiobj) 
Параметр Описание Значение по
умолчанию
CreationFcn Задает функцию, создающую начальную популяцию: @gacreationuniform, @gacreationlinearfeasible
@gacreationuniform 
CrossoverFcn Задает функцию кроссовера: 
@crossoverheuristic, 
@crossoverscattered, 
@crossoverintermediate,@crossoversinglepoint, @crossovertwopoint, 
@crossoverarithmetic
@crossoverscattered 
CrossoverFraction 
Доля популяции следующего поколения, создаваемая кроссовером
0.8 
Display Уровень вывода: 'off', 'iter', 'diagnose', 'final'
'final' 
DistanceMeasu–
reFcn
Задает функцию, которая вычисляет меру
расстояния между особями в пространстве
переменных (генотип) или функции (фенотип): {@distancecrowding, 'phenotype'}
[] 
EliteCount Число элитных особей, Не используется в
gamultiobj
2 
FitnessLimit Значение фитнес-функции, при достижении
которого останавливается алгоритм
-Inf 
186 
FitnessScalingFcn 
Задает функцию, масштабирующую фитнесфункцию: @fitscalingshiftlinear,
@fitscalingprop, @fitscalingtop,
@fitscalingrank
@fitscalingrank 
Generations Определяет максимальное число итераций 100 
HybridFcn Задает функцию, которая продолжает оптимизацию после окончания ga: собственная,
@fminsearch, @patternsearch,
@fminunc, @fmincon или {@solver, hybridoptions}(при типе данных double)
[] 
InitialPenalty
Начальное значение параметра штрафа 10 
InitialPopulation 
Задаваемая пользователем матрица начальной популяции или ее части
[] 
InitialScores Задаваемый пользователем вектор-столбец
начальных меток фитнес, возможно частичный 
[] 
MigrationDirection 
Направление миграции (перемещения):
'both', 'forward'
'forward' 
MigrationFraction 
Доля особей в каждой подпопуляции, перемещаемая в другую подпопуляцию
0.2 
MigrationInterval 
Число поколений между миграциями особей
между подпопуляциями
20 
MutationFcn Указывает функцию получения потомков мутацией: @mutationuniform, @mutationadaptfeasible, @mutationgaussian
@mutation 
gaussian 
OutputFcns Указывает функцию, вызываемую на каждой
итерации: @gaoutputgen
[] 
ParetoFraction 
Доля особей, удерживаемых на первом фронте Парето, в то время как решатель выбирает
особи из более высоких фронтов
0.35 
PenaltyFactor Коэффициент обновления штрафа 100 
PlotFcns Задает функции графики: 
@gaplotbestf, @gaplotbestindiv,
@gaplotdistance, @gaplotexpectation,
@gaplotgeneology, @gaplotselection,
@gaplotrange, @gaplotscorediversity,
@gaplotscores, gaplotstopping
[] 
PlotInterval Число поколений между вызовами функций
графики
1 
187 
PopInitRange Матрица или вектор диапазона особей в начальной популяции
[0;1] 
PopulationSize 
Размер популяции, целое число или вектор 20 
PopulationType 
Задает тип данных популяции: 'bitstring', 'custom' (оба при отсутствии
ограничений),'doubleVector'
'doubleVec
tor' 
SelectionFcn Определяет функцию выбора родителей:
@selectionremainder,
@selectionuniform,
@selectionstochunif,
@selectionroulette,
@selectiontournament
@selection
stochunif 
StallGenLimit Число последовательных поколений, не
дающее улучшение целевой функции, после
которого останавливается алгоритм
50 
StallTimeLimit 
Время, за которое, если нет улучшения целевой функции, алгоритм останавливается, с 
Inf 
TimeLimit Максимально допустимое время работы ga, с Inf 
TolCon Приемлемая величина нарушения нелинейных ограничений
1e-6 
TolFun Если изменение целевой функции за StallGenLimit поколений меньше этой величины,
алгоритм останавливается
1e-6 
UseParallel Определяет, вычислять ли фитнес-функции
популяции в параллель: 'always','never'
'never' 
Vectorized Определяет вычисление фитнес-функции как
векторной величины: 'on','off'
'off' 
ПРИЛОЖЕНИЕ 7 
Параметры fgoalattain и fminimax
Параметр Описание Значение по
умолчанию
DerivativeCheck Сравнивает вычисление производных по
аналитическим записям и по конечноразностному способу: 'on', 'off'
'off' 
Diagnostics Показывать или нет диагностическую информацию о функции: 'on', 'off'
'off' 
188 
DiffMaxChange Максимальное изменение переменных при
конечно-разностном вычислении градиентов
0.1 
DiffMinChange Минимальное изменение переменных при
конечно-разностном вычислении градиентов
1e-8 
Display Уровень вывода: 'off','iter','iterdetailed','notify'(вывод только при
несходимости),'notify-detailed', 'final','final-detailed'
'final' 
FinDiffType Способ вычисления конечной разности для
градиентов: 'forward' (сдвигом вперед),
'central'
'forward' 
FunValCheck Показывать или нет ошибку при неправильных значениях функций (комплексных, Inf или NaN): 'on', 'off'
'off' 
GoalsExactAchieve 
Задает число целевых функций, по которым требуется, чтобы они равнялись целевым значениям (только для fgoalattain)
0 
MinAbsMax Число функций fi(x), по которым для минимизации берется максимальная абсолютная величина (только для fminmax) 
0 
GradObj, GradConstr 
Их включение ('on') означает, что градиенты целевых функций и нелинейных ограничений даются пользователем в mфайлах
'off' 
MaxFunEvals Максимально допустимое число вычислений функции
100 × число
переменных
MaxIter Максимально допустимое число итераций 400 
MaxSQPIter Максимально допустимое число итераций
SQP-алгоритма
>10 × число
переменных
MeritFunction 'multiobj' – использование функции
качества goal attainment/minimax,
'singleobj' – использование функции
качества fmincon
'multiobj' 
OutputFcn Задает одну или более функций вывода
пользователя
[] 
189 
PlotFcns Задает функции графики: @optimplotx,
@optimplotfunccount, 
@optimplotfval,
@optimplotconstrviolation, 
@optimplotstepsize
[] 
RelLineSrchBnd Коэффициент для ограничения величины
смещения по x в линейном поиске:
|Δx(i)| ≤ relLineSrchBnd·max(|x(i)|.|typicalx(i)|).
[] 
RelLineSrchBndDuration 
Число итераций, на которых ограничение
на |Δx(i)| должно быть активным
1 
TolCon Допустимая конечная величина нарушений
ограничений
1e-6 
TolConSQP Допустимая конечная величина нарушений
ограничений в итерациях SQP
1e-6 
TolFun Допустимое конечное изменение значения
функции
1e-6 
TolX Допустимое конечное изменение по x 1e-6 
TypicalX Fgoalattain применяет для шкалирования конечных разностей при вычислении
градиента
Единичный
вектор с размером, равным числу
переменных
UseParallel Задает способ вычисления градиентов:
'always' (параллельный), 'never' (нет)
'never' 
ПРИЛОЖЕНИЕ 8 
Параметры quadprog
Параметр Описание Значение по
умолчанию
HessMult Задает функцию вычисления произведения
H×Y
___ 
MaxPCGIter Максимальное число итераций PCG Число переменных/2
PrecondBandWidth
Определяет метод решения большой системы: 0 – PCG, Inf – прямая факторизация
0 
190 
TolFun Допустимое отклонение целевой функции При границах
2.2204e-14, 
при равенствах 1e-6
TolPCG Конечная допустимость в PCG 0.1 
TolX Конечная допустимость по х 2.2204e-14 
TypicalX Типовые значения х для внутреннего масштабирования. Эффективно при наличии неограниченных компонент х и TypicalX>1
Все компоненты равны
1 
ПРИЛОЖЕНИЕ 9 
Параметры fsolve
Общие для всех алгоритмов
Параметр Описание Значение по
умолчанию
Algorithm Используемый алгоритм: 'trustregion-dogleg', 'trust-regionreflective', 'levenberg-marquardt' 
'trustregiondogleg'
DerivativeCheck,
Diagnostics, 
DiffMaxChange,
DiffMinChange,
Display, FunValCheck, MaxFunEvals, MaxIter,
OutputFcn, TolFun, TolX, TypicalX 
Как в предыдущих приложениях – 
PlotFcns Задает функцию графики: @optimplotx, 
@optimplotfunccount, @optimplotfval, @optimplotresnorm, @optimplotstepsize, @optimplotfirstorderopt
[] 
Jacobian Вычисление Якобиана: 'on'– задано пользователем, 'off'– по конечным разностям
'off'
191 
Только для алгоритма Trust-Region-Reflective
Параметр Описание Значение по
умолчанию
JacobMult Задает функцию вычисления произведения
Якобиана на другую матрицу без явного
формирования Якобиана (когда он структуризован) 
– 
JacobPattern Задает разреженный образец Якобиана для
конечного дифференцирования, иначе используется плотная матрица, влекущая
большие затраты
– 
MaxPCGIter 
PrecondBandWidth 
TolPCG 
Как в предыдущих приложениях – 
Только для алгоритма Levenberg-Marquardt
Параметр Описание Значение по
умолчанию
ScaleProblem Значение 'Jacobian' может улучшать
сходимость плохо масштабированной задачи
'none'
192 
Учебное издание
Гольдштейн Аркадий Леонидович
ОПТИМИЗАЦИЯ В СРЕДЕ MATLAB 
Учебное пособие
Редактор и корректор В.В. Мальцева
___________________________________________________ 
Подписано в печать 15.01.2015. Формат 70×100/16. 
Усл. печ. л. 15,48. Тираж 20 экз. Заказ № 3/2015. 
___________________________________________________ 
Издательство
Пермского национального исследовательского
политехнического университета. 
Адрес: 614990, г. Пермь, Комсомольский пр., 29, к. 113. 
Тел. (342) 219-80-33. 